{
  "description": "SW1wbGVtZW50IHRoZSBlcHNpbG9uLWdyZWVkeSBtZXRob2QgZm9yIGFjdGlvbiBzZWxlY3Rpb24gaW4gYW4gbi1hcm1lZCBiYW5kaXQgcHJvYmxlbS4gR2l2ZW4gYSBzZXQgb2YgZXN0aW1hdGVkIGFjdGlvbiB2YWx1ZXMgKFEtdmFsdWVzKSwgc2VsZWN0IGFuIGFjdGlvbiB1c2luZyB0aGUgZXBzaWxvbi1ncmVlZHkgcG9saWN5OiB3aXRoIHByb2JhYmlsaXR5IGVwc2lsb24sIGNob29zZSBhIHJhbmRvbSBhY3Rpb247IHdpdGggcHJvYmFiaWxpdHkgMSAtIGVwc2lsb24sIGNob29zZSB0aGUgYWN0aW9uIHdpdGggdGhlIGhpZ2hlc3QgZXN0aW1hdGVkIHZhbHVlLg==",
  "id": "158",
  "test_cases": [
    {
      "test": "import numpy as np\nnp.random.seed(0)\nprint([epsilon_greedy(np.array([1, 2, 3]), epsilon=0.0) for _ in range(5)])",
      "expected_output": "[2, 2, 2, 2, 2]"
    },
    {
      "test": "import numpy as np\nnp.random.seed(1)\nprint([epsilon_greedy(np.array([5, 2, 1]), epsilon=1.0) for _ in range(5)])",
      "expected_output": "[0, 1, 0, 0, 0]"
    }
  ],
  "difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "Q = np.array([0.5, 2.3, 1.7])\nepsilon = 0.0\naction = epsilon_greedy(Q, epsilon)\nprint(action)",
    "output": "1",
    "reasoning": "With epsilon=0.0 (always greedy), the highest Q-value is 2.3 at index 1, so the function always returns 1."
  },
  "category": "Reinforcement Learning",
  "starter_code": "import numpy as np\n\ndef epsilon_greedy(Q, epsilon=0.1):\n    \"\"\"\n    Selects an action using epsilon-greedy policy.\n    Q: np.ndarray of shape (n,) -- estimated action values\n    epsilon: float in [0, 1]\n    Returns: int, selected action index\n    \"\"\"\n    # Your code here\n    pass",
  "title": "Epsilon-Greedy Action Selection for n-Armed Bandit",
  "learn_section": "IyMjIEVwc2lsb24tR3JlZWR5IFBvbGljeQoKVGhlIGVwc2lsb24tZ3JlZWR5IG1ldGhvZCBpcyBhIGZ1bmRhbWVudGFsIGFjdGlvbiBzZWxlY3Rpb24gc3RyYXRlZ3kgdXNlZCBpbiByZWluZm9yY2VtZW50IGxlYXJuaW5nLCBlc3BlY2lhbGx5IGZvciBzb2x2aW5nIHRoZSBuLWFybWVkIGJhbmRpdCBwcm9ibGVtLiBUaGUga2V5IGlkZWEgaXMgdG8gYmFsYW5jZSAqKmV4cGxvcmF0aW9uKiogKHRyeWluZyBuZXcgYWN0aW9ucykgYW5kICoqZXhwbG9pdGF0aW9uKiogKGNob29zaW5nIHRoZSBiZXN0LWtub3duIGFjdGlvbik6CgotIFdpdGggcHJvYmFiaWxpdHkgJFx2YXJlcHNpbG9uJCAoZXBzaWxvbiksIHRoZSBhZ2VudCBleHBsb3JlcyBieSBzZWxlY3RpbmcgYW4gYWN0aW9uIGF0IHJhbmRvbS4KLSBXaXRoIHByb2JhYmlsaXR5ICQxLVx2YXJlcHNpbG9uJCwgaXQgZXhwbG9pdHMgYnkgY2hvb3NpbmcgdGhlIGFjdGlvbiB3aXRoIHRoZSBoaWdoZXN0IGVzdGltYXRlZCB2YWx1ZSAoZ3JlZWR5IGNob2ljZSkuCgpUaGUgZXBzaWxvbi1ncmVlZHkgcG9saWN5IGlzIHNpbXBsZSB0byBpbXBsZW1lbnQgYW5kIHByb3ZpZGVzIGEgd2F5IHRvIGF2b2lkIGdldHRpbmcgc3R1Y2sgd2l0aCBzdWJvcHRpbWFsIGFjdGlvbnMgZHVlIHRvIGluc3VmZmljaWVudCBleHBsb3JhdGlvbi4=",
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "Moe Chabot"
    }
  ],
  "description_decoded": "Implement the epsilon-greedy method for action selection in an n-armed bandit problem. Given a set of estimated action values (Q-values), select an action using the epsilon-greedy policy: with probability epsilon, choose a random action; with probability 1 - epsilon, choose the action with the highest estimated value.",
  "learn_section_decoded": "### Epsilon-Greedy Policy\n\nThe epsilon-greedy method is a fundamental action selection strategy used in reinforcement learning, especially for solving the n-armed bandit problem. The key idea is to balance **exploration** (trying new actions) and **exploitation** (choosing the best-known action):\n\n- With probability $\\varepsilon$ (epsilon), the agent explores by selecting an action at random.\n- With probability $1-\\varepsilon$, it exploits by choosing the action with the highest estimated value (greedy choice).\n\nThe epsilon-greedy policy is simple to implement and provides a way to avoid getting stuck with suboptimal actions due to insufficient exploration."
}