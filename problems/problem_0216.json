{
  "description": "V3JpdGUgYSBQeXRob24gZnVuY3Rpb24gdG8gcHJlZGljdCB0aGUgcHJvYmFiaWxpdHkgZGlzdHJpYnV0aW9uIG9mIHdoaWNoIFRoYW5rc2dpdmluZyBkaXNoIGEgZ3Vlc3Qgd2lsbCBjaG9vc2UgYmFzZWQgb24gdGhlaXIgcHJlZmVyZW5jZSBzY29yZXMuIEdpdmVuIGEgbGlzdCBvZiBwcmVmZXJlbmNlIHNjb3JlcyBmb3IgZGlmZmVyZW50IGRpc2hlcyAoZS5nLiwgdHVya2V5LCBzdHVmZmluZywgY3JhbmJlcnJ5IHNhdWNlLCBwdW1wa2luIHBpZSksIHVzZSB0aGUgc29mdG1heCBmdW5jdGlvbiB0byBjb252ZXJ0IHRoZXNlIHNjb3JlcyBpbnRvIHByb2JhYmlsaXRpZXMuIFRoZSBmdW5jdGlvbiBzaG91bGQgcmV0dXJuIGEgbGlzdCBvZiBwcm9iYWJpbGl0aWVzIHdoZXJlIGVhY2ggcHJvYmFiaWxpdHkgcmVwcmVzZW50cyB0aGUgbGlrZWxpaG9vZCBvZiBjaG9vc2luZyB0aGF0IGRpc2guIFRoZSBwcm9iYWJpbGl0aWVzIHNob3VsZCBzdW0gdG8gMS4=",
  "id": "216",
  "test_cases": [
    {
      "test": "print([round(p, 4) for p in thanksgiving_dish_predictor([2.0, 1.0, 0.5, 1.5])])",
      "expected_output": "[0.4551, 0.1674, 0.1015, 0.276]"
    },
    {
      "test": "print([round(p, 4) for p in thanksgiving_dish_predictor([3.0, 3.0, 3.0, 3.0])])",
      "expected_output": "[0.25, 0.25, 0.25, 0.25]"
    }
  ],
  "difficulty": "easy",
  "pytorch_difficulty": "easy",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "preference_scores = [2.0, 1.0, 0.5, 1.5]  # [turkey, stuffing, cranberry_sauce, pumpkin_pie]",
    "output": "[0.4551, 0.1674, 0.1015, 0.276]",
    "reasoning": "Using softmax: For turkey with score 2.0, we compute e^2.0 / (e^2.0 + e^1.0 + e^0.5 + e^1.5) = 7.389 / 16.238 = 0.4551. The guest has a 45.51% chance of choosing turkey, which has the highest preference score."
  },
  "category": "Deep Learning",
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgdGhhbmtzZ2l2aW5nX2Rpc2hfcHJlZGljdG9yKHByZWZlcmVuY2Vfc2NvcmVzOiB0b3JjaC5UZW5zb3IpIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgUHJlZGljdCB0aGUgcHJvYmFiaWxpdHkgb2YgY2hvb3NpbmcgZWFjaCBUaGFua3NnaXZpbmcgZGlzaCB1c2luZyBzb2Z0bWF4LgogICAgCiAgICBBcmdzOgogICAgICAgIHByZWZlcmVuY2Vfc2NvcmVzOiBUZW5zb3Igb2YgcHJlZmVyZW5jZSBzY29yZXMgZm9yIGVhY2ggZGlzaAogICAgICAgIAogICAgUmV0dXJuczoKICAgICAgICBUZW5zb3Igb2YgcHJvYmFiaWxpdGllcyBmb3IgZWFjaCBkaXNoCiAgICAiIiIKICAgICMgWW91ciBjb2RlIGhlcmUKICAgIHBhc3M=",
  "learn_section": "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",
  "title": "Thanksgiving Feast Predictor: Softmax for Dish Selection",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "pytorch_test_cases": [
    {
      "test": "import torch\nres = thanksgiving_dish_predictor(torch.tensor([2.0, 1.0, 0.5, 1.5]))\nprint([round(p, 4) for p in res.numpy().tolist()])",
      "expected_output": "[0.4551, 0.1674, 0.1015, 0.276]"
    },
    {
      "test": "import torch\nres = thanksgiving_dish_predictor(torch.tensor([3.0, 3.0, 3.0, 3.0]))\nprint([round(p, 4) for p in res.numpy().tolist()])",
      "expected_output": "[0.25, 0.25, 0.25, 0.25]"
    }
  ],
  "starter_code": "def thanksgiving_dish_predictor(preference_scores: list[float]) -> list[float]:\n\t\"\"\"\n\tPredict the probability of choosing each Thanksgiving dish using softmax.\n\t\n\tArgs:\n\t\tpreference_scores: List of preference scores for each dish\n\t\t(e.g., [turkey_score, stuffing_score, cranberry_score, pie_score])\n\t\t\n\tReturns:\n\t\tList of probabilities for each dish\n\t\"\"\"\n\t# Your code here\n\tpass",
  "createdAt": "November 27, 2025 at 12:44:17â€¯PM UTC-0500",
  "description_decoded": "Write a Python function to predict the probability distribution of which Thanksgiving dish a guest will choose based on their preference scores. Given a list of preference scores for different dishes (e.g., turkey, stuffing, cranberry sauce, pumpkin pie), use the softmax function to convert these scores into probabilities. The function should return a list of probabilities where each probability represents the likelihood of choosing that dish. The probabilities should sum to 1.",
  "learn_section_decoded": "## Thanksgiving Feast Predictor: Understanding Softmax\n\n### The Scenario\n\nImagine you're hosting Thanksgiving dinner and want to predict which dish each guest will most likely choose based on their preference scores. A higher score means a stronger preference for that dish.\n\n### The Softmax Function\n\nThe softmax function converts a vector of real numbers (preference scores) into a probability distribution. It's widely used in machine learning for multi-class classification.\n\n**Mathematical Definition:**\n\nFor a vector of scores $\\mathbf{z} = [z_1, z_2, ..., z_n]$, the softmax function computes:\n\n$$\n\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n$$\n\n### Example with Thanksgiving Dishes\n\nSuppose a guest has these preference scores:\n- Turkey: 2.0\n- Stuffing: 1.0\n- Cranberry Sauce: 0.5\n- Pumpkin Pie: 1.5\n\n**Step 1:** Compute exponentials\n- $e^{2.0} \\approx 7.389$\n- $e^{1.0} \\approx 2.718$\n- $e^{0.5} \\approx 1.649$\n- $e^{1.5} \\approx 4.482$\n\n**Step 2:** Sum all exponentials\n- Total = $7.389 + 2.718 + 1.649 + 4.482 \\approx 16.238$\n\n**Step 3:** Divide each by the sum\n- P(Turkey) = $7.389 / 16.238 \\approx 0.455$\n- P(Stuffing) = $2.718 / 16.238 \\approx 0.167$\n- P(Cranberry) = $1.649 / 16.238 \\approx 0.102$\n- P(Pie) = $4.482 / 16.238 \\approx 0.276$\n\n### Key Properties\n\n1. **Output Range**: All outputs are between 0 and 1\n2. **Sum to One**: All probabilities sum to exactly 1.0\n3. **Preserves Order**: Higher scores lead to higher probabilities\n4. **Numerical Stability**: Subtract the max value before exponentiating to prevent overflow\n\n### Numerical Stability Trick\n\nFor large values, $e^{z_i}$ can overflow. The trick is to subtract the maximum:\n\n$$\n\\text{softmax}(z_i) = \\frac{e^{z_i - \\max(\\mathbf{z})}}{\\sum_{j=1}^{n} e^{z_j - \\max(\\mathbf{z})}}\n$$\n\nThis gives the same result but prevents numerical issues!\n\n### Real-World ML Applications\n\n- **Classification**: Predicting which category an input belongs to\n- **Attention Mechanisms**: Weighting importance in transformers\n- **Reinforcement Learning**: Converting action values to selection probabilities\n\nHappy Thanksgiving!"
}