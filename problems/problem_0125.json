{
  "description": "SW1wbGVtZW50IGEgTWl4dHVyZS1vZi1FeHBlcnRzIChNb0UpIGxheWVyIHVzaW5nIHNvZnRtYXggZ2F0aW5nIGFuZCB0b3AtayByb3V0aW5nLiBHaXZlbiBhbiBpbnB1dCB0ZW5zb3IsIGEgc2V0IG9mIGV4cGVydCB3ZWlnaHQgbWF0cmljZXMsIGEgZ2F0aW5nIHdlaWdodCBtYXRyaXgsIGFuZCBwYXJhbWV0ZXJzIHNwZWNpZnlpbmcgdGhlIG51bWJlciBvZiBleHBlcnRzIGFuZCB0aGUgdmFsdWUgb2YgaywgY29tcHV0ZSB0aGUgZmluYWwgTW9FIG91dHB1dCBieSBzZWxlY3RpbmcgdGhlIHRvcC1rIGV4cGVydHMgcGVyIHRva2VuLCBhcHBseWluZyB0aGVpciB0cmFuc2Zvcm1hdGlvbnMsIGFuZCBhZ2dyZWdhdGluZyB0aGUgcmVzdWx0cyB3ZWlnaHRlZCBieSB0aGUgbm9ybWFsaXplZCBnYXRpbmcgcHJvYmFiaWxpdGllcy4=",
  "id": "125",
  "test_cases": [
    {
      "test": "import numpy as np\nnp.random.seed(42)\nd_model = 2\nn_experts = 4\nl_seq = 3\nn_batch = 2\ntop_k = 2\nx = np.random.rand(n_batch, l_seq, d_model)\nWe = np.random.rand(n_experts, d_model, d_model)\nWg = np.random.rand(d_model, n_experts)\noutput = moe(x, We, Wg, n_experts, top_k)\nprint(np.round(output, 4))",
      "expected_output": "[[[0.5148 0.4329]\n  [0.5554 0.5447]\n  [0.1285 0.102 ]]\n\n [[0.339  0.3046]\n  [0.5391 0.417 ]\n  [0.3597 0.3262]]]"
    },
    {
      "test": "import numpy as np\nnp.random.seed(42)\nd_model = 2\nn_experts = 4\nl_seq = 3\nn_batch = 2\ntop_k = 2\nx = np.random.rand(n_batch, l_seq, d_model)\nWe = np.zeros((n_experts, d_model, d_model))\nWg = np.random.rand(d_model, n_experts)\noutput = moe(x, We, Wg, n_experts, top_k)\nprint(output)",
      "expected_output": "[[[0. 0.]\n  [0. 0.]\n  [0. 0.]]\n\n [[0. 0.]\n  [0. 0.]\n  [0. 0.]]]"
    }
  ],
  "difficulty": "hard",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "x = np.arange(12).reshape(2, 3, 2)\nWe = np.ones((4, 2, 2))\nWg = np.ones((2, 4))\ntop_k = 1",
    "output": "[[[1, 1], [5, 5], [9, 9]], [[13, 13], [17, 17], [21, 21]]]",
    "reasoning": "Each token is routed to its top expert and processed using a weight matrix of ones. The result matches the input tokens due to identity transformation and weight 1."
  },
  "category": "Deep Learning",
  "starter_code": "import numpy as np\n\ndef moe(x: np.ndarray, We: np.ndarray, Wg: np.ndarray, n_experts: int, top_k: int) -> np.ndarray:\n    \"\"\"\n    Args:\n        x: Input tensor of shape (n_batch, l_seq, d_model)\n        We: Expert weights of shape (n_experts, d_model, d_model)\n        Wg: Gating weights of shape (d_model, n_experts)\n        n_experts: Number of experts\n        top_k: Number of experts to route each token to\n    Returns:\n        Output tensor of shape (n_batch, l_seq, d_model)\n    \"\"\"\n    pass",
  "title": "Implement a Sparse Mixture of Experts Layer",
  "learn_section": "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",
  "contributor": [
    {
      "profile_link": "https://github.com/lefarov",
      "name": "lefarov"
    }
  ],
  "description_decoded": "Implement a Mixture-of-Experts (MoE) layer using softmax gating and top-k routing. Given an input tensor, a set of expert weight matrices, a gating weight matrix, and parameters specifying the number of experts and the value of k, compute the final MoE output by selecting the top-k experts per token, applying their transformations, and aggregating the results weighted by the normalized gating probabilities.",
  "learn_section_decoded": "\n## Mixture of Experts Layer\n\nMixture-of-Experts layers route each token through a small subset of expert networks, reducing computation while retaining flexibility.\n\n### 1. Gating with Softmax  \n- **Logits**: For each token $t$, compute a vector of gating scores $g_t \\in \\mathbb{R}^E$, where $E$ is the number of experts.  \n- **Softmax**: Convert scores into a probability distribution  \n  $$\n  \\alpha_{t,j}\n    = \\frac{\\exp\\bigl(g_{t,j} - \\max_j g_{t,j}\\bigr)}\n           {\\sum_{j'=1}^{E}\\exp\\bigl(g_{t,j'} - \\max_j g_{t,j'}\\bigr)}.\n  $$\n\n### 2. Top-$k$ Selection  \n- **Sparsity**: Keep only the $k$ largest weights per token, zeroing out the rest.  \n- **Renormalize**: For token $t$, let $\\mathcal{K}_t$ be the indices of the top $k$ experts. Then  \n  $$\n  \\tilde\\alpha_{t,j} =\n    \\begin{cases}\n      \\displaystyle\\frac{\\alpha_{t,j}}{\\sum_{i \\in \\mathcal{K}_t}\\alpha_{t,i}}\n        & j \\in \\mathcal{K}_t,\\\\[8pt]\n      0\n        & \\text{otherwise.}\n    \\end{cases}\n  $$\n\n### 3. Expert Computation  \nEach expert $i$ applies its own linear transform to the token embedding $x_t$:  \n$$\nO_t^{(i)} = x_t\\,W_e^{(i)},\n$$  \nwhere $W_e^{(i)}$ is the expert's $d \\times d$ weight matrix.\n\n### 4. Weighted Aggregation  \nCombine the selected experts' outputs for each token:  \n$$\ny_t = \\sum_{i=1}^{E} \\tilde\\alpha_{t,i}\\,O_t^{(i)}.\n$$  \nThe result $y_t$ lives in the original embedding space $\\mathbb{R}^d$.\n\n---\n\n### Example Walk Through\n\nSuppose one sentence of length 2, embedding size 3, $E=4$ experts, and $k=2$.  \n- After flattening, you get 2 softmax distributions of length 4.  \n- You pick the top 2 experts for each token and renormalize their weights.  \n- Each selected expert produces a 3-dimensional output for its tokens.  \n- You weight and sum those outputs to yield the final 3-dimensional vector per token.\n\nThis sparse routing mechanism dramatically cuts computation only $k$ experts run per token instead of all $E$ while retaining the expressivity of a full ensemble.\n\n"
}