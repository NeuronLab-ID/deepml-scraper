{
  "description": "SW4gcHJvZHVjdGlvbiBNTCBzeXN0ZW1zLCBTZXJ2aWNlIExldmVsIEFncmVlbWVudCAoU0xBKSBtb25pdG9yaW5nIGlzIGNydWNpYWwgZm9yIGVuc3VyaW5nIHlvdXIgbW9kZWwgc2VydmluZyBlbmRwb2ludHMgbWVldCBwZXJmb3JtYW5jZSBndWFyYW50ZWVzLiBHaXZlbiBhIGxpc3Qgb2YgcmVxdWVzdCByZXN1bHRzIGZyb20gYSBtb2RlbCBzZXJ2aW5nIGVuZHBvaW50LCBjb21wdXRlIGtleSBTTEEgY29tcGxpYW5jZSBtZXRyaWNzLgoKRWFjaCByZXF1ZXN0IHJlc3VsdCBpcyBhIGRpY3Rpb25hcnkgd2l0aDoKLSAnbGF0ZW5jeV9tcyc6IFJlc3BvbnNlIGxhdGVuY3kgaW4gbWlsbGlzZWNvbmRzIChmbG9hdCkKLSAnc3RhdHVzJzogRWl0aGVyICdzdWNjZXNzJywgJ2Vycm9yJywgb3IgJ3RpbWVvdXQnCgpXcml0ZSBhIGZ1bmN0aW9uIGBjYWxjdWxhdGVfc2xhX21ldHJpY3MocmVxdWVzdHMsIGxhdGVuY3lfc2xhX21zKWAgdGhhdCBjb21wdXRlczoKCjEuICoqTGF0ZW5jeSBTTEEgQ29tcGxpYW5jZSoqOiBQZXJjZW50YWdlIG9mIHN1Y2Nlc3NmdWwgcmVxdWVzdHMgdGhhdCBjb21wbGV0ZWQgd2l0aGluIHRoZSBsYXRlbmN5IHRocmVzaG9sZAoyLiAqKkVycm9yIFJhdGUqKjogUGVyY2VudGFnZSBvZiBhbGwgcmVxdWVzdHMgdGhhdCByZXN1bHRlZCBpbiBhbiBlcnJvciBvciB0aW1lb3V0CjMuICoqT3ZlcmFsbCBTTEEgQ29tcGxpYW5jZSoqOiBQZXJjZW50YWdlIG9mIGFsbCByZXF1ZXN0cyB0aGF0IGJvdGggc3VjY2VlZGVkIEFORCBtZXQgdGhlIGxhdGVuY3kgdGhyZXNob2xkCgpUaGUgZnVuY3Rpb24gc2hvdWxkIHJldHVybiBhIGRpY3Rpb25hcnkgd2l0aCB0aGVzZSB0aHJlZSBtZXRyaWNzLiBJZiB0aGUgaW5wdXQgbGlzdCBpcyBlbXB0eSwgcmV0dXJuIGFuIGVtcHR5IGRpY3Rpb25hcnkuIElmIHRoZXJlIGFyZSBubyBzdWNjZXNzZnVsIHJlcXVlc3RzLCBsYXRlbmN5X3NsYV9jb21wbGlhbmNlIHNob3VsZCBiZSAwLjAuCgpBbGwgcmV0dXJuZWQgdmFsdWVzIHNob3VsZCBiZSBwZXJjZW50YWdlcyAoMC0xMDApIHJvdW5kZWQgdG8gMiBkZWNpbWFsIHBsYWNlcy4=",
  "id": "250",
  "test_cases": [
    {
      "test": "print(calculate_sla_metrics([{'status': 'success', 'latency_ms': 50}, {'status': 'success', 'latency_ms': 80}, {'status': 'success', 'latency_ms': 120}, {'status': 'error', 'latency_ms': 30}, {'status': 'timeout', 'latency_ms': 5000}]))",
      "expected_output": "{'latency_sla_compliance': 66.67, 'error_rate': 40.0, 'overall_sla_compliance': 40.0}"
    },
    {
      "test": "print(calculate_sla_metrics([{'status': 'success', 'latency_ms': 50}, {'status': 'success', 'latency_ms': 60}]))",
      "expected_output": "{'latency_sla_compliance': 100.0, 'error_rate': 0.0, 'overall_sla_compliance': 100.0}"
    }
  ],
  "difficulty": "easy",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "requests = [{'status': 'success', 'latency_ms': 50}, {'status': 'success', 'latency_ms': 80}, {'status': 'success', 'latency_ms': 120}, {'status': 'error', 'latency_ms': 30}, {'status': 'timeout', 'latency_ms': 5000}], latency_sla_ms = 100.0",
    "output": "{'latency_sla_compliance': 66.67, 'error_rate': 40.0, 'overall_sla_compliance': 40.0}",
    "reasoning": "Out of 5 total requests, 3 succeeded. Of the 3 successful requests, 2 had latency <= 100ms (50ms and 80ms), giving latency_sla_compliance = 2/3 * 100 = 66.67%. There were 2 failed requests (1 error + 1 timeout), giving error_rate = 2/5 * 100 = 40%. Overall SLA compliance = 2/5 * 100 = 40% (requests that both succeeded AND met the latency threshold)."
  },
  "category": "MLOps",
  "starter_code": "def calculate_sla_metrics(requests: list, latency_sla_ms: float = 100.0) -> dict:\n    \"\"\"\n    Calculate SLA compliance metrics for a model serving endpoint.\n    \n    Args:\n        requests: list of request results, each a dict with 'latency_ms' and 'status'\n        latency_sla_ms: maximum acceptable latency in ms for SLA compliance\n    \n    Returns:\n        dict with keys: 'latency_sla_compliance', 'error_rate', 'overall_sla_compliance'\n        All values as percentages (0-100), rounded to 2 decimal places.\n    \"\"\"\n    pass",
  "title": "Calculate SLA Compliance Metrics for Model Service",
  "createdAt": "December 14, 2025 at 11:47:18â€¯AM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "learn_section": "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",
  "description_decoded": "In production ML systems, Service Level Agreement (SLA) monitoring is crucial for ensuring your model serving endpoints meet performance guarantees. Given a list of request results from a model serving endpoint, compute key SLA compliance metrics.\n\nEach request result is a dictionary with:\n- 'latency_ms': Response latency in milliseconds (float)\n- 'status': Either 'success', 'error', or 'timeout'\n\nWrite a function `calculate_sla_metrics(requests, latency_sla_ms)` that computes:\n\n1. **Latency SLA Compliance**: Percentage of successful requests that completed within the latency threshold\n2. **Error Rate**: Percentage of all requests that resulted in an error or timeout\n3. **Overall SLA Compliance**: Percentage of all requests that both succeeded AND met the latency threshold\n\nThe function should return a dictionary with these three metrics. If the input list is empty, return an empty dictionary. If there are no successful requests, latency_sla_compliance should be 0.0.\n\nAll returned values should be percentages (0-100) rounded to 2 decimal places.",
  "learn_section_decoded": "## SLA Compliance Monitoring in MLOps\n\nService Level Agreements (SLAs) define the performance guarantees that a model serving system must meet. Monitoring SLA compliance is essential for maintaining production ML systems and meeting business requirements.\n\n### Key SLA Metrics\n\n#### 1. Latency SLA Compliance\n\nThis metric measures what percentage of successful requests met the latency requirement:\n\n$$\\text{Latency SLA Compliance} = \\frac{|\\{r : r.status = success \\land r.latency \\leq \\tau\\}|}{|\\{r : r.status = success\\}|} \\times 100\\%$$\n\nwhere $\\tau$ is the latency threshold (e.g., 100ms).\n\nThis is crucial because:\n- It focuses on user-facing performance\n- Helps identify latency spikes and performance degradation\n- Guides infrastructure scaling decisions\n\n#### 2. Error Rate\n\nThe error rate captures the reliability of your service:\n\n$$\\text{Error Rate} = \\frac{|\\{r : r.status \\in \\{error, timeout\\}\\}|}{|R|} \\times 100\\%$$\n\nwhere $R$ is the set of all requests.\n\nHigh error rates may indicate:\n- Model crashes or exceptions\n- Resource exhaustion\n- Network issues\n- Invalid input data patterns\n\n#### 3. Overall SLA Compliance\n\nThis comprehensive metric captures requests that meet all SLA requirements:\n\n$$\\text{Overall SLA} = \\frac{|\\{r : r.status = success \\land r.latency \\leq \\tau\\}|}{|R|} \\times 100\\%$$\n\nThis is often the primary metric reported to stakeholders as it reflects the end-user experience.\n\n### Relationship Between Metrics\n\nThese metrics are related:\n\n$$\\text{Overall SLA} = \\text{Success Rate} \\times \\text{Latency SLA Compliance}$$\n\nwhere $\\text{Success Rate} = 100\\% - \\text{Error Rate}$.\n\n### Setting SLA Thresholds\n\nCommon SLA thresholds in ML systems:\n- **p50 latency**: 50-100ms for real-time inference\n- **p99 latency**: 200-500ms (tail latency)\n- **Error rate**: < 0.1% for critical systems\n- **Availability**: 99.9% to 99.99% (three to four nines)\n\n### Alerting Strategy\n\nTypical alerting thresholds:\n- **Warning**: Overall SLA drops below 99%\n- **Critical**: Overall SLA drops below 95%\n- **Page**: Error rate exceeds 5%"
}