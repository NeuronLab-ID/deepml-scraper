{
  "description": "VGhlIE5lZ2F0aXZlIEJpbm9taWFsIGRpc3RyaWJ1dGlvbiBtb2RlbHMgdGhlIG51bWJlciBvZiBmYWlsdXJlcyBiZWZvcmUgYSBzcGVjaWZpZWQgbnVtYmVyIG9mIHN1Y2Nlc3NlcyBvY2N1cnMgaW4gYSBzZXF1ZW5jZSBvZiBpbmRlcGVuZGVudCBCZXJub3VsbGkgdHJpYWxzLiBUaGlzIGRpc3RyaWJ1dGlvbiBpcyB3aWRlbHkgdXNlZCBpbiBtYWNoaW5lIGxlYXJuaW5nIGZvciBtb2RlbGluZyBvdmVyZGlzcGVyc2VkIGNvdW50IGRhdGEgKHdoZXJlIHZhcmlhbmNlIGV4Y2VlZHMgdGhlIG1lYW4pLCBjb21tb24gaW4gYXBwbGljYXRpb25zIGxpa2UgbmF0dXJhbCBsYW5ndWFnZSBwcm9jZXNzaW5nLCBnZW5vbWljcywgYW5kIGN1c3RvbWVyIGJlaGF2aW9yIGFuYWx5c2lzLgoKKipZb3VyIFRhc2s6KioKV3JpdGUgYSBmdW5jdGlvbiBgbmVnYXRpdmVfYmlub21pYWxfcG1mKGssIHIsIHApYCB0aGF0IGNvbXB1dGVzIHRoZSBwcm9iYWJpbGl0eSBtYXNzIGZ1bmN0aW9uIChQTUYpIG9mIHRoZSBOZWdhdGl2ZSBCaW5vbWlhbCBkaXN0cmlidXRpb24uCgpQYXJhbWV0ZXJzOgotIGBrYDogVGhlIG51bWJlciBvZiBmYWlsdXJlcyAobm9uLW5lZ2F0aXZlIGludGVnZXIpCi0gYHJgOiBUaGUgbnVtYmVyIG9mIHN1Y2Nlc3NlcyByZXF1aXJlZCAocG9zaXRpdmUgaW50ZWdlcikKLSBgcGA6IFRoZSBwcm9iYWJpbGl0eSBvZiBzdWNjZXNzIG9uIGVhY2ggdHJpYWwgKDAgPCBwIDw9IDEpCgpUaGUgZnVuY3Rpb24gc2hvdWxkIHJldHVybiB0aGUgcHJvYmFiaWxpdHkgUChYID0gaykgcm91bmRlZCB0byA1IGRlY2ltYWwgcGxhY2VzLgoKTm90ZTogVXNlIHRoZSBwYXJhbWV0ZXJpemF0aW9uIHdoZXJlIFggcmVwcmVzZW50cyB0aGUgbnVtYmVyIG9mIGZhaWx1cmVzIGJlZm9yZSBhY2hpZXZpbmcgciBzdWNjZXNzZXMu",
  "id": "247",
  "test_cases": [
    {
      "test": "print(negative_binomial_pmf(3, 2, 0.5))",
      "expected_output": "0.125"
    },
    {
      "test": "print(negative_binomial_pmf(0, 1, 0.7))",
      "expected_output": "0.7"
    }
  ],
  "difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "k = 3, r = 2, p = 0.5",
    "output": "0.125",
    "reasoning": "We want the probability of exactly 3 failures before achieving 2 successes with p=0.5. Using the PMF formula: P(X=3) = C(3+2-1, 3) * 0.5^2 * 0.5^3 = C(4,3) * 0.25 * 0.125 = 4 * 0.03125 = 0.125. This represents sequences like FFFSFS, FFSFS, etc. where F=failure and S=success, ending with the 2nd success."
  },
  "category": "Probability",
  "starter_code": "import math\n\ndef negative_binomial_pmf(k: int, r: int, p: float) -> float:\n    \"\"\"\n    Calculate the probability of observing exactly k failures\n    before achieving r successes in independent Bernoulli trials.\n    \n    Args:\n        k: Number of failures (non-negative integer)\n        r: Number of successes required (positive integer)\n        p: Probability of success on each trial (0 < p <= 1)\n    \n    Returns:\n        Probability P(X = k) rounded to 5 decimal places\n    \"\"\"\n    # Your code here\n    pass",
  "title": "Negative Binomial Distribution Probability",
  "createdAt": "December 14, 2025 at 11:41:24â€¯AM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "learn_section": "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",
  "description_decoded": "The Negative Binomial distribution models the number of failures before a specified number of successes occurs in a sequence of independent Bernoulli trials. This distribution is widely used in machine learning for modeling overdispersed count data (where variance exceeds the mean), common in applications like natural language processing, genomics, and customer behavior analysis.\n\n**Your Task:**\nWrite a function `negative_binomial_pmf(k, r, p)` that computes the probability mass function (PMF) of the Negative Binomial distribution.\n\nParameters:\n- `k`: The number of failures (non-negative integer)\n- `r`: The number of successes required (positive integer)\n- `p`: The probability of success on each trial (0 < p <= 1)\n\nThe function should return the probability P(X = k) rounded to 5 decimal places.\n\nNote: Use the parameterization where X represents the number of failures before achieving r successes.",
  "learn_section_decoded": "## Negative Binomial Distribution\n\n### Definition\n\nThe Negative Binomial distribution models the number of failures that occur before a specified number of successes is achieved in a sequence of independent Bernoulli trials. Each trial has the same probability $p$ of success.\n\n### Probability Mass Function\n\nIf $X$ is the number of failures before $r$ successes, then:\n\n$$\nP(X = k) = \\binom{k + r - 1}{k} p^r (1-p)^k\n$$\n\nwhere:\n- $k$ = number of failures $(k = 0, 1, 2, ...)$\n- $r$ = number of successes required $(r > 0)$\n- $p$ = probability of success on each trial $(0 < p \\leq 1)$\n- $\\binom{k+r-1}{k} = \\frac{(k+r-1)!}{k!(r-1)!}$ is the binomial coefficient\n\n### Understanding the Formula\n\nThe binomial coefficient $\\binom{k+r-1}{k}$ counts the number of ways to arrange $k$ failures and $r-1$ successes before the final (r-th) success. We multiply by:\n- $p^r$: probability of $r$ successes\n- $(1-p)^k$: probability of $k$ failures\n\n### Key Properties\n\n**Mean (Expected Value):**\n$$\nE[X] = \\frac{r(1-p)}{p}\n$$\n\n**Variance:**\n$$\nVar(X) = \\frac{r(1-p)}{p^2}\n$$\n\nNotice that the variance is always greater than the mean when $p < 1$, making this distribution useful for modeling **overdispersed** count data.\n\n### Special Case: Geometric Distribution\n\nWhen $r = 1$, the Negative Binomial reduces to the Geometric distribution, which models the number of failures before the first success:\n\n$$\nP(X = k) = p(1-p)^k\n$$\n\n### Example Calculation\n\nSuppose we flip a coin with $p = 0.5$ and want exactly 3 failures before 2 successes:\n\n1. **Identify parameters**: $k = 3$, $r = 2$, $p = 0.5$\n\n2. **Calculate binomial coefficient**:\n$$\n\\binom{3 + 2 - 1}{3} = \\binom{4}{3} = 4\n$$\n\n3. **Apply the formula**:\n$$\nP(X = 3) = 4 \\times (0.5)^2 \\times (0.5)^3 = 4 \\times 0.25 \\times 0.125 = 0.125\n$$\n\n### Applications in Machine Learning\n\n1. **Text Analysis**: Modeling word counts that exhibit overdispersion\n2. **Genomics**: Analyzing RNA-seq read counts\n3. **Customer Analytics**: Modeling purchase frequencies\n4. **Reliability Engineering**: Number of defects before system failure\n\nThe Negative Binomial distribution is preferred over Poisson when data shows variance greater than the mean, which is common in real-world count data."
}