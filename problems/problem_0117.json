{
  "description": "SW1wbGVtZW50IGEgZnVuY3Rpb24gdGhhdCBjb21wdXRlcyBhbiBvcnRob25vcm1hbCBiYXNpcyBmb3IgdGhlIHN1YnNwYWNlIHNwYW5uZWQgYnkgYSBsaXN0IG9mIDJEIHZlY3RvcnMgdXNpbmcgdGhlIEdyYW0tU2NobWlkdCBwcm9jZXNzLiBUaGUgZnVuY3Rpb24gc2hvdWxkIHRha2UgYSBsaXN0IG9mIDJEIHZlY3RvcnMgYW5kIGEgdG9sZXJhbmNlIHZhbHVlICh0b2wpIHRvIGRldGVybWluZSBsaW5lYXIgaW5kZXBlbmRlbmNlLCByZXR1cm5pbmcgYSBsaXN0IG9mIG9ydGhvbm9ybWFsIHZlY3RvcnMgKHVuaXQgbGVuZ3RoIGFuZCBvcnRob2dvbmFsIHRvIGVhY2ggb3RoZXIpIHRoYXQgc3BhbiB0aGUgc2FtZSBzdWJzcGFjZS4gVGhpcyBpcyBhIGZ1bmRhbWVudGFsIGNvbmNlcHQgaW4gbGluZWFyIGFsZ2VicmEgd2l0aCBhcHBsaWNhdGlvbnMgaW4gbWFjaGluZSBsZWFybmluZywgc3VjaCBhcyBmZWF0dXJlIG9ydGhvZ29uYWxpemF0aW9uLg==",
  "id": "117",
  "test_cases": [
    {
      "test": "basis = orthonormal_basis([[1, 0], [1, 1]]); print([b.round(4) for b in basis])",
      "expected_output": "[array([1., 0.]), array([0., 1.])]"
    },
    {
      "test": "basis = orthonormal_basis([[2, 0], [4, 0]], tol=1e-10); print([b.round(4) for b in basis])",
      "expected_output": "[array([1., 0.])]"
    }
  ],
  "difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "orthonormal_basis([[1, 0], [1, 1]])",
    "output": "[array([1., 0.]), array([0., 1.])]",
    "reasoning": "Start with [1, 0], normalize to [1, 0]. For [1, 1], subtract its projection onto [1, 0] (which is [1, 0]), leaving [0, 1]. Check if norm > 1e-10 (it is 1), then normalize to [0, 1]. The result is an orthonormal basis."
  },
  "category": "Linear Algebra",
  "starter_code": "import numpy as np\n\ndef orthonormal_basis(vectors: list[list[float]], tol: float = 1e-10) -> list[np.ndarray]:\n    # Your code here\n    pass",
  "title": "Compute Orthonormal Basis for 2D Vectors",
  "learn_section": "IyMgVW5kZXJzdGFuZGluZyB0aGUgR3JhbS1TY2htaWR0IFByb2Nlc3MKClRoZSBHcmFtLVNjaG1pZHQgcHJvY2VzcyB0cmFuc2Zvcm1zIGEgc2V0IG9mIHZlY3RvcnMgaW50byBhbiBvcnRob25vcm1hbCBiYXNpcyB2ZWN0b3JzIHRoYXQgYXJlIG9ydGhvZ29uYWwgKHBlcnBlbmRpY3VsYXIpIGFuZCBoYXZlIHVuaXQgbGVuZ3RoIGZvciB0aGUgc3Vic3BhY2UgdGhleSBzcGFuLgoKIyMjIE1hdGhlbWF0aWNhbCBEZWZpbml0aW9uCgpHaXZlbiB2ZWN0b3JzICR2XzEsIHZfMiwgXGxkb3RzJCwgdGhlIHByb2Nlc3MgY29uc3RydWN0cyBhbiBvcnRob25vcm1hbCBzZXQgJHVfMSwgdV8yLCBcbGRvdHMkIGFzIGZvbGxvd3M6CjEuICR1XzEgPSBcZnJhY3t2XzF9e1x8dl8xXHx9JCAobm9ybWFsaXplIHRoZSBmaXJzdCB2ZWN0b3IpLgoyLiBGb3Igc3Vic2VxdWVudCB2ZWN0b3JzICR2X2skOgogICAtIFN1YnRyYWN0IHByb2plY3Rpb25zOiAkJHdfayA9IHZfayAtIFxzdW1fe2k9MX1ee2stMX0gXHRleHR7cHJvan1fe3VfaX0odl9rKSwkJCB3aGVyZSAkXHRleHR7cHJvan1fe3VfaX0odl9rKSA9ICh2X2sgXGNkb3QgdV9pKSB1X2kkLgogICAtIE5vcm1hbGl6ZTogJCR1X2sgPSBcZnJhY3t3X2t9e1x8d19rXHx9LCQkIGlmICRcfHdfa1x8ID4gXHRleHR7dG9sfSQuCgojIyMgV2h5IE9ydGhvbm9ybWFsIEJhc2VzPwoKLSBPcnRob2dvbmFsIHZlY3RvcnMgc2ltcGxpZnkgY29tcHV0YXRpb25zIChlLmcuLCB0aGVpciBkb3QgcHJvZHVjdCBpcyB6ZXJvKS4KLSBVbml0IGxlbmd0aCBlbnN1cmVzIGVxdWFsIHNjYWxpbmcsIHVzZWZ1bCBpbiAkUENBJCwgJFFSJCBkZWNvbXBvc2l0aW9uLCBhbmQgbmV1cmFsIG5ldHdvcmsgb3B0aW1pemF0aW9uLgoKIyMjIFNwZWNpYWwgQ2FzZQoKSWYgYSB2ZWN0b3IncyBub3JtIGlzIGxlc3MgdGhhbiBvciBlcXVhbCB0byAkXHRleHR7dG9sfSQgKGRlZmF1bHQgJDFlLTEwJCksIGl0J3MgY29uc2lkZXJlZCBsaW5lYXJseSBkZXBlbmRlbnQgYW5kIGV4Y2x1ZGVkIGZyb20gdGhlIGJhc2lzLgoKIyMjIEV4YW1wbGUKCkZvciB2ZWN0b3JzIGBbWzEsIDBdLCBbMSwgMV1dYCB3aXRoICRcdGV4dHt0b2x9ID0gMWUtMTAkOgoxLiAkdl8xID0gWzEsIDBdJCwgJFx8dl8xXHwgPSAxJCwgc28gJHVfMSA9IFsxLCAwXSQuCjIuICR2XzIgPSBbMSwgMV0kLCBwcm9qZWN0aW9uIG9uICR1XzEkOiAkKHZfMiBcY2RvdCB1XzEpIHVfMSA9IDEgXGNkb3QgWzEsIDBdID0gWzEsIDBdJC4KICAgLSAkd18yID0gWzEsIDFdIC0gWzEsIDBdID0gWzAsIDFdJC4KICAgLSAkXHx3XzJcfCA9IDEgPiAxZS0xMCQsIHNvICR1XzIgPSBbMCwgMV0kLgoKUmVzdWx0OiBgW1sxLCAwXSwgWzAsIDFdXWAsIHJvdW5kZWQgdG8gNCBkZWNpbWFsIHBsYWNlcy4=",
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "Moe Chabot"
    }
  ],
  "description_decoded": "Implement a function that computes an orthonormal basis for the subspace spanned by a list of 2D vectors using the Gram-Schmidt process. The function should take a list of 2D vectors and a tolerance value (tol) to determine linear independence, returning a list of orthonormal vectors (unit length and orthogonal to each other) that span the same subspace. This is a fundamental concept in linear algebra with applications in machine learning, such as feature orthogonalization.",
  "learn_section_decoded": "## Understanding the Gram-Schmidt Process\n\nThe Gram-Schmidt process transforms a set of vectors into an orthonormal basis vectors that are orthogonal (perpendicular) and have unit length for the subspace they span.\n\n### Mathematical Definition\n\nGiven vectors $v_1, v_2, \\ldots$, the process constructs an orthonormal set $u_1, u_2, \\ldots$ as follows:\n1. $u_1 = \\frac{v_1}{\\|v_1\\|}$ (normalize the first vector).\n2. For subsequent vectors $v_k$:\n   - Subtract projections: $$w_k = v_k - \\sum_{i=1}^{k-1} \\text{proj}_{u_i}(v_k),$$ where $\\text{proj}_{u_i}(v_k) = (v_k \\cdot u_i) u_i$.\n   - Normalize: $$u_k = \\frac{w_k}{\\|w_k\\|},$$ if $\\|w_k\\| > \\text{tol}$.\n\n### Why Orthonormal Bases?\n\n- Orthogonal vectors simplify computations (e.g., their dot product is zero).\n- Unit length ensures equal scaling, useful in $PCA$, $QR$ decomposition, and neural network optimization.\n\n### Special Case\n\nIf a vector's norm is less than or equal to $\\text{tol}$ (default $1e-10$), it's considered linearly dependent and excluded from the basis.\n\n### Example\n\nFor vectors `[[1, 0], [1, 1]]` with $\\text{tol} = 1e-10$:\n1. $v_1 = [1, 0]$, $\\|v_1\\| = 1$, so $u_1 = [1, 0]$.\n2. $v_2 = [1, 1]$, projection on $u_1$: $(v_2 \\cdot u_1) u_1 = 1 \\cdot [1, 0] = [1, 0]$.\n   - $w_2 = [1, 1] - [1, 0] = [0, 1]$.\n   - $\\|w_2\\| = 1 > 1e-10$, so $u_2 = [0, 1]$.\n\nResult: `[[1, 0], [0, 1]]`, rounded to 4 decimal places."
}