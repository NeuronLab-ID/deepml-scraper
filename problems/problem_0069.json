{
  "video": "",
  "description": "CiMjIFRhc2s6IENvbXB1dGUgdGhlIFItc3F1YXJlZCBWYWx1ZSBpbiBSZWdyZXNzaW9uIEFuYWx5c2lzCgotIFItc3F1YXJlZCwgYWxzbyBrbm93biBhcyB0aGUgY29lZmZpY2llbnQgb2YgZGV0ZXJtaW5hdGlvbiwgaXMgYSBtZWFzdXJlIHRoYXQgaW5kaWNhdGVzIGhvdyB3ZWxsIHRoZSBpbmRlcGVuZGVudCB2YXJpYWJsZXMgZXhwbGFpbiB0aGUgdmFyaWFiaWxpdHkgb2YgdGhlIGRlcGVuZGVudCB2YXJpYWJsZSBpbiBhIHJlZ3Jlc3Npb24gbW9kZWwuIAoKLSAqKllvdXIgVGFzayoqOiAKICAgIFRvIGltcGxlbWVudCB0aGUgZnVuY3Rpb24gYHJfc3F1YXJlZCh5X3RydWUsIHlfcHJlZClgIHRoYXQgY2FsY3VsYXRlcyB0aGUgUi1zcXVhcmVkIHZhbHVlLCBnaXZlbiBhcnJheXMgb2YgdHJ1ZSB2YWx1ZXMgYHlfdHJ1ZWAgYW5kIHByZWRpY3RlZCB2YWx1ZXMgYHlfcHJlZGAuCg==",
  "example": {
    "input": "import numpy as np\n\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1.1, 2.1, 2.9, 4.2, 4.8])\nprint(r_squared(y_true, y_pred))",
    "output": "0.989",
    "reasoning": "The R-squared value is calculated to be 0.989, indicating that the regression model explains 98.9% of the variance in the dependent variable."
  },
  "dislikes": 0,
  "test_cases": [
    {
      "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1, 2, 3, 4, 5])\nprint(r_squared(y_true, y_pred))\n",
      "expected_output": "1.0"
    },
    {
      "test": "\nimport numpy as np\ny_true = np.array([1, 2, 3, 4, 5])\ny_pred = np.array([1.1, 2.1, 2.9, 4.2, 4.8])\nprint(r_squared(y_true, y_pred))\n",
      "expected_output": "0.989"
    }
  ],
  "starter_code": "\nimport numpy as np\n\ndef r_squared(y_true, y_pred):\n\t# Write your code here\n\tpass\n",
  "title": "Calculate R-squared for Regression Analysis",
  "learn_section": "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",
  "difficulty": "easy",
  "contributor": [
    {
      "profile_link": "https://github.com/rittik9",
      "name": "rittik9"
    }
  ],
  "likes": 0,
  "category": "Machine Learning",
  "description_decoded": "\n## Task: Compute the R-squared Value in Regression Analysis\n\n- R-squared, also known as the coefficient of determination, is a measure that indicates how well the independent variables explain the variability of the dependent variable in a regression model. \n\n- **Your Task**: \n    To implement the function `r_squared(y_true, y_pred)` that calculates the R-squared value, given arrays of true values `y_true` and predicted values `y_pred`.\n",
  "learn_section_decoded": "\n# Understanding R-squared (RÂ²) in Regression Analysis\n\nR-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. It provides insight into how well the model fits the data.\n\n### Mathematical Definition\n\nThe R-squared value is calculated using the following formula:  \n$$\nR^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n$$\nWhere:  \n\n1) $ \\text{SSR} $ (Sum of Squared Residuals): The sum of the squares of the differences between the actual values and the predicted values.  \n2) $ \\text{SST} $ (Total Sum of Squares): The sum of the squares of the differences between the actual values and the mean of the actual values.\n\n### Equations for SSR and SST\n\nTo calculate SSR and SST, we use the following formulas:  \n\n1) SSR:  \n$$\n\\text{SSR} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n$$  \n\n2) SST:  \n$$\n\\text{SST} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n$$  \n\nWhere:  \n\n1) $ y_i $: Actual value  \n2) $ \\hat{y}_i $: Predicted value  \n3) $ \\bar{y} $: Mean of the actual values  \n\n### Significance of R-squared\n\nR-squared is a key metric for evaluating how well a regression model performs. A higher R-squared value indicates a better fit for the model, meaning it can explain more variability in the data. However, it's important to note:  \n\n- A high R-squared does not always imply that the model is good; it can sometimes be misleading if overfitting occurs.  \n- It should be used in conjunction with other metrics for comprehensive model evaluation.\n\n### Implementing R-squared Calculation\n\nIn this problem, you will implement a function to calculate R-squared given arrays of true and predicted values from a regression task. The results should be rounded to three decimal places.  \n\nIn the solution, the implemented $ r\\_squared() $ function calculates R-squared by first determining SSR and SST, then applying them to compute $ R^2 $. It handles edge cases such as perfect predictions and situations where all true values are identical.\n\n### Reference\n\nYou can refer to this resource for more information:  \n[Coefficient of Determination](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html)\n"
}