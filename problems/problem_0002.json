{
  "mdx_file": "a8855223-dfbd-4871-b7d6-09761d70e9a5.mdx",
  "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIHRyYW5zcG9zZV9tYXRyaXhfdGcoYTpUZW5zb3IpIC0+IFRlbnNvcjoKICAgICIiIgogICAgVHJhbnNwb3NlIGEgMkQgbWF0cml4IGBhYCB1c2luZyB0aW55Z3JhZC4KICAgIElucHV0cyBhcmUgdGlueWdyYWQgVGVuc29ycy4KICAgIFJldHVybnMgYSB0cmFuc3Bvc2VkIFRlbnNvci4KICAgICIiIgogICAgcGFzcw==",
  "test_cases": [
    {
      "test": "print(transpose_matrix([[1, 2], [3, 4], [5, 6]]))",
      "expected_output": "[[1, 3, 5], [2, 4, 6]]"
    },
    {
      "test": "print(transpose_matrix([[1, 2, 3], [4, 5, 6]]))",
      "expected_output": "[[1, 4], [2, 5], [3, 6]]"
    }
  ],
  "pytorch_difficulty": "easy",
  "likes": "0",
  "video": "https://youtu.be/fj0ZJ2gTSmI?si=vG8VSqASjyG0eNLY",
  "cuda_test_cases": [
    {
      "test": "#include <iostream>\n#include <vector>\n\nstd::vector<std::vector<float>> transpose_matrix(const std::vector<std::vector<float>>& matrix);\n\nvoid print_matrix(const std::vector<std::vector<float>>& m) {\n    std::cout << \"[\";\n    for (int i = 0; i < m.size(); i++) {\n        std::cout << \"[\";\n        for (int j = 0; j < m[i].size(); j++) {\n            std::cout << (int)m[i][j];\n            if (j < m[i].size() - 1) std::cout << \", \";\n        }\n        std::cout << \"]\";\n        if (i < m.size() - 1) std::cout << \", \";\n    }\n    std::cout << \"]\" << std::endl;\n}\n\nint main() {\n    std::vector<std::vector<float>> matrix = {{1,2},{3,4},{5,6}};\n    auto result = transpose_matrix(matrix);\n    print_matrix(result);\n    return 0;\n}",
      "expected_output": "[[1, 3, 5], [2, 4, 6]]"
    },
    {
      "test": "#include <iostream>\n#include <vector>\n\nstd::vector<std::vector<float>> transpose_matrix(const std::vector<std::vector<float>>& matrix);\n\nvoid print_matrix(const std::vector<std::vector<float>>& m) {\n    std::cout << \"[\";\n    for (int i = 0; i < m.size(); i++) {\n        std::cout << \"[\";\n        for (int j = 0; j < m[i].size(); j++) {\n            std::cout << (int)m[i][j];\n            if (j < m[i].size() - 1) std::cout << \", \";\n        }\n        std::cout << \"]\";\n        if (i < m.size() - 1) std::cout << \", \";\n    }\n    std::cout << \"]\" << std::endl;\n}\n\nint main() {\n    std::vector<std::vector<float>> matrix = {{1,2,3},{4,5,6}};\n    auto result = transpose_matrix(matrix);\n    print_matrix(result);\n    return 0;\n}",
      "expected_output": "[[1, 4], [2, 5], [3, 6]]"
    }
  ],
  "example": {
    "input": "a = [[1, 2, 3], [4, 5, 6]]",
    "output": "[[1, 4], [2, 5], [3, 6]]",
    "reasoning": "The input is a 2×3 matrix. The transpose swaps rows and columns: the first row [1, 2, 3] becomes the first column, and the second row [4, 5, 6] becomes the second column, resulting in a 3×2 matrix."
  },
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgdHJhbnNwb3NlX21hdHJpeChhKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFRyYW5zcG9zZSBhIDJEIG1hdHJpeCB1c2luZyBQeVRvcmNoLgogICAgCiAgICBBcmdzOgogICAgICAgIGE6IEEgMkQgbWF0cml4IChjYW4gYmUgbGlzdCwgbnVtcHkgYXJyYXksIG9yIHRvcmNoLlRlbnNvcikKICAgIAogICAgUmV0dXJuczoKICAgICAgICBBIHRyYW5zcG9zZWQgdG9yY2guVGVuc29yCiAgICAiIiIKICAgIGFfdCA9IHRvcmNoLmFzX3RlbnNvcihhKQogICAgIyBZb3VyIGNvZGUgaGVyZQogICAgcGFzcw==",
  "learn_section": "IyMgVHJhbnNwb3NlIG9mIGEgTWF0cml4CgpUaGUgKip0cmFuc3Bvc2UqKiBvZiBhIG1hdHJpeCBpcyBvYnRhaW5lZCBieSBpbnRlcmNoYW5naW5nIGl0cyByb3dzIGFuZCBjb2x1bW5zLiBJZiAkQSQgaXMgYW4gJG0gXHRpbWVzIG4kIG1hdHJpeCwgdGhlbiBpdHMgdHJhbnNwb3NlICRBXlQkIGlzIGFuICRuIFx0aW1lcyBtJCBtYXRyaXguCgojIyMgRGVmaW5pdGlvbgoKRm9yIGEgbWF0cml4ICRBJCB3aGVyZSBlbGVtZW50ICRBX3tpan0kIGlzIGluIHJvdyAkaSQgYW5kIGNvbHVtbiAkaiQ6CiQkCihBXlQpX3tpan0gPSBBX3tqaX0KJCQKCiMjIyBFeGFtcGxlCgoqKk9yaWdpbmFsIE1hdHJpeCAkQSQgKDLDlzMpOioqCiQkCkEgPSBcYmVnaW57cG1hdHJpeH0gCjEgJiAyICYgMyBcXCAKNCAmIDUgJiA2IApcZW5ke3BtYXRyaXh9CiQkCgoqKlRyYW5zcG9zZWQgTWF0cml4ICRBXlQkICgzw5cyKToqKgokJApBXlQgPSBcYmVnaW57cG1hdHJpeH0gCjEgJiA0IFxcIAoyICYgNSBcXCAKMyAmIDYgClxlbmR7cG1hdHJpeH0KJCQKCiMjIyBQcm9wZXJ0aWVzIG9mIFRyYW5zcG9zZQoKMS4gKipEb3VibGUgdHJhbnNwb3NlKio6ICQoQV5UKV5UID0gQSQKMi4gKipTdW0qKjogJChBICsgQileVCA9IEFeVCArIEJeVCQKMy4gKipTY2FsYXIgbXVsdGlwbGljYXRpb24qKjogJChjQSleVCA9IGNBXlQkCjQuICoqUHJvZHVjdCoqOiAkKEFCKV5UID0gQl5UIEFeVCQgKG5vdGUgdGhlIHJldmVyc2VkIG9yZGVyKQo1LiAqKlN5bW1ldHJpYyBtYXRyaXgqKjogJEEgPSBBXlQkIG1lYW5zICRBJCBpcyBzeW1tZXRyaWMKCiMjIyBQeXRob24gSW1wbGVtZW50YXRpb24KClVzaW5nIGB6aXAoKm1hdHJpeClgIGlzIGEgUHl0aG9uaWMgd2F5IHRvIHRyYW5zcG9zZToKLSBgKm1hdHJpeGAgdW5wYWNrcyByb3dzIGFzIHNlcGFyYXRlIGFyZ3VtZW50cwotIGB6aXAoKWAgZ3JvdXBzIGVsZW1lbnRzIGJ5IHBvc2l0aW9uIChmaXJzdCBlbGVtZW50cyB0b2dldGhlciwgc2Vjb25kIGVsZW1lbnRzIHRvZ2V0aGVyLCBldGMuKQotIENvbnZlcnQgZWFjaCB0dXBsZSB0byBhIGxpc3QgZm9yIHRoZSBmaW5hbCByZXN1bHQKCiMjIyBBcHBsaWNhdGlvbnMKCi0gKipMaW5lYXIgYWxnZWJyYSoqOiBTb2x2aW5nIHN5c3RlbXMgb2YgZXF1YXRpb25zCi0gKipNYWNoaW5lIGxlYXJuaW5nKio6IFJlc2hhcGluZyBmZWF0dXJlIG1hdHJpY2VzLCBjb21wdXRpbmcgY292YXJpYW5jZSBtYXRyaWNlcwotICoqQ29tcHV0ZXIgZ3JhcGhpY3MqKjogVHJhbnNmb3JtYXRpb24gbWF0cmljZXMKLSAqKkRhdGEgcHJvY2Vzc2luZyoqOiBDb252ZXJ0aW5nIGJldHdlZW4gcm93LW1ham9yIGFuZCBjb2x1bW4tbWFqb3IgZm9ybWF0cwo=",
  "cuda_starter_code": "I2luY2x1ZGUgPGN1ZGFfcnVudGltZS5oPgojaW5jbHVkZSA8aW9zdHJlYW0+CiNpbmNsdWRlIDx2ZWN0b3I+CgpfX2dsb2JhbF9fIHZvaWQgdHJhbnNwb3NlX2tlcm5lbCgKICAgIGNvbnN0IGZsb2F0KiBpbnB1dCwKICAgIGZsb2F0KiBvdXRwdXQsCiAgICBpbnQgcm93cywKICAgIGludCBjb2xzCikgewogICAgLy8gSW1wbGVtZW50IHRoZSBrZXJuZWwgdG8gdHJhbnNwb3NlIHRoZSBtYXRyaXgKICAgIC8vIGlucHV0IGlzIHJvd3MgeCBjb2xzLCBvdXRwdXQgc2hvdWxkIGJlIGNvbHMgeCByb3dzCn0KCnN0ZDo6dmVjdG9yPHN0ZDo6dmVjdG9yPGZsb2F0Pj4gdHJhbnNwb3NlX21hdHJpeChjb25zdCBzdGQ6OnZlY3RvcjxzdGQ6OnZlY3RvcjxmbG9hdD4+JiBtYXRyaXgpIHsKICAgIC8vIDEuIEFsbG9jYXRlIGRldmljZSBtZW1vcnkKICAgIC8vIDIuIENvcHkgZGF0YSB0byBkZXZpY2UKICAgIC8vIDMuIExhdW5jaCBrZXJuZWwKICAgIC8vIDQuIENvcHkgcmVzdWx0IGJhY2sKICAgIC8vIDUuIEZyZWUgbWVtb3J5IGFuZCByZXR1cm4gcmVzdWx0CiAgICByZXR1cm4ge307Cn0=",
  "tinygrad_test_cases": [
    {
      "test": "from tinygrad.tensor import Tensor\nres = transpose_matrix_tg(Tensor([[1,2,3],[4,5,6]]))\nprint(res.numpy().tolist())",
      "expected_output": "[[1, 4], [2, 5], [3, 6]]"
    },
    {
      "test": "from tinygrad.tensor import Tensor\nres = transpose_matrix_tg(Tensor([[1,2],[3,4]]))\nprint(res.numpy().tolist())",
      "expected_output": "[[1, 3], [2, 4]]"
    }
  ],
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "Moe Chabot"
    }
  ],
  "description": "V3JpdGUgYSBQeXRob24gZnVuY3Rpb24gdGhhdCBjb21wdXRlcyB0aGUgdHJhbnNwb3NlIG9mIGEgZ2l2ZW4gMkQgbWF0cml4LiBUaGUgdHJhbnNwb3NlIG9mIGEgbWF0cml4IGlzIGZvcm1lZCBieSB0dXJuaW5nIGl0cyByb3dzIGludG8gY29sdW1ucyBhbmQgY29sdW1ucyBpbnRvIHJvd3MuIEZvciBhbiBtw5duIG1hdHJpeCwgdGhlIHRyYW5zcG9zZSB3aWxsIGJlIGFuIG7Dl20gbWF0cml4Lg==",
  "id": "2",
  "tinygrad_difficulty": "easy",
  "difficulty": "easy",
  "cuda_difficulty": "medium",
  "dislikes": "0",
  "category": "Linear Algebra",
  "starter_code": "def transpose_matrix(a: list[list[int|float]]) -> list[list[int|float]]:\n    \"\"\"\n    Transpose a 2D matrix by swapping rows and columns.\n    \n    Args:\n        a: A 2D matrix of shape (m, n)\n    \n    Returns:\n        The transposed matrix of shape (n, m)\n    \"\"\"\n    # Your code here\n    pass",
  "title": "Transpose of a Matrix",
  "createdAt": "December 15, 2025 at 7:47:47 AM UTC-0500",
  "pytorch_test_cases": [
    {
      "test": "import torch\nres = transpose_matrix(torch.tensor([[1, 2, 3], [4, 5, 6]]))\nprint(res.numpy().tolist())",
      "expected_output": "[[1, 4], [2, 5], [3, 6]]"
    },
    {
      "test": "import torch\nres = transpose_matrix(torch.tensor([[1, 2], [3, 4]]))\nprint(res.numpy().tolist())",
      "expected_output": "[[1, 3], [2, 4]]"
    },
    {
      "test": "import torch\nres = transpose_matrix(torch.tensor([[1, 2], [3, 4], [5, 6]]))\nprint(res.numpy().tolist())",
      "expected_output": "[[1, 3, 5], [2, 4, 6]]"
    }
  ],
  "description_decoded": "Write a Python function that computes the transpose of a given 2D matrix. The transpose of a matrix is formed by turning its rows into columns and columns into rows. For an m×n matrix, the transpose will be an n×m matrix.",
  "learn_section_decoded": "## Transpose of a Matrix\n\nThe **transpose** of a matrix is obtained by interchanging its rows and columns. If $A$ is an $m \\times n$ matrix, then its transpose $A^T$ is an $n \\times m$ matrix.\n\n### Definition\n\nFor a matrix $A$ where element $A_{ij}$ is in row $i$ and column $j$:\n$$\n(A^T)_{ij} = A_{ji}\n$$\n\n### Example\n\n**Original Matrix $A$ (2×3):**\n$$\nA = \\begin{pmatrix} \n1 & 2 & 3 \\\\ \n4 & 5 & 6 \n\\end{pmatrix}\n$$\n\n**Transposed Matrix $A^T$ (3×2):**\n$$\nA^T = \\begin{pmatrix} \n1 & 4 \\\\ \n2 & 5 \\\\ \n3 & 6 \n\\end{pmatrix}\n$$\n\n### Properties of Transpose\n\n1. **Double transpose**: $(A^T)^T = A$\n2. **Sum**: $(A + B)^T = A^T + B^T$\n3. **Scalar multiplication**: $(cA)^T = cA^T$\n4. **Product**: $(AB)^T = B^T A^T$ (note the reversed order)\n5. **Symmetric matrix**: $A = A^T$ means $A$ is symmetric\n\n### Python Implementation\n\nUsing `zip(*matrix)` is a Pythonic way to transpose:\n- `*matrix` unpacks rows as separate arguments\n- `zip()` groups elements by position (first elements together, second elements together, etc.)\n- Convert each tuple to a list for the final result\n\n### Applications\n\n- **Linear algebra**: Solving systems of equations\n- **Machine learning**: Reshaping feature matrices, computing covariance matrices\n- **Computer graphics**: Transformation matrices\n- **Data processing**: Converting between row-major and column-major formats\n",
  "tinygrad_starter_code_decoded": "from tinygrad.tensor import Tensor\n\ndef transpose_matrix_tg(a:Tensor) -> Tensor:\n    \"\"\"\n    Transpose a 2D matrix `a` using tinygrad.\n    Inputs are tinygrad Tensors.\n    Returns a transposed Tensor.\n    \"\"\"\n    pass"
}