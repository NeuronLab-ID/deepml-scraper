{
  "description": "SW1wbGVtZW50IHRoZSBmb3J3YXJkIHBhc3Mgb2YgUUxvUkEgKFF1YW50aXplZCBMb3ctUmFuayBBZGFwdGF0aW9uKSwgYW4gZXh0ZW5zaW9uIG9mIExvUkEgdGhhdCBlbmFibGVzIGZpbmUtdHVuaW5nIG9mIGxhcmdlIGxhbmd1YWdlIG1vZGVscyBvbiBjb25zdW1lciBHUFVzIGJ5IHF1YW50aXppbmcgdGhlIGZyb3plbiBwcmV0cmFpbmVkIHdlaWdodHMgdG8gNC1iaXQgcHJlY2lzaW9uLiBUaGUgZnJvemVuIHdlaWdodHMgYXJlIHN0b3JlZCBpbiA0LWJpdCBmb3JtYXQgdG8gc2F2ZSBtZW1vcnksIGJ1dCBhcmUgZGVxdWFudGl6ZWQgdG8gZnVsbCBwcmVjaXNpb24gZHVyaW5nIHRoZSBmb3J3YXJkIHBhc3MuIFRoZSB0cmFpbmFibGUgTG9SQSBtYXRyaWNlcyAoQSBhbmQgQikgcmVtYWluIGluIGZ1bGwgcHJlY2lzaW9uLiBHaXZlbiBxdWFudGl6ZWQgd2VpZ2h0cyB3aXRoIHRoZWlyIHNjYWxlIGFuZCB6ZXJvX3BvaW50LCBhbG9uZyB3aXRoIExvUkEgbWF0cmljZXMsIGNvbXB1dGUgdGhlIG91dHB1dC4=",
  "id": "223",
  "test_cases": [
    {
      "test": "x = [[1.0, 2.0]]\nquantized_W = [[0, 10], [10, 0]]\nscale, zero_point = 0.1, 0.0\nB = [[0.5], [0.5]]\nA = [[1.0, 1.0]]\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=1.0)\nprint([[round(v, 4) for v in row] for row in result])",
      "expected_output": "[[3.5, 2.5]]"
    },
    {
      "test": "x = [[1.0, 0.0], [0.0, 1.0]]\nquantized_W = [[15, 5], [5, 15]]\nscale, zero_point = 0.2, 0.0\nB = [[1.0], [1.0]]\nA = [[0.5, 0.5]]\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=1.0)\nprint([[round(v, 4) for v in row] for row in result])",
      "expected_output": "[[3.5, 1.5], [1.5, 3.5]]"
    }
  ],
  "difficulty": "medium",
  "pytorch_difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "x = [[1.0, 2.0]], quantized_W = [[0, 10], [10, 0]], scale = 0.1, zero_point = 0.0, B, A, alpha = 1.0",
    "output": "[[3.5, 2.5]]",
    "reasoning": "First dequantize W: W = quantized_W * scale + zero_point = [[0, 1], [1, 0]]. Then compute the standard LoRA forward pass combining the frozen path (x @ W) with the low-rank adaptation path (x @ B @ A), scaled by alpha/rank."
  },
  "category": "Deep Learning",
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgcWxvcmFfZm9yd2FyZCgKICAgIHg6IHRvcmNoLlRlbnNvciwKICAgIHF1YW50aXplZF9XOiB0b3JjaC5UZW5zb3IsCiAgICBzY2FsZTogZmxvYXQsCiAgICB6ZXJvX3BvaW50OiBmbG9hdCwKICAgIEE6IHRvcmNoLlRlbnNvciwKICAgIEI6IHRvcmNoLlRlbnNvciwKICAgIGFscGhhOiBmbG9hdCA9IDEuMAopIC0+IHRvcmNoLlRlbnNvcjoKICAgICIiIgogICAgUUxvUkEgZm9yd2FyZCBwYXNzIHdpdGggcXVhbnRpemVkIGZyb3plbiB3ZWlnaHRzIHVzaW5nIFB5VG9yY2guCiAgICAKICAgIEFyZ3M6CiAgICAgICAgeDogSW5wdXQgdGVuc29yIChiYXRjaF9zaXplIHggaW5fZmVhdHVyZXMpCiAgICAgICAgcXVhbnRpemVkX1c6IDQtYml0IHF1YW50aXplZCB3ZWlnaHRzIGFzIGludGVnZXJzIChpbl9mZWF0dXJlcyB4IG91dF9mZWF0dXJlcykKICAgICAgICBzY2FsZTogUXVhbnRpemF0aW9uIHNjYWxlIGZhY3RvcgogICAgICAgIHplcm9fcG9pbnQ6IFF1YW50aXphdGlvbiB6ZXJvIHBvaW50CiAgICAgICAgQTogTG9SQSBtYXRyaXggQSAocmFuayB4IG91dF9mZWF0dXJlcykKICAgICAgICBCOiBMb1JBIG1hdHJpeCBCIChpbl9mZWF0dXJlcyB4IHJhbmspCiAgICAgICAgYWxwaGE6IExvUkEgc2NhbGluZyBmYWN0b3IKICAgICAgICAKICAgIFJldHVybnM6CiAgICAgICAgT3V0cHV0IHRlbnNvciAoYmF0Y2hfc2l6ZSB4IG91dF9mZWF0dXJlcykKICAgICIiIgogICAgIyBZb3VyIGNvZGUgaGVyZQogICAgcGFzcw==",
  "title": "QLoRA: Quantized Low-Rank Adaptation Forward Pass",
  "starter_code": "import numpy as np\n\ndef qlora_forward(\n\tx: list[list[float]],\n\tquantized_W: list[list[int]],\n\tscale: float,\n\tzero_point: float,\n\tA: list[list[float]],\n\tB: list[list[float]],\n\talpha: float = 1.0\n) -> list[list[float]]:\n\t\"\"\"\n\tQLoRA forward pass with 4-bit quantized frozen weights.\n\t\n\tArgs:\n\t\tx: Input matrix (batch_size x in_features)\n\t\tquantized_W: 4-bit quantized weights (in_features x out_features)\n\t\t             Values are integers that need to be dequantized\n\t\tscale: Quantization scale factor\n\t\tzero_point: Quantization zero point for dequantization\n\t\tA: LoRA matrix A (rank x out_features) - full precision\n\t\tB: LoRA matrix B (in_features x rank) - full precision\n\t\talpha: LoRA scaling factor\n\t\t\n\tReturns:\n\t\tOutput matrix (batch_size x out_features)\n\t\"\"\"\n\t# Your code here\n\tpass",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "pytorch_test_cases": [
    {
      "test": "import torch\nx = torch.tensor([[1.0, 2.0]])\nquantized_W = torch.tensor([[0, 10], [10, 0]])\nscale, zero_point = 0.1, 0.0\nB = torch.tensor([[0.5], [0.5]])\nA = torch.tensor([[1.0, 1.0]])\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=1.0)\nprint([[round(v, 4) for v in row.tolist()] for row in result])",
      "expected_output": "[[3.5, 2.5]]"
    },
    {
      "test": "import torch\nx = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\nquantized_W = torch.tensor([[15, 5], [5, 15]])\nscale, zero_point = 0.2, 0.0\nB = torch.tensor([[1.0], [1.0]])\nA = torch.tensor([[0.5, 0.5]])\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=1.0)\nprint([[round(v, 4) for v in row.tolist()] for row in result])",
      "expected_output": "[[3.5, 1.5], [1.5, 3.5]]"
    },
    {
      "test": "import torch\nx = torch.tensor([[2.0, 1.0]])\nquantized_W = torch.tensor([[10, 5], [5, 10]])\nscale, zero_point = 0.1, 0.0\nB = torch.tensor([[0.2], [0.2]])\nA = torch.tensor([[5.0, 5.0]])\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=2.0)\nprint([[round(v, 4) for v in row.tolist()] for row in result])",
      "expected_output": "[[8.5, 8.0]]"
    },
    {
      "test": "import torch\nx = torch.tensor([[1.0, 1.0]])\nquantized_W = torch.tensor([[5, 10], [10, 5]])\nscale, zero_point = 0.2, -1.0\nB = torch.tensor([[1.0], [1.0]])\nA = torch.tensor([[1.0, 2.0]])\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=1.0)\nprint([[round(v, 4) for v in row.tolist()] for row in result])",
      "expected_output": "[[3.0, 5.0]]"
    },
    {
      "test": "import torch\nx = torch.tensor([[1.0, 2.0, 3.0]])\nquantized_W = torch.tensor([[0, 5], [5, 10], [10, 15]])\nscale, zero_point = 0.2, 0.0\nB = torch.tensor([[0.1, 0.2], [0.2, 0.1], [0.1, 0.2]])\nA = torch.tensor([[1.0, 0.0], [0.0, 1.0]])\nresult = qlora_forward(x, quantized_W, scale, zero_point, A, B, alpha=2.0)\nprint([[round(v, 4) for v in row.tolist()] for row in result])",
      "expected_output": "[[8.8, 15.0]]"
    }
  ],
  "createdAt": "December 7, 2025 at 8:41:28 AM UTC-0500",
  "learn_section": "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",
  "description_decoded": "Implement the forward pass of QLoRA (Quantized Low-Rank Adaptation), an extension of LoRA that enables fine-tuning of large language models on consumer GPUs by quantizing the frozen pretrained weights to 4-bit precision. The frozen weights are stored in 4-bit format to save memory, but are dequantized to full precision during the forward pass. The trainable LoRA matrices (A and B) remain in full precision. Given quantized weights with their scale and zero_point, along with LoRA matrices, compute the output.",
  "learn_section_decoded": "## QLoRA: Quantized Low-Rank Adaptation\n\n### The Memory Problem\n\nEven with LoRA freezing the pretrained weights, those weights still consume massive memory. A 65B parameter model in 16-bit precision requires around 130GB just for storage - far exceeding consumer GPU capacity.\n\n### The QLoRA Solution\n\nQLoRA stores the frozen pretrained weights in 4-bit precision instead of 16-bit or 32-bit, reducing memory by 4-8x. The trainable LoRA matrices (A and B) remain in full precision since they need accurate gradients.\n\n### Understanding Quantization\n\nQuantization maps continuous floating-point values to discrete integer levels. With 4 bits, we have $2^4 = 16$ possible values (0 through 15).\n\n**Affine Quantization** uses two parameters:\n- **Scale** ($s$): The step size between quantization levels\n- **Zero Point** ($z$): An offset that shifts the quantization range\n\n### The Quantization Formula\n\nTo quantize a floating-point weight $w$ to an integer $w_q$:\n\n$$w_q = \\text{round}\\left(\\frac{w - z}{s}\\right)$$\n\nThe result is clipped to the valid range [0, 15] for 4-bit unsigned integers.\n\n### The Dequantization Formula\n\nTo recover an approximate floating-point value from a quantized integer:\n\n$$\\hat{w} = w_q \\cdot s + z$$\n\nNote that $\\hat{w} \\approx w$ but not exactly equal due to rounding. This small error is the trade-off for memory savings.\n\n### Example\n\nSuppose we have weights in the range [−1.0, 2.0]:\n- Scale: $s = \\frac{2.0 - (-1.0)}{15} = 0.2$\n- Zero point: $z = -1.0$\n\nTo quantize $w = 0.5$:\n$$w_q = \\text{round}\\left(\\frac{0.5 - (-1.0)}{0.2}\\right) = \\text{round}(7.5) = 8$$\n\nTo dequantize back:\n$$\\hat{w} = 8 \\times 0.2 + (-1.0) = 0.6$$\n\nThe small error (0.6 vs 0.5) is acceptable for frozen weights.\n\n### The QLoRA Forward Pass\n\nDuring forward computation:\n\n1. **Dequantize** the frozen weights: $W = W_q \\cdot s + z$\n\n2. **Compute** the standard LoRA forward pass using dequantized weights:\n$$h = xW + \\frac{\\alpha}{r} \\cdot xBA$$\n\nThe dequantization happens on-the-fly during each forward pass. Weights are stored as 4-bit integers but computed in full precision.\n\n### NormalFloat4 (NF4)\n\nStandard uniform quantization spaces levels evenly. But neural network weights typically follow a normal distribution - most values cluster near zero with fewer at the extremes.\n\nNF4 places quantization levels at the quantiles of a normal distribution, putting more levels where weights are dense. This preserves more information for the same number of bits.\n\n### Double Quantization\n\nEach block of weights (typically 64) has its own scale and zero point. These constants themselves consume memory. QLoRA applies a second level of quantization to these constants, storing them in 8-bit instead of 32-bit, saving additional memory.\n\n### Memory Comparison\n\nFor a 65B parameter model:\n- Full fine-tuning (FP16): ~780 GB (weights + optimizer + gradients)\n- LoRA (FP16 frozen): ~130 GB \n- QLoRA (4-bit frozen): ~33 GB\n\nQLoRA enables fine-tuning 65B models on a single 48GB GPU."
}