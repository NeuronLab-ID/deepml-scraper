{
  "mdx_file": "2416a2a2-3b84-4a4f-9706-27ec64420715.mdx",
  "tinygrad_starter_code": "ZnJvbSB0aW55Z3JhZC50ZW5zb3IgaW1wb3J0IFRlbnNvcgoKZGVmIG1hdHJpeF9kb3RfdmVjdG9yX3RnKGE6VGVuc29yLCBiOlRlbnNvcikgLT4gVGVuc29yOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBwcm9kdWN0IG9mIG1hdHJpeCBgYWAgYW5kIHZlY3RvciBgYmAgdXNpbmcgdGlueWdyYWQuCiAgICBXaWxsIGJlIHRpbnlncmFkIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMS1EIFRlbnNvciBvZiBsZW5ndGggbSwgb3IgVGVuc29yKC0xKSBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICBwYXNzCg==",
  "test_cases": [
    {
      "test": "print(matrix_dot_vector([[1, 2, 3], [2, 4, 5], [6, 8, 9]], [1, 2, 3]))",
      "expected_output": "[14, 25, 49]"
    },
    {
      "test": "print(matrix_dot_vector([[1, 2], [2, 4], [6, 8], [12, 4]], [1, 2, 3]))",
      "expected_output": "-1"
    }
  ],
  "pytorch_difficulty": "easy",
  "likes": "0",
  "video": "https://youtu.be/DNoLs5tTGAw?si=vpkPobZMA8YY10WY",
  "cuda_test_cases": [
    {
      "test": "#include <iostream>\n#include <vector>\n\nstd::vector<float> matrix_dot_vector(const std::vector<std::vector<float>>& matrix, const std::vector<float>& vec);\n\nint main() {\n    std::vector<std::vector<float>> matrix = {{1, 2, 3}, {2, 4, 5}, {6, 8, 9}};\n    std::vector<float> vec = {1, 2, 3};\n    auto result = matrix_dot_vector(matrix, vec);\n    std::cout << \"[\";\n    for (int i = 0; i < result.size(); i++) {\n        std::cout << result[i];\n        if (i < result.size() - 1) std::cout << \", \";\n    }\n    std::cout << \"]\" << std::endl;\n    return 0;\n}",
      "expected_output": "[14, 25, 49]"
    },
    {
      "test": "#include <iostream>\n#include <vector>\n\nstd::vector<float> matrix_dot_vector(const std::vector<std::vector<float>>& matrix, const std::vector<float>& vec);\n\nint main() {\n    std::vector<std::vector<float>> matrix = {{1, 2}, {2, 4}, {6, 8}, {12, 4}};\n    std::vector<float> vec = {1, 2, 3};\n    auto result = matrix_dot_vector(matrix, vec);\n    std::cout << result[0] << std::endl;\n    return 0;\n}",
      "expected_output": "-1"
    },
    {
      "test": "#include <iostream>\n#include <vector>\n\nstd::vector<float> matrix_dot_vector(const std::vector<std::vector<float>>& matrix, const std::vector<float>& vec);\n\nint main() {\n    std::vector<std::vector<float>> matrix = {{1.5f, 2.5f}, {3.0f, 4.0f}};\n    std::vector<float> vec = {2, 1};\n    auto result = matrix_dot_vector(matrix, vec);\n    std::cout << \"[\" << result[0] << \", \" << result[1] << \"]\" << std::endl;\n    return 0;\n}",
      "expected_output": "[5.5, 10]"
    }
  ],
  "example": {
    "input": "a = [[1, 2], [2, 4]], b = [1, 2]",
    "output": "[5, 10]",
    "reasoning": "Row 1: (1 * 1) + (2 * 2) = 1 + 4 = 5; Row 2: (2 * 1) + (4 * 2) = 2 + 8 = 10"
  },
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbWF0cml4X2RvdF92ZWN0b3IoYSwgYikgLT4gdG9yY2guVGVuc29yOgogICAgIiIiCiAgICBDb21wdXRlIHRoZSBwcm9kdWN0IG9mIG1hdHJpeCBgYWAgYW5kIHZlY3RvciBgYmAgdXNpbmcgUHlUb3JjaC4KICAgIElucHV0cyBjYW4gYmUgUHl0aG9uIGxpc3RzLCBOdW1QeSBhcnJheXMsIG9yIHRvcmNoIFRlbnNvcnMuCiAgICBSZXR1cm5zIGEgMS1EIHRlbnNvciBvZiBsZW5ndGggbSwgb3IgdGVuc29yKC0xKSBpZiBkaW1lbnNpb25zIG1pc21hdGNoLgogICAgIiIiCiAgICBhX3QgPSB0b3JjaC5hc190ZW5zb3IoYSwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICBiX3QgPSB0b3JjaC5hc190ZW5zb3IoYiwgZHR5cGU9dG9yY2guZmxvYXQpCiAgICAjIERpbWVuc2lvbiBtaXNtYXRjaCBjaGVjawogICAgaWYgYV90LnNpemUoMSkgIT0gYl90LnNpemUoMCk6CiAgICAgICAgcmV0dXJuIHRvcmNoLnRlbnNvcigtMSkKICAgICMgWW91ciBpbXBsZW1lbnRhdGlvbiBoZXJlCiAgICBwYXNzCg==",
  "learn_section": "CiMjIE1hdHJpeC1WZWN0b3IgRG90IFByb2R1Y3QKCkNvbnNpZGVyIGEgbWF0cml4ICRBJCBhbmQgYSB2ZWN0b3IgJHYkOgoKKipNYXRyaXggJEEkIChuIHggbSk6KioKJCQKQSA9IFxiZWdpbntwbWF0cml4fQphX3sxMX0gJiBhX3sxMn0gJiBcY2RvdHMgJiBhX3sxbX0gXFwKYV97MjF9ICYgYV97MjJ9ICYgXGNkb3RzICYgYV97Mm19IFxcClx2ZG90cyAmIFx2ZG90cyAmIFxkZG90cyAmIFx2ZG90cyBcXAphX3tuMX0gJiBhX3tuMn0gJiBcY2RvdHMgJiBhX3tubX0KXGVuZHtwbWF0cml4fQokJAoKKipWZWN0b3IgJHYkIChsZW5ndGggbSk6KioKJCQKdiA9IFxiZWdpbntwbWF0cml4fQp2XzEgXFwKdl8yIFxcClx2ZG90cyBcXAp2X20KXGVuZHtwbWF0cml4fQokJAoKVGhlIGRvdCBwcm9kdWN0ICRBIFxjZG90IHYkIHByb2R1Y2VzIGEgbmV3IHZlY3RvciBvZiBsZW5ndGggJG4kOgokJApBIFxjZG90IHYgPSBcYmVnaW57cG1hdHJpeH0KYV97MTF9dl8xICsgYV97MTJ9dl8yICsgXGNkb3RzICsgYV97MW19dl9tIFxcCmFfezIxfXZfMSArIGFfezIyfXZfMiArIFxjZG90cyArIGFfezJtfXZfbSBcXApcdmRvdHMgXFwKYV97bjF9dl8xICsgYV97bjJ9dl8yICsgXGNkb3RzICsgYV97bm19dl9tClxlbmR7cG1hdHJpeH0KJCQKCiMjIyBLZXkgUmVxdWlyZW1lbnQ6ClRoZSBudW1iZXIgb2YgY29sdW1ucyBpbiB0aGUgbWF0cml4ICgkbSQpIG11c3QgZXF1YWwgdGhlIGxlbmd0aCBvZiB0aGUgdmVjdG9yICgkbSQpLiBJZiBub3QsIHRoZSBvcGVyYXRpb24gaXMgdW5kZWZpbmVkLCBhbmQgdGhlIGZ1bmN0aW9uIHNob3VsZCByZXR1cm4gLTEu",
  "cuda_starter_code": "I2luY2x1ZGUgPGN1ZGFfcnVudGltZS5oPgojaW5jbHVkZSA8aW9zdHJlYW0+CiNpbmNsdWRlIDx2ZWN0b3I+CgpfX2dsb2JhbF9fIHZvaWQgbWF0cml4X3ZlY3Rvcl9kb3Rfa2VybmVsKAogICAgY29uc3QgZmxvYXQqIG1hdHJpeCwKICAgIGNvbnN0IGZsb2F0KiB2ZWN0b3IsCiAgICBmbG9hdCogcmVzdWx0LAogICAgaW50IHJvd3MsCiAgICBpbnQgY29scwopIHsKICAgIC8vIEltcGxlbWVudCB0aGUga2VybmVsIHRvIGNvbXB1dGUgbWF0cml4LXZlY3RvciBkb3QgcHJvZHVjdAogICAgLy8gRWFjaCB0aHJlYWQgY29tcHV0ZXMgb25lIGVsZW1lbnQgb2YgdGhlIHJlc3VsdCB2ZWN0b3IKfQoKc3RkOjp2ZWN0b3I8ZmxvYXQ+IG1hdHJpeF9kb3RfdmVjdG9yKGNvbnN0IHN0ZDo6dmVjdG9yPHN0ZDo6dmVjdG9yPGZsb2F0Pj4mIG1hdHJpeCwgY29uc3Qgc3RkOjp2ZWN0b3I8ZmxvYXQ+JiB2ZWMpIHsKICAgIC8vIFJldHVybiBlbXB0eSB2ZWN0b3IgaWYgZGltZW5zaW9ucyBkb24ndCBtYXRjaAogICAgLy8gMS4gQWxsb2NhdGUgZGV2aWNlIG1lbW9yeQogICAgLy8gMi4gQ29weSBkYXRhIHRvIGRldmljZQogICAgLy8gMy4gTGF1bmNoIGtlcm5lbAogICAgLy8gNC4gQ29weSByZXN1bHQgYmFjawogICAgLy8gNS4gRnJlZSBtZW1vcnkgYW5kIHJldHVybiByZXN1bHQKICAgIHJldHVybiB7fTsKfQ==",
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "Moe Chabot"
    }
  ],
  "tinygrad_test_cases": [
    {
      "test": "from tinygrad.tensor import Tensor\nres = matrix_dot_vector_tg(\n    Tensor([[1,2,3],[2,4,5],[6,8,9]]),\n    Tensor([1,2,3])\n)\nprint(res.numpy().tolist())",
      "expected_output": "[14.0, 25.0, 49.0]"
    },
    {
      "test": "from tinygrad.tensor import Tensor\nres = matrix_dot_vector_tg(\n    Tensor([[1,2,3],[2,4,5]]),\n    Tensor([1,2])\n)\nprint(res.numpy().tolist())",
      "expected_output": "-1"
    },
    {
      "test": "from tinygrad.tensor import Tensor\nres = matrix_dot_vector_tg(\n    Tensor([[1, 2], [2, 4]]),\n    Tensor([1, 2])\n)\nprint(res.numpy().tolist())",
      "expected_output": "[5, 10]"
    }
  ],
  "description": "V3JpdGUgYSBQeXRob24gZnVuY3Rpb24gdGhhdCBjb21wdXRlcyB0aGUgZG90IHByb2R1Y3Qgb2YgYSBtYXRyaXggYW5kIGEgdmVjdG9yLiBUaGUgZnVuY3Rpb24gc2hvdWxkIHJldHVybiBhIGxpc3QgcmVwcmVzZW50aW5nIHRoZSByZXN1bHRpbmcgdmVjdG9yIGlmIHRoZSBvcGVyYXRpb24gaXMgdmFsaWQsIG9yIC0xIGlmIHRoZSBtYXRyaXggYW5kIHZlY3RvciBkaW1lbnNpb25zIGFyZSBpbmNvbXBhdGlibGUuIEEgbWF0cml4IChhIGxpc3Qgb2YgbGlzdHMpIGNhbiBiZSBkb3R0ZWQgd2l0aCBhIHZlY3RvciAoYSBsaXN0KSBvbmx5IGlmIHRoZSBudW1iZXIgb2YgY29sdW1ucyBpbiB0aGUgbWF0cml4IGVxdWFscyB0aGUgbGVuZ3RoIG9mIHRoZSB2ZWN0b3IuIEZvciBleGFtcGxlLCBhbiBuIHggbSBtYXRyaXggcmVxdWlyZXMgYSB2ZWN0b3Igb2YgbGVuZ3RoIG0u",
  "id": "1",
  "tinygrad_difficulty": "easy",
  "difficulty": "easy",
  "cuda_difficulty": "medium",
  "dislikes": "0",
  "category": "Linear Algebra",
  "starter_code": "def matrix_dot_vector(a: list[list[int|float]], b: list[int|float]) -> list[int|float]:\n\t# Return a list where each element is the dot product of a row of 'a' with 'b'.\n\t# If the number of columns in 'a' does not match the length of 'b', return -1.\n\tpass",
  "title": "Matrix-Vector Dot Product",
  "createdAt": "December 15, 2025 at 7:00:52â€¯AM UTC-0500",
  "pytorch_test_cases": [
    {
      "test": "import torch\nres = matrix_dot_vector(\n    torch.tensor([[1,2,3],[2,4,5],[6,8,9]], dtype=torch.float),\n    torch.tensor([1,2,3], dtype=torch.float)\n)\nprint(res.numpy().tolist())",
      "expected_output": "[14.0, 25.0, 49.0]"
    },
    {
      "test": "import torch\nres = matrix_dot_vector(\n    torch.tensor([[1,2,3],[2,4,5]], dtype=torch.float),\n    torch.tensor([1,2], dtype=torch.float)\n)\nprint(res.numpy().tolist())",
      "expected_output": "-1"
    }
  ],
  "description_decoded": "Write a Python function that computes the dot product of a matrix and a vector. The function should return a list representing the resulting vector if the operation is valid, or -1 if the matrix and vector dimensions are incompatible. A matrix (a list of lists) can be dotted with a vector (a list) only if the number of columns in the matrix equals the length of the vector. For example, an n x m matrix requires a vector of length m.",
  "learn_section_decoded": "\n## Matrix-Vector Dot Product\n\nConsider a matrix $A$ and a vector $v$:\n\n**Matrix $A$ (n x m):**\n$$\nA = \\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1m} \\\\\na_{21} & a_{22} & \\cdots & a_{2m} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{n1} & a_{n2} & \\cdots & a_{nm}\n\\end{pmatrix}\n$$\n\n**Vector $v$ (length m):**\n$$\nv = \\begin{pmatrix}\nv_1 \\\\\nv_2 \\\\\n\\vdots \\\\\nv_m\n\\end{pmatrix}\n$$\n\nThe dot product $A \\cdot v$ produces a new vector of length $n$:\n$$\nA \\cdot v = \\begin{pmatrix}\na_{11}v_1 + a_{12}v_2 + \\cdots + a_{1m}v_m \\\\\na_{21}v_1 + a_{22}v_2 + \\cdots + a_{2m}v_m \\\\\n\\vdots \\\\\na_{n1}v_1 + a_{n2}v_2 + \\cdots + a_{nm}v_m\n\\end{pmatrix}\n$$\n\n### Key Requirement:\nThe number of columns in the matrix ($m$) must equal the length of the vector ($m$). If not, the operation is undefined, and the function should return -1.",
  "tinygrad_starter_code_decoded": "from tinygrad.tensor import Tensor\n\ndef matrix_dot_vector_tg(a:Tensor, b:Tensor) -> Tensor:\n    \"\"\"\n    Compute the product of matrix `a` and vector `b` using tinygrad.\n    Will be tinygrad Tensors.\n    Returns a 1-D Tensor of length m, or Tensor(-1) if dimensions mismatch.\n    \"\"\"\n    pass\n"
}