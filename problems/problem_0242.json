{
  "description": "IyMgVGFzazogSW1wbGVtZW50IE5vbi1NYXhpbXVtIFN1cHByZXNzaW9uIChOTVMpCgpOb24tTWF4aW11bSBTdXBwcmVzc2lvbiBpcyBhIGNyaXRpY2FsIHBvc3QtcHJvY2Vzc2luZyB0ZWNobmlxdWUgaW4gb2JqZWN0IGRldGVjdGlvbiBwaXBlbGluZXMuIFdoZW4gb2JqZWN0IGRldGVjdG9ycyBsaWtlIFlPTE8sIFNTRCwgb3IgRmFzdGVyIFItQ05OIGdlbmVyYXRlIHByZWRpY3Rpb25zLCB0aGV5IG9mdGVuIHByb2R1Y2UgbXVsdGlwbGUgb3ZlcmxhcHBpbmcgYm91bmRpbmcgYm94ZXMgZm9yIHRoZSBzYW1lIG9iamVjdC4gTk1TIGZpbHRlcnMgdGhlc2UgcmVkdW5kYW50IGRldGVjdGlvbnMgYnkga2VlcGluZyBvbmx5IHRoZSBtb3N0IGNvbmZpZGVudCBib3ggYW5kIHN1cHByZXNzaW5nIGJveGVzIHRoYXQgc2lnbmlmaWNhbnRseSBvdmVybGFwIHdpdGggaXQuCgojIyMgSW5wdXQ6Ci0gYGJveGVzYDogQW4gYXJyYXktbGlrZSBvZiBzaGFwZSAoTiwgNCkgY29udGFpbmluZyBOIGJvdW5kaW5nIGJveGVzIGluIGZvcm1hdCBbeDEsIHkxLCB4MiwgeTJdIHdoZXJlICh4MSwgeTEpIGlzIHRoZSB0b3AtbGVmdCBjb3JuZXIgYW5kICh4MiwgeTIpIGlzIHRoZSBib3R0b20tcmlnaHQgY29ybmVyCi0gYHNjb3Jlc2A6IEFuIGFycmF5LWxpa2Ugb2Ygc2hhcGUgKE4sKSBjb250YWluaW5nIGNvbmZpZGVuY2Ugc2NvcmVzIGZvciBlYWNoIGJveAotIGBpb3VfdGhyZXNob2xkYDogQSBmbG9hdCBiZXR3ZWVuIDAgYW5kIDEgc3BlY2lmeWluZyB0aGUgSW50ZXJzZWN0aW9uIG92ZXIgVW5pb24gdGhyZXNob2xkIGZvciBzdXBwcmVzc2lvbgoKIyMjIE91dHB1dDoKLSBSZXR1cm4gYSBsaXN0IG9mIGluZGljZXMgb2YgdGhlIGtlcHQgYm94ZXMsIG9yZGVyZWQgYnkgZGVzY2VuZGluZyBjb25maWRlbmNlIHNjb3JlCi0gUmV0dXJuIC0xIGZvciBpbnZhbGlkIGlucHV0cyAobWlzbWF0Y2hlZCBkaW1lbnNpb25zLCBpbnZhbGlkIHNoYXBlcywgdGhyZXNob2xkIG91dCBvZiByYW5nZSkKLSBSZXR1cm4gZW1wdHkgbGlzdCBmb3IgZW1wdHkgaW5wdXQKCiMjIyBBbGdvcml0aG0gT3ZlcnZpZXc6CjEuIFNlbGVjdCB0aGUgYm94IHdpdGggdGhlIGhpZ2hlc3QgY29uZmlkZW5jZSBzY29yZQoyLiBSZW1vdmUgYWxsIGJveGVzIHRoYXQgaGF2ZSBoaWdoIElvVSBvdmVybGFwIHdpdGggdGhlIHNlbGVjdGVkIGJveAozLiBSZXBlYXQgdW50aWwgbm8gYm94ZXMgcmVtYWluCgojIyMgSW9VIChJbnRlcnNlY3Rpb24gb3ZlciBVbmlvbik6ClRoZSBJb1UgYmV0d2VlbiB0d28gYm94ZXMgbWVhc3VyZXMgdGhlaXIgb3ZlcmxhcCBhbmQgaXMgY29tcHV0ZWQgYXMgdGhlIGFyZWEgb2YgaW50ZXJzZWN0aW9uIGRpdmlkZWQgYnkgdGhlIGFyZWEgb2YgdW5pb24u",
  "id": "242",
  "test_cases": [
    {
      "test": "boxes = [[0, 0, 10, 10], [1, 1, 11, 11], [20, 20, 30, 30], [21, 21, 31, 31]]\nscores = [0.9, 0.8, 0.95, 0.7]\nprint(non_maximum_suppression(boxes, scores, 0.5))",
      "expected_output": "[2, 0]"
    },
    {
      "test": "boxes = [[0, 0, 10, 10], [0, 0, 10, 10], [0, 0, 10, 10]]\nscores = [0.9, 0.8, 0.7]\nprint(non_maximum_suppression(boxes, scores, 0.5))",
      "expected_output": "[0]"
    }
  ],
  "difficulty": "hard",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "boxes = [[0, 0, 10, 10], [1, 1, 11, 11], [20, 20, 30, 30], [21, 21, 31, 31]]\nscores = [0.9, 0.8, 0.95, 0.7]\niou_threshold = 0.5",
    "output": "[2, 0]",
    "reasoning": "Box 2 (score 0.95) at [20,20,30,30] is selected first as it has the highest score. Box 3 (score 0.7) overlaps significantly with Box 2 (IoU = 81/119 = 0.68 > 0.5), so it is suppressed. Box 0 (score 0.9) at [0,0,10,10] is selected next. Box 1 (score 0.8) overlaps significantly with Box 0 (IoU = 81/119 = 0.68 > 0.5), so it is suppressed. Final result: indices [2, 0]."
  },
  "category": "Computer Vision",
  "starter_code": "import numpy as np\n\ndef non_maximum_suppression(boxes, scores, iou_threshold):\n    \"\"\"\n    Apply Non-Maximum Suppression (NMS) to bounding boxes.\n    \n    Args:\n        boxes: Array-like of shape (N, 4) with boxes in format [x1, y1, x2, y2]\n        scores: Array-like of shape (N,) with confidence scores\n        iou_threshold: float, IoU threshold for suppression (0 to 1)\n    \n    Returns:\n        List of indices of kept boxes, ordered by descending score\n        Returns -1 for invalid inputs\n    \"\"\"\n    # Your code here\n    pass",
  "title": "Non-Maximum Suppression for Object Detection",
  "createdAt": "December 14, 2025 at 11:33:11â€¯AM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "learn_section": "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",
  "description_decoded": "## Task: Implement Non-Maximum Suppression (NMS)\n\nNon-Maximum Suppression is a critical post-processing technique in object detection pipelines. When object detectors like YOLO, SSD, or Faster R-CNN generate predictions, they often produce multiple overlapping bounding boxes for the same object. NMS filters these redundant detections by keeping only the most confident box and suppressing boxes that significantly overlap with it.\n\n### Input:\n- `boxes`: An array-like of shape (N, 4) containing N bounding boxes in format [x1, y1, x2, y2] where (x1, y1) is the top-left corner and (x2, y2) is the bottom-right corner\n- `scores`: An array-like of shape (N,) containing confidence scores for each box\n- `iou_threshold`: A float between 0 and 1 specifying the Intersection over Union threshold for suppression\n\n### Output:\n- Return a list of indices of the kept boxes, ordered by descending confidence score\n- Return -1 for invalid inputs (mismatched dimensions, invalid shapes, threshold out of range)\n- Return empty list for empty input\n\n### Algorithm Overview:\n1. Select the box with the highest confidence score\n2. Remove all boxes that have high IoU overlap with the selected box\n3. Repeat until no boxes remain\n\n### IoU (Intersection over Union):\nThe IoU between two boxes measures their overlap and is computed as the area of intersection divided by the area of union.",
  "learn_section_decoded": "## Non-Maximum Suppression (NMS) in Object Detection\n\nNon-Maximum Suppression is a fundamental post-processing technique used in virtually all modern object detection systems. When neural networks detect objects, they typically produce multiple overlapping bounding boxes for the same object instance. NMS eliminates these redundant detections.\n\n### The Core Problem\n\nObject detectors often use a sliding window approach or anchor boxes, generating predictions at multiple scales and locations. This results in many overlapping boxes around the same object:\n\n- A car might have 10+ overlapping detections\n- Each detection has a confidence score\n- We want to keep only the best detection\n\n### Intersection over Union (IoU)\n\nThe IoU metric measures how much two bounding boxes overlap:\n\n$$\\text{IoU}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} = \\frac{\\text{Area of Intersection}}{\\text{Area of Union}}$$\n\nFor two boxes with coordinates $[x_1^A, y_1^A, x_2^A, y_2^A]$ and $[x_1^B, y_1^B, x_2^B, y_2^B]$:\n\n**Intersection coordinates:**\n$$x_1^{\\cap} = \\max(x_1^A, x_1^B), \\quad y_1^{\\cap} = \\max(y_1^A, y_1^B)$$\n$$x_2^{\\cap} = \\min(x_2^A, x_2^B), \\quad y_2^{\\cap} = \\min(y_2^A, y_2^B)$$\n\n**Intersection area:**\n$$\\text{Area}_{\\cap} = \\max(0, x_2^{\\cap} - x_1^{\\cap}) \\times \\max(0, y_2^{\\cap} - y_1^{\\cap})$$\n\n**Union area:**\n$$\\text{Area}_{\\cup} = \\text{Area}_A + \\text{Area}_B - \\text{Area}_{\\cap}$$\n\n### The NMS Algorithm\n\n1. **Sort** all boxes by confidence score in descending order\n2. **Select** the box with the highest score and add it to the output\n3. **Compute** IoU between the selected box and all remaining boxes\n4. **Remove** boxes with IoU > threshold (they likely detect the same object)\n5. **Repeat** from step 2 until no boxes remain\n\n### Algorithm Complexity\n\n- **Time complexity**: $O(N^2)$ where $N$ is the number of boxes (comparing each pair)\n- **Space complexity**: $O(N)$ for storing indices and intermediate results\n\n### IoU Threshold Selection\n\n- **Low threshold (0.3-0.4)**: Aggressive suppression, fewer boxes kept\n- **Standard threshold (0.5)**: Balanced approach, common default\n- **High threshold (0.7-0.8)**: Conservative suppression, more boxes kept\n\n### Variants of NMS\n\n1. **Soft-NMS**: Instead of hard removal, decreases scores of overlapping boxes: $s_i = s_i \\cdot e^{-\\text{IoU}^2/\\sigma}$\n\n2. **Weighted NMS**: Combines overlapping boxes using weighted average based on scores\n\n3. **DIoU-NMS**: Uses Distance-IoU considering box center distance\n\n### Applications\n\n- **YOLO, SSD, Faster R-CNN**: All use NMS as post-processing\n- **Face detection**: Remove duplicate face boxes\n- **Pedestrian detection**: Critical for autonomous driving\n- **Text detection**: OCR pipelines use NMS for text regions"
}