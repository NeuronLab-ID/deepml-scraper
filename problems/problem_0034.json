{
  "description": "V3JpdGUgYSBQeXRob24gZnVuY3Rpb24gdG8gcGVyZm9ybSBvbmUtaG90IGVuY29kaW5nIG9mIG5vbWluYWwgdmFsdWVzLiBUaGUgZnVuY3Rpb24gc2hvdWxkIHRha2UgaW4gYSAxRCBudW1weSBhcnJheSB4IG9mIGludGVnZXIgdmFsdWVzIGFuZCBhbiBvcHRpb25hbCBpbnRlZ2VyIG5fY29sIHJlcHJlc2VudGluZyB0aGUgbnVtYmVyIG9mIGNvbHVtbnMgZm9yIHRoZSBvbmUtaG90IGVuY29kZWQgYXJyYXkuIElmIG5fY29sIGlzIG5vdCBwcm92aWRlZCwgaXQgc2hvdWxkIGJlIGF1dG9tYXRpY2FsbHkgZGV0ZXJtaW5lZCBmcm9tIHRoZSBpbnB1dCBhcnJheS4=",
  "mdx_file": "62e9bd5d-ae0e-4c48-a5e2-0653437f196c.mdx",
  "test_cases": [
    {
      "test": "print(to_categorical(np.array([0, 1, 2, 1, 0])))",
      "expected_output": "[[1., 0., 0.], [0., 1., 0.], [0., 0., 1.], [0., 1., 0.], [1., 0., 0.]]"
    },
    {
      "test": "print(to_categorical(np.array([3, 1, 2, 1, 3]), 4))",
      "expected_output": "[[0., 0., 0., 1.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 1., 0., 0.], [0., 0., 0., 1.]]"
    }
  ],
  "difficulty": "easy",
  "pytorch_difficulty": "easy",
  "video": "",
  "likes": "0",
  "example": {
    "input": "x = np.array([0, 1, 2, 1, 0])\n    output = to_categorical(x)\n    print(output)",
    "output": "# [[1. 0. 0.]\n    #  [0. 1. 0.]\n    #  [0. 0. 1.]\n    #  [0. 1. 0.]\n    #  [1. 0. 0.]]",
    "reasoning": "Each element in the input array is transformed into a one-hot encoded vector,\n    where the index corresponding to the value in the input array is set to 1, \n    and all other indices are set to 0."
  },
  "dislikes": "0",
  "category": "Machine Learning",
  "starter_code": "import numpy as np\n\ndef to_categorical(x, n_col=None):\n\t# Your code here\n\tpass",
  "title": "One-Hot Encoding of Nominal Values",
  "learn_section": "CiMjIFVuZGVyc3RhbmRpbmcgT25lLUhvdCBFbmNvZGluZwoKT25lLWhvdCBlbmNvZGluZyBpcyBhIG1ldGhvZCB1c2VkIHRvIHJlcHJlc2VudCBjYXRlZ29yaWNhbCB2YXJpYWJsZXMgYXMgYmluYXJ5IHZlY3RvcnMuIFRoaXMgdGVjaG5pcXVlIGlzIHVzZWZ1bCBpbiBtYWNoaW5lIGxlYXJuaW5nIHdoZW4gZGVhbGluZyB3aXRoIGNhdGVnb3JpY2FsIGRhdGEgdGhhdCBoYXMgbm8gb3JkaW5hbCByZWxhdGlvbnNoaXAuCgojIyMgRXhwbGFuYXRpb24KSW4gb25lLWhvdCBlbmNvZGluZywgZWFjaCBjYXRlZ29yeSBpcyByZXByZXNlbnRlZCBieSBhIGJpbmFyeSB2ZWN0b3Igd2l0aCBhIGxlbmd0aCBlcXVhbCB0byB0aGUgbnVtYmVyIG9mIGNhdGVnb3JpZXMuIFRoZSB2ZWN0b3IgaGFzIGEgdmFsdWUgb2YgMSBhdCB0aGUgaW5kZXggY29ycmVzcG9uZGluZyB0byB0aGUgY2F0ZWdvcnkgYW5kIDAgYXQgYWxsIG90aGVyIGluZGljZXMuCgojIyMgRXhhbXBsZQpGb3IgaW5zdGFuY2UsIGlmIHlvdSBoYXZlIHRocmVlIGNhdGVnb3JpZXM6IDAsIDEsIGFuZCAyLCB0aGUgb25lLWhvdCBlbmNvZGVkIHZlY3RvcnMgd291bGQgYmU6Ci0gKiowKio6ICRbMSwgMCwgMF0kCi0gKioxKio6ICRbMCwgMSwgMF0kCi0gKioyKio6ICRbMCwgMCwgMV0kCgpUaGlzIG1ldGhvZCBlbnN1cmVzIHRoYXQgdGhlIG1vZGVsIGRvZXMgbm90IGFzc3VtZSBhbnkgb3JkaW5hbCByZWxhdGlvbnNoaXAgYmV0d2VlbiBjYXRlZ29yaWVzLCB3aGljaCBpcyBjcnVjaWFsIGZvciBtYW55IG1hY2hpbmUgbGVhcm5pbmcgYWxnb3JpdGhtcy4KCiMjIyBNYXRoZW1hdGljYWwgUmVwcmVzZW50YXRpb24KVGhlIG9uZS1ob3QgZW5jb2RpbmcgcHJvY2VzcyBjYW4gYmUgbWF0aGVtYXRpY2FsbHkgcmVwcmVzZW50ZWQgYXMgZm9sbG93czoKCkdpdmVuIGEgY2F0ZWdvcnkgJHhfaSQgZnJvbSBhIHNldCBvZiBjYXRlZ29yaWVzICRcezAsIDEsIFxsZG90cywgbi0xXH0kLCB0aGUgb25lLWhvdCBlbmNvZGVkIHZlY3RvciAkXG1hdGhiZnt2fSQgaXM6CiQkClxtYXRoYmZ7dn1faSA9IApcYmVnaW57Y2FzZXN9IAoxICYgXHRleHR7aWYgfSBpID0geF9pIFxcCjAgJiBcdGV4dHtvdGhlcndpc2V9ClxlbmR7Y2FzZXN9CiQkCgpUaGlzIHZlY3RvciAkXG1hdGhiZnt2fSQgd2lsbCBoYXZlIGEgbGVuZ3RoIGVxdWFsIHRvIHRoZSBudW1iZXIgb2YgdW5pcXVlIGNhdGVnb3JpZXMuCg==",
  "contributor": null,
  "pytorch_test_cases": [
    {
      "test": "import numpy as np, torch; from __main__ import to_categorical; x = torch.tensor([0,1,2,1,0]); out = to_categorical(x); print(out.numpy())",
      "expected_output": "[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 1. 0.]\n [1. 0. 0.]]"
    },
    {
      "test": "import numpy as np, torch; from __main__ import to_categorical; x = torch.tensor([3,1,2,1,3]); out = to_categorical(x, 4); print(out.numpy())",
      "expected_output": "[[0. 0. 0. 1.]\n [0. 1. 0. 0.]\n [0. 0. 1. 0.]\n [0. 1. 0. 0.]\n [0. 0. 0. 1.]]"
    }
  ],
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmZyb20gdHlwaW5nIGltcG9ydCBPcHRpb25hbAoKZGVmIHRvX2NhdGVnb3JpY2FsKHg6IHRvcmNoLlRlbnNvciwgbl9jb2w6IE9wdGlvbmFsW2ludF0gPSBOb25lKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIFBlcmZvcm0gb25lLWhvdCBlbmNvZGluZyBvbiBhIDFEIGludGVnZXIgdGVuc29yIGB4YC4gSWYgYG5fY29sYCBpcyBub3QgcHJvdmlkZWQsIGluZmVyIGl0IGZyb20gdGhlIG1heCB2YWx1ZSBpbiBgeGAuCiAgICAiIiIKICAgICMgSGludDogWW91IGNhbiB1c2UgdG9yY2gubm4uZnVuY3Rpb25hbC5vbmVfaG90CiAgICBwYXNzCg==",
  "description_decoded": "Write a Python function to perform one-hot encoding of nominal values. The function should take in a 1D numpy array x of integer values and an optional integer n_col representing the number of columns for the one-hot encoded array. If n_col is not provided, it should be automatically determined from the input array.",
  "learn_section_decoded": "\n## Understanding One-Hot Encoding\n\nOne-hot encoding is a method used to represent categorical variables as binary vectors. This technique is useful in machine learning when dealing with categorical data that has no ordinal relationship.\n\n### Explanation\nIn one-hot encoding, each category is represented by a binary vector with a length equal to the number of categories. The vector has a value of 1 at the index corresponding to the category and 0 at all other indices.\n\n### Example\nFor instance, if you have three categories: 0, 1, and 2, the one-hot encoded vectors would be:\n- **0**: $[1, 0, 0]$\n- **1**: $[0, 1, 0]$\n- **2**: $[0, 0, 1]$\n\nThis method ensures that the model does not assume any ordinal relationship between categories, which is crucial for many machine learning algorithms.\n\n### Mathematical Representation\nThe one-hot encoding process can be mathematically represented as follows:\n\nGiven a category $x_i$ from a set of categories $\\{0, 1, \\ldots, n-1\\}$, the one-hot encoded vector $\\mathbf{v}$ is:\n$$\n\\mathbf{v}_i = \n\\begin{cases} \n1 & \\text{if } i = x_i \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nThis vector $\\mathbf{v}$ will have a length equal to the number of unique categories.\n"
}