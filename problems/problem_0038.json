{
  "description": "V3JpdGUgYSBQeXRob24gZnVuY3Rpb24gYGFkYWJvb3N0X2ZpdGAgdGhhdCBpbXBsZW1lbnRzIHRoZSBmaXQgbWV0aG9kIGZvciBhbiBBZGFCb29zdCBjbGFzc2lmaWVyLiBUaGUgZnVuY3Rpb24gc2hvdWxkIHRha2UgaW4gYSAyRCBudW1weSBhcnJheSBgWGAgb2Ygc2hhcGUgYChuX3NhbXBsZXMsIG5fZmVhdHVyZXMpYCByZXByZXNlbnRpbmcgdGhlIGRhdGFzZXQsIGEgMUQgbnVtcHkgYXJyYXkgYHlgIG9mIHNoYXBlIGAobl9zYW1wbGVzLClgIHJlcHJlc2VudGluZyB0aGUgbGFiZWxzLCBhbmQgYW4gaW50ZWdlciBgbl9jbGZgIHJlcHJlc2VudGluZyB0aGUgbnVtYmVyIG9mIGNsYXNzaWZpZXJzLiBUaGUgZnVuY3Rpb24gc2hvdWxkIGluaXRpYWxpemUgc2FtcGxlIHdlaWdodHMsIGZpbmQgdGhlIGJlc3QgdGhyZXNob2xkcyBmb3IgZWFjaCBmZWF0dXJlLCBjYWxjdWxhdGUgdGhlIGVycm9yLCB1cGRhdGUgd2VpZ2h0cywgYW5kIHJldHVybiBhIGxpc3Qgb2YgY2xhc3NpZmllcnMgd2l0aCB0aGVpciBwYXJhbWV0ZXJzLg==",
  "mdx_file": "12dafded-0efd-4fa3-b7ed-ee6de40f4f1e.mdx",
  "id": "38",
  "test_cases": [
    {
      "test": "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\ny = np.array([1, 1, -1, -1])\nn_clf = 3\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
      "expected_output": "[{'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 11.512925464970229}]"
    },
    {
      "test": "X = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\ny = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\nn_clf = 2\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
      "expected_output": "[{'polarity': 1, 'threshold': 5, 'feature_index': 0, 'alpha': 0.6931471803099453}, {'polarity': -1, 'threshold': 3, 'feature_index': 0, 'alpha': 0.5493061439673882}]"
    }
  ],
  "difficulty": "hard",
  "pytorch_difficulty": "hard",
  "video": "",
  "likes": "0",
  "example": {
    "input": "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n    y = np.array([1, 1, -1, -1])\n    n_clf = 3\n\n    clfs = adaboost_fit(X, y, n_clf)\n    print(clfs)",
    "output": "(example format, actual values may vary):\n    # [{'polarity': 1, 'threshold': 2, 'feature_index': 0, 'alpha': 0.5},\n    #  {'polarity': -1, 'threshold': 3, 'feature_index': 1, 'alpha': 0.3},\n    #  {'polarity': 1, 'threshold': 4, 'feature_index': 0, 'alpha': 0.2}]",
    "reasoning": "The function fits an AdaBoost classifier on the dataset X with the given labels y and number of classifiers n_clf. It returns a list of classifiers with their parameters, including the polarity, threshold, feature index, and alpha values"
  },
  "dislikes": "0",
  "category": "Machine Learning",
  "starter_code": "import numpy as np\nimport math\n\ndef adaboost_fit(X, y, n_clf):\n\tn_samples, n_features = np.shape(X)\n\tw = np.full(n_samples, (1 / n_samples))\n\tclfs = []\n\n\t# Your code here\n\n\treturn clfs\n    ",
  "title": "Implement AdaBoost Fit Method",
  "learn_section": "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",
  "contributor": [
    {
      "profile_link": "https://github.com/eriklindernoren/ML-From-Scratch",
      "name": "Erik Linder-NorÃ©n"
    },
    {
      "profile_link": "https://github.com/moe18",
      "name": "Moe Chabot"
    }
  ],
  "pytorch_test_cases": [
    {
      "test": "import torch\nimport numpy as np\nfrom __main__ import adaboost_fit\nX = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\ny = np.array([1, 1, -1, -1])\nn_clf = 3\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
      "expected_output": "[{'polarity': -1, 'threshold': 2.0, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 2.0, 'feature_index': 0, 'alpha': 11.512925464970229}, {'polarity': -1, 'threshold': 2.0, 'feature_index': 0, 'alpha': 11.512925464970229}]"
    },
    {
      "test": "import torch\nimport numpy as np\nfrom __main__ import adaboost_fit\nX = np.array([[8, 7], [3, 4], [5, 9], [4, 0], [1, 0], [0, 7], [3, 8], [4, 2], [6, 8], [0, 2]])\ny = np.array([1, -1, 1, -1, 1, -1, -1, -1, 1, 1])\nn_clf = 2\nclfs = adaboost_fit(X, y, n_clf)\nprint(clfs)",
      "expected_output": "[{'polarity': 1, 'threshold': 4.0, 'feature_index': 0, 'alpha': 0.693147403827393}, {'polarity': -1, 'threshold': 1.0, 'feature_index': 0, 'alpha': 0.7520388802384615}]"
    }
  ],
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmltcG9ydCBtYXRoCmZyb20gdHlwaW5nIGltcG9ydCBMaXN0LCBEaWN0CgpkZWYgYWRhYm9vc3RfZml0KFgsIHksIG5fY2xmKSAtPiBMaXN0W0RpY3RdOgogICAgIiIiCiAgICBGaXQgYW4gQWRhQm9vc3QgY2xhc3NpZmllciB1c2luZyBQeVRvcmNoIHRlbnNvcnMgKG5vIHNrbGVhcm4pLgogICAgQXJnczoKICAgICAgICBYOiB0b3JjaC5UZW5zb3Igb3IgYXJyYXktbGlrZSwgc2hhcGUgKG5fc2FtcGxlcywgbl9mZWF0dXJlcykKICAgICAgICB5OiB0b3JjaC5UZW5zb3Igb3IgYXJyYXktbGlrZSwgc2hhcGUgKG5fc2FtcGxlcywpIHdpdGggbGFiZWxzICgrMS8tMSkKICAgICAgICBuX2NsZjogaW50LCBudW1iZXIgb2Ygd2VhayBjbGFzc2lmaWVycwogICAgUmV0dXJuczoKICAgICAgICBMaXN0IG9mIGRpY3Rpb25hcmllcyB3aXRoIGNsYXNzaWZpZXIgcGFyYW1zOiAncG9sYXJpdHknLCAndGhyZXNob2xkJywgJ2ZlYXR1cmVfaW5kZXgnLCAnYWxwaGEnLgogICAgIiIiCiAgICAjIFlvdXIgaW1wbGVtZW50YXRpb24gaGVyZQogICAgcGFzcwo=",
  "description_decoded": "Write a Python function `adaboost_fit` that implements the fit method for an AdaBoost classifier. The function should take in a 2D numpy array `X` of shape `(n_samples, n_features)` representing the dataset, a 1D numpy array `y` of shape `(n_samples,)` representing the labels, and an integer `n_clf` representing the number of classifiers. The function should initialize sample weights, find the best thresholds for each feature, calculate the error, update weights, and return a list of classifiers with their parameters.",
  "learn_section_decoded": "\n## Understanding AdaBoost\n\nAdaBoost, short for Adaptive Boosting, is an ensemble learning method that combines multiple weak classifiers to create a strong classifier. The basic idea is to fit a sequence of weak learners on weighted versions of the data.\n\n### Implementing the Fit Method for an AdaBoost Classifier\n\n1. **Initialize Weights**  \n   Start by initializing the sample weights uniformly:\n   $$\n   w_i = \\frac{1}{N}, \\text{ where } N \\text{ is the number of samples}\n   $$\n\n2. **Iterate Through Classifiers**  \n   For each classifier, determine the best threshold for each feature to minimize the error.\n\n3. **Calculate Error and Flip Polarity**  \n   If the error is greater than 0.5, flip the polarity:\n   $$\n   \\text{error} = \\sum_{i=1}^N w_i [y_i \\neq h(x_i)]\n   $$\n   $$\n   \\text{if error} > 0.5: \\text{error} = 1 - \\text{error}, \\text{ and flip the polarity}\n   $$\n\n4. **Calculate Alpha**  \n   Compute the weight (alpha) of the classifier based on its error rate:\n   $$\n   \\alpha = \\frac{1}{2} \\ln \\left( \\frac{1 - \\text{error}}{\\text{error} + 1e-10} \\right)\n   $$\n\n5. **Update Weights**  \n   Adjust the sample weights based on the classifier's performance and normalize them:\n   $$\n   w_i = w_i \\exp(-\\alpha y_i h(x_i))\n   $$\n   $$\n   w_i = \\frac{w_i}{\\sum_{j=1}^N w_j}\n   $$\n\n6. **Save Classifier**  \n   Store the classifier with its parameters.\n\n### Key Insight\nThis method helps in focusing more on the misclassified samples in subsequent rounds, thereby improving the overall performance.\n"
}