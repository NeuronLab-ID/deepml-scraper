{
  "description": "SW1wbGVtZW50IGEgZnVuY3Rpb24gdG8gY2FsY3VsYXRlIHRoZSBFeHBlY3RlZCBDYWxpYnJhdGlvbiBFcnJvciAoRUNFKSBmb3IgZXZhbHVhdGluZyBob3cgd2VsbCBhIGJpbmFyeSBjbGFzc2lmaWNhdGlvbiBtb2RlbCdzIHByZWRpY3RlZCBwcm9iYWJpbGl0aWVzIGFyZSBjYWxpYnJhdGVkLgoKR2l2ZW4gdHJ1ZSBiaW5hcnkgbGFiZWxzICgwIG9yIDEpIGFuZCBwcmVkaWN0ZWQgcHJvYmFiaWxpdGllcyBmb3IgdGhlIHBvc2l0aXZlIGNsYXNzLCBjb21wdXRlIHRoZSBFQ0UgYnk6CjEuIERpdmlkaW5nIHRoZSBwcm9iYWJpbGl0eSByYW5nZSBbMCwgMV0gaW50byBuX2JpbnMgZXF1YWwtd2lkdGggYmlucwoyLiBGb3IgZWFjaCBub24tZW1wdHkgYmluLCBjYWxjdWxhdGluZyB0aGUgYXZlcmFnZSBwcmVkaWN0ZWQgcHJvYmFiaWxpdHkgKGNvbmZpZGVuY2UpIGFuZCB0aGUgYWN0dWFsIGFjY3VyYWN5IChmcmFjdGlvbiBvZiBwb3NpdGl2ZSBsYWJlbHMpCjMuIENvbXB1dGluZyB0aGUgd2VpZ2h0ZWQgYXZlcmFnZSBvZiB0aGUgYWJzb2x1dGUgZGlmZmVyZW5jZXMgYmV0d2VlbiBjb25maWRlbmNlIGFuZCBhY2N1cmFjeSBhY3Jvc3MgYWxsIGJpbnMsIHdoZXJlIHdlaWdodHMgYXJlIHRoZSBwcm9wb3J0aW9uIG9mIHNhbXBsZXMgaW4gZWFjaCBiaW4KClRoZSBmaXJzdCBiaW4gc2hvdWxkIGluY2x1ZGUgYm90aCBlbmRwb2ludHMgWzAsIDEvbl9iaW5zXSwgd2hpbGUgc3Vic2VxdWVudCBiaW5zIHNob3VsZCBleGNsdWRlIHRoZWlyIGxvd2VyIGJvdW5kYXJ5IChsb3dlciwgdXBwZXJdLgoKVGhlIGZ1bmN0aW9uIHNob3VsZCByZXR1cm4gdGhlIEVDRSB2YWx1ZSByb3VuZGVkIHRvIDMgZGVjaW1hbCBwbGFjZXMuIExvd2VyIEVDRSB2YWx1ZXMgaW5kaWNhdGUgYmV0dGVyIGNhbGlicmF0aW9uLCB3aXRoIDAgYmVpbmcgcGVyZmVjdGx5IGNhbGlicmF0ZWQu",
  "id": "260",
  "test_cases": [
    {
      "test": "print(expected_calibration_error([0, 1], [0.0, 1.0], n_bins=2))",
      "expected_output": "0.0"
    },
    {
      "test": "print(expected_calibration_error([0, 0, 1, 1], [0.8, 0.8, 0.8, 0.8], n_bins=5))",
      "expected_output": "0.3"
    }
  ],
  "difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "y_true = [0, 0, 1, 1], y_prob = [0.8, 0.8, 0.8, 0.8], n_bins = 5",
    "output": "0.3",
    "reasoning": "All 4 predictions fall into the bin (0.6, 0.8]. The average confidence in this bin is 0.8, but the actual accuracy is 2/4 = 0.5 (only 2 out of 4 are positive). The absolute difference is |0.5 - 0.8| = 0.3. Since all samples are in this bin, the weight is 1.0, giving ECE = 1.0 * 0.3 = 0.3. This indicates an overconfident model."
  },
  "category": "Machine Learning",
  "starter_code": "import numpy as np\n\ndef expected_calibration_error(y_true, y_prob, n_bins=10):\n    \"\"\"\n    Calculate the Expected Calibration Error (ECE).\n    \n    Args:\n        y_true: List or array of true binary labels (0 or 1)\n        y_prob: List or array of predicted probabilities for the positive class\n        n_bins: Number of bins for grouping predictions (default: 10)\n    \n    Returns:\n        float: ECE value rounded to 3 decimal places\n    \"\"\"\n    # Your code here\n    pass",
  "title": "Calculate Expected Calibration Error (ECE)",
  "createdAt": "December 14, 2025 at 1:18:30â€¯PM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "learn_section": "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",
  "description_decoded": "Implement a function to calculate the Expected Calibration Error (ECE) for evaluating how well a binary classification model's predicted probabilities are calibrated.\n\nGiven true binary labels (0 or 1) and predicted probabilities for the positive class, compute the ECE by:\n1. Dividing the probability range [0, 1] into n_bins equal-width bins\n2. For each non-empty bin, calculating the average predicted probability (confidence) and the actual accuracy (fraction of positive labels)\n3. Computing the weighted average of the absolute differences between confidence and accuracy across all bins, where weights are the proportion of samples in each bin\n\nThe first bin should include both endpoints [0, 1/n_bins], while subsequent bins should exclude their lower boundary (lower, upper].\n\nThe function should return the ECE value rounded to 3 decimal places. Lower ECE values indicate better calibration, with 0 being perfectly calibrated.",
  "learn_section_decoded": "## Expected Calibration Error (ECE)\n\nExpected Calibration Error (ECE) is a widely-used metric for evaluating how well a model's predicted probabilities align with actual outcomes. A well-calibrated model should have predicted probabilities that match the true frequency of positive outcomes.\n\n### Why Calibration Matters\n\nIn many real-world applications, we need not just accurate predictions, but also reliable confidence estimates:\n- Medical diagnosis: A 90% confidence should mean 9 out of 10 similar cases are positive\n- Weather forecasting: \"70% chance of rain\" should correspond to rain 70% of the time\n- Risk assessment: Probability estimates directly affect decision-making\n\n### Mathematical Definition\n\nECE partitions predictions into $M$ bins based on confidence levels and computes:\n\n$$\n\\text{ECE} = \\sum_{m=1}^{M} \\frac{|B_m|}{n} \\cdot |\\text{acc}(B_m) - \\text{conf}(B_m)|\n$$\n\nWhere:\n- $B_m$ is the set of samples whose predicted probability falls in bin $m$\n- $|B_m|$ is the number of samples in bin $m$\n- $n$ is the total number of samples\n- $\\text{acc}(B_m)$ is the accuracy (fraction of positive labels) in bin $m$\n- $\\text{conf}(B_m)$ is the average predicted probability in bin $m$\n\n### Computing Accuracy and Confidence per Bin\n\nFor each bin $B_m$:\n\n$$\n\\text{acc}(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} y_i\n$$\n\n$$\n\\text{conf}(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} \\hat{p}_i\n$$\n\nWhere $y_i \\in \\{0, 1\\}$ is the true label and $\\hat{p}_i$ is the predicted probability.\n\n### Interpreting ECE Values\n\n| ECE Value | Interpretation |\n|-----------|----------------|\n| 0.0 | Perfectly calibrated |\n| < 0.05 | Well calibrated |\n| 0.05 - 0.15 | Moderately calibrated |\n| > 0.15 | Poorly calibrated |\n\n### Types of Miscalibration\n\n**Overconfidence**: When $\\text{conf}(B_m) > \\text{acc}(B_m)$, the model is overconfident - it predicts higher probabilities than the actual positive rate.\n\n**Underconfidence**: When $\\text{conf}(B_m) < \\text{acc}(B_m)$, the model is underconfident - it predicts lower probabilities than warranted by the data.\n\n### Reliability Diagrams\n\nECE is often visualized using reliability diagrams, which plot:\n- X-axis: Mean predicted probability per bin (confidence)\n- Y-axis: Fraction of positives per bin (accuracy)\n\nA perfectly calibrated model produces points along the diagonal line $y = x$.\n\n### Limitations\n\n1. **Bin sensitivity**: ECE depends on the number and boundaries of bins\n2. **Sample size**: Small bins may have unreliable statistics\n3. **Class imbalance**: May need stratified versions for imbalanced datasets\n\n### Calibration Methods\n\nWhen ECE is high, calibration techniques can improve probability estimates:\n- **Platt Scaling**: Fits a sigmoid function to transform outputs\n- **Temperature Scaling**: Divides logits by a learned temperature\n- **Isotonic Regression**: Non-parametric monotonic calibration"
}