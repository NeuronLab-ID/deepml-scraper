{
  "description": "SW1wbGVtZW50IGEgZnVuY3Rpb24gdG8gY29tcHV0ZSBhIGNvbmZ1c2lvbiBtYXRyaXggZm9yIG11bHRpLWNsYXNzIGNsYXNzaWZpY2F0aW9uIHdpdGggb3B0aW9uYWwgbm9ybWFsaXphdGlvbi4gVGhlIGZ1bmN0aW9uIHNob3VsZCBzdXBwb3J0IHRocmVlIG5vcm1hbGl6YXRpb24gbW9kZXM6IGJ5IHRydWUgbGFiZWxzIChyb3ctd2lzZSksIGJ5IHByZWRpY3RlZCBsYWJlbHMgKGNvbHVtbi13aXNlKSwgYW5kIGJ5IGFsbCBzYW1wbGVzIChnbG9iYWwpLiBXaGVuIG5vcm1hbGl6YXRpb24gaXMgZW5hYmxlZCwgcm91bmQgdGhlIG91dHB1dHMgdG8gYSBjb25maWd1cmFibGUgbnVtYmVyIG9mIGRlY2ltYWwgcGxhY2VzLg==",
  "id": "193",
  "test_cases": [
    {
      "test": "print(compute_confusion_matrix([0,1,2,2,2,1], [0,2,2,2,1,1], 3))",
      "expected_output": "[[1, 0, 0], [0, 1, 1], [0, 1, 2]]"
    },
    {
      "test": "print(compute_confusion_matrix([0,1,2,2,2,1], [0,2,2,2,1,1], 3, normalize='true', round_decimals=4))",
      "expected_output": "[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5], [0.0, 0.3333, 0.6667]]"
    }
  ],
  "difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "compute_confusion_matrix([0,1,2,2], [0,2,1,2], 3, normalize='true', round_decimals=4)",
    "output": "[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.5, 0.5]]",
    "reasoning": "Counts: [[1,0,0],[0,0,1],[0,1,1]]. Row-wise normalization divides each row by its sum; rows with sums 1 stay the same, the last row [0,1,1]/2 -> [0.0, 0.5, 0.5]."
  },
  "category": "Machine Learning",
  "starter_code": "import numpy as np\n\ndef compute_confusion_matrix(y_true, y_pred, num_classes, normalize=None, round_decimals=4):\n    \"\"\"\n    Compute a KxK confusion matrix with optional normalization.\n\n    Args:\n        y_true: Iterable of true labels in [0, K-1]\n        y_pred: Iterable of predicted labels in [0, K-1]\n        num_classes: K, number of classes\n        normalize: None | 'true' | 'pred' | 'all'\n        round_decimals: decimals to round when normalization is applied\n\n    Returns:\n        list[list[int|float]] confusion matrix\n    \"\"\"\n    # Your implementation here\n    pass\n",
  "title": "Compute Confusion Matrix with Normalization",
  "createdAt": "November 9, 2025 at 1:40:06â€¯PM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "moe"
    }
  ],
  "learn_section": "IyMgQ29uZnVzaW9uIE1hdHJpeCAmIE5vcm1hbGl6YXRpb24KQSAqKmNvbmZ1c2lvbiBtYXRyaXgqKiBmb3IgYSAkSyQtY2xhc3MgY2xhc3NpZmllciBpcyBhICRLXHRpbWVzIEskIHRhYmxlICRDJCB3aGVyZQokJENfe2lqfSA9IFxzdW1fe249MX1ee059IFxtYXRoYmZ7MX1beV57KG4pfT1pIFx3ZWRnZSBcaGF0e3l9Xnsobil9PWpdJCQKUm93cyBpbmRleCB0aGUgKip0cnVlKiogY2xhc3MgJGkkIGFuZCBjb2x1bW5zIGluZGV4IHRoZSAqKnByZWRpY3RlZCoqIGNsYXNzICRqJC4KCiMjIyBOb3JtYWxpemF0aW9uIHNjaGVtZXMKLSAqKk5vbmUgKGNvdW50cyk6KiogUmV0dXJuIHJhdyBjb3VudHMgJENfe2lqfSQuCi0gKipCeSB0cnVlIGxhYmVscyAocm93LXdpc2UpOioqCiQkQ157KFx0ZXh0e3RydWV9KX1fe2lqfSA9IFxiZWdpbntjYXNlc31cZGZyYWN7Q197aWp9fXtcc3VtX3tqJ30gQ197aWonfX0gJiBcdGV4dHtpZiB9IFxzdW1fe2onfSBDX3tpaid9PjBcXFs0cHRdMCAmIFx0ZXh0e290aGVyd2lzZX1cZW5ke2Nhc2VzfSQkCkludGVycHJldGVkIGFzICRQKFxoYXR7WX09alxtaWQgWT1pKSQuCi0gKipCeSBwcmVkaWN0ZWQgbGFiZWxzIChjb2x1bW4td2lzZSk6KioKJCRDXnsoXHRleHR7cHJlZH0pfV97aWp9ID0gXGJlZ2lue2Nhc2VzfVxkZnJhY3tDX3tpan19e1xzdW1fe2knfSBDX3tpJ2p9fSAmIFx0ZXh0e2lmIH0gXHN1bV97aSd9IENfe2knan0+MFxcWzRwdF0wICYgXHRleHR7b3RoZXJ3aXNlfVxlbmR7Y2FzZXN9JCQKSW50ZXJwcmV0ZWQgYXMgJFAoWT1pXG1pZCBcaGF0e1l9PWopJC4KLSAqKkJ5IGFsbCBzYW1wbGVzIChnbG9iYWwpOioqCiQkQ157KFx0ZXh0e2FsbH0pfV97aWp9ID0gXGRmcmFje0Nfe2lqfX17XHN1bV97aScsaid9IENfe2knaid9fSA9IFxkZnJhY3tDX3tpan19e059JCQKSW50ZXJwcmV0ZWQgYXMgam9pbnQgcHJvYmFiaWxpdHkgJFAoWT1pLFxoYXR7WX09aikkLgoKIyMjIE5vdGVzCi0gVXNlICRLJCAobnVtYmVyIG9mIGNsYXNzZXMpIHRvIHNpemUgdGhlIG1hdHJpeCBldmVuIGlmIHNvbWUgY2xhc3NlcyBhcmUgYWJzZW50LgotIFdoZW4gbm9ybWFsaXppbmcsIHJvdW5kIHRvIGEgc3BlY2lmaWVkIG51bWJlciBvZiBkZWNpbWFscyAoZS5nLiwgNCkuIEF2b2lkIGRpdmlzaW9uIGJ5IHplcm8gYnkgbGVhdmluZyByb3dzL2NvbHVtbnMgYXMgemVyb3Mgd2hlbiB0aGVpciBzdW1zIGFyZSB6ZXJvLg==",
  "description_decoded": "Implement a function to compute a confusion matrix for multi-class classification with optional normalization. The function should support three normalization modes: by true labels (row-wise), by predicted labels (column-wise), and by all samples (global). When normalization is enabled, round the outputs to a configurable number of decimal places.",
  "learn_section_decoded": "## Confusion Matrix & Normalization\nA **confusion matrix** for a $K$-class classifier is a $K\\times K$ table $C$ where\n$$C_{ij} = \\sum_{n=1}^{N} \\mathbf{1}[y^{(n)}=i \\wedge \\hat{y}^{(n)}=j]$$\nRows index the **true** class $i$ and columns index the **predicted** class $j$.\n\n### Normalization schemes\n- **None (counts):** Return raw counts $C_{ij}$.\n- **By true labels (row-wise):**\n$$C^{(\\text{true})}_{ij} = \\begin{cases}\\dfrac{C_{ij}}{\\sum_{j'} C_{ij'}} & \\text{if } \\sum_{j'} C_{ij'}>0\\\\[4pt]0 & \\text{otherwise}\\end{cases}$$\nInterpreted as $P(\\hat{Y}=j\\mid Y=i)$.\n- **By predicted labels (column-wise):**\n$$C^{(\\text{pred})}_{ij} = \\begin{cases}\\dfrac{C_{ij}}{\\sum_{i'} C_{i'j}} & \\text{if } \\sum_{i'} C_{i'j}>0\\\\[4pt]0 & \\text{otherwise}\\end{cases}$$\nInterpreted as $P(Y=i\\mid \\hat{Y}=j)$.\n- **By all samples (global):**\n$$C^{(\\text{all})}_{ij} = \\dfrac{C_{ij}}{\\sum_{i',j'} C_{i'j'}} = \\dfrac{C_{ij}}{N}$$\nInterpreted as joint probability $P(Y=i,\\hat{Y}=j)$.\n\n### Notes\n- Use $K$ (number of classes) to size the matrix even if some classes are absent.\n- When normalizing, round to a specified number of decimals (e.g., 4). Avoid division by zero by leaving rows/columns as zeros when their sums are zero."
}