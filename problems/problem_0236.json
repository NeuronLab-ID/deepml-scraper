{
  "description": "SW1wbGVtZW50IGEgbWVhbiBhYmxhdGlvbiBmdW5jdGlvbiBmb3IgbmV1cmFsIG5ldHdvcmsgaW50ZXJwcmV0YWJpbGl0eS4gTWVhbiBhYmxhdGlvbiBpcyBhIHRlY2huaXF1ZSB1c2VkIHRvIGlzb2xhdGUgbmV1cmFsIGNpcmN1aXRzIGJ5IHJlcGxhY2luZyBhIG5vZGUncyBhY3RpdmF0aW9uIHdpdGggaXRzIG1lYW4gdmFsdWUgY29tcHV0ZWQgb3ZlciBhIHJlZmVyZW5jZSBkaXN0cmlidXRpb24uIEdpdmVuIG5vZGUgYWN0aXZhdGlvbnMsIGEgYmluYXJ5IG1hc2sgaW5kaWNhdGluZyB3aGljaCBub2RlcyB0byBhYmxhdGUsIGFuZCBwcmVjb21wdXRlZCBtZWFuIGFjdGl2YXRpb25zLCByZXR1cm4gdGhlIGFibGF0ZWQgYWN0aXZhdGlvbnMgd2hlcmUgbWFza2VkIG5vZGVzIGFyZSByZXBsYWNlZCB3aXRoIHRoZWlyIG1lYW5zIHdoaWxlIHVubWFza2VkIG5vZGVzIHJldGFpbiB0aGVpciBvcmlnaW5hbCB2YWx1ZXMu",
  "id": "236",
  "test_cases": [
    {
      "test": "import numpy as np\nresult = mean_ablate(np.array([0.5, -0.3, 0.8, 0.2]), np.array([1, 0, 1, 0]), np.array([0.1, 0.0, 0.2, -0.1]))\nprint(result.tolist())",
      "expected_output": "[0.1, -0.3, 0.2, 0.2]"
    },
    {
      "test": "import numpy as np\nresult = mean_ablate(np.array([1.0, 2.0, 3.0]), np.array([0, 0, 0]), np.array([0.0, 0.0, 0.0]))\nprint(result.tolist())",
      "expected_output": "[1.0, 2.0, 3.0]"
    }
  ],
  "difficulty": "medium",
  "pytorch_difficulty": "medium",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "activations = [0.5, -0.3, 0.8, 0.2], mask = [1, 0, 1, 0], means = [0.1, 0.0, 0.2, -0.1]",
    "output": "[0.1, -0.3, 0.2, 0.2]",
    "reasoning": "Nodes at indices 0 and 2 have mask=1 so they are ablated (replaced with means 0.1 and 0.2). Nodes at indices 1 and 3 have mask=0 so they keep their original values (-0.3 and 0.2)."
  },
  "category": "Deep Learning",
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCgpkZWYgbWVhbl9hYmxhdGUoYWN0aXZhdGlvbnM6IHRvcmNoLlRlbnNvciwgbWFzazogdG9yY2guVGVuc29yLCBtZWFuczogdG9yY2guVGVuc29yKSAtPiB0b3JjaC5UZW5zb3I6CiAgICAiIiIKICAgIEFwcGx5IG1lYW4gYWJsYXRpb24gdG8gbm9kZSBhY3RpdmF0aW9ucyB1c2luZyBQeVRvcmNoLgogICAgCiAgICBBcmdzOgogICAgICAgIGFjdGl2YXRpb25zOiBPcmlnaW5hbCBub2RlIGFjdGl2YXRpb25zLCBzaGFwZSAobiwpIG9yIChiYXRjaCwgbikKICAgICAgICBtYXNrOiBCaW5hcnkgbWFzayB3aGVyZSAxID0gYWJsYXRlIChyZXBsYWNlIHdpdGggbWVhbiksIDAgPSBrZWVwIG9yaWdpbmFsICAKICAgICAgICBtZWFuczogUHJlY29tcHV0ZWQgbWVhbiBhY3RpdmF0aW9ucyBmb3IgZWFjaCBub2RlLCBzaGFwZSAobiwpCiAgICAKICAgIFJldHVybnM6CiAgICAgICAgQWJsYXRlZCBhY3RpdmF0aW9ucyB3aXRoIHNhbWUgc2hhcGUgYXMgaW5wdXQKICAgICIiIgogICAgIyBZb3VyIGNvZGUgaGVyZQogICAgcGFzcw==",
  "title": "Mean Ablation for Circuit Discovery",
  "createdAt": "December 13, 2025 at 6:03:01â€¯PM UTC-0500",
  "contributor": [
    {
      "profile_link": "https://github.com/Open-Deep-ML",
      "name": "Deep-ML"
    }
  ],
  "pytorch_test_cases": [
    {
      "test": "import torch\nresult = mean_ablate(torch.tensor([0.5, -0.3, 0.8, 0.2]), torch.tensor([1, 0, 1, 0]), torch.tensor([0.1, 0.0, 0.2, -0.1]))\nprint([round(x, 4) for x in result.tolist()])",
      "expected_output": "[0.1, -0.3, 0.2, 0.2]"
    },
    {
      "test": "import torch\nresult = mean_ablate(torch.tensor([1.0, 2.0, 3.0]), torch.tensor([0, 0, 0]), torch.tensor([0.0, 0.0, 0.0]))\nprint([round(x, 4) for x in result.tolist()])",
      "expected_output": "[1.0, 2.0, 3.0]"
    },
    {
      "test": "import torch\nresult = mean_ablate(torch.tensor([1.0, 2.0, 3.0]), torch.tensor([1, 1, 1]), torch.tensor([0.5, 0.5, 0.5]))\nprint([round(x, 4) for x in result.tolist()])",
      "expected_output": "[0.5, 0.5, 0.5]"
    }
  ],
  "learn_section": "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",
  "starter_code": "import numpy as np\n\ndef mean_ablate(activations: np.ndarray, mask: np.ndarray, means: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Apply mean ablation to node activations.\n    \n    Args:\n        activations: Original node activations, shape (n,) or (batch, n)\n        mask: Binary mask where 1 = ablate (replace with mean), 0 = keep original\n        means: Precomputed mean activations for each node, shape (n,)\n    \n    Returns:\n        Ablated activations with same shape as input\n    \"\"\"\n    # Your code here\n    pass",
  "description_decoded": "Implement a mean ablation function for neural network interpretability. Mean ablation is a technique used to isolate neural circuits by replacing a node's activation with its mean value computed over a reference distribution. Given node activations, a binary mask indicating which nodes to ablate, and precomputed mean activations, return the ablated activations where masked nodes are replaced with their means while unmasked nodes retain their original values.",
  "learn_section_decoded": "## Mean Ablation for Circuit Discovery\n\nMean ablation is a fundamental technique in mechanistic interpretability for isolating the minimal circuit responsible for a specific behavior in neural networks.\n\n### Core Idea\n\nWhen analyzing neural networks, we want to identify which nodes (neurons, attention heads, residual channels) are necessary for a particular task. Mean ablation works by:\n\n1. Computing the mean activation of each node over a reference distribution (typically the pretraining data)\n2. \"Ablating\" nodes by replacing their activation with this mean value\n3. Observing how task performance changes\n\n### Mathematical Definition\n\nFor a node with activation $x_i$ and precomputed mean $\\mu_i$, mean ablation with mask $m_i \\in \\{0, 1\\}$ produces:\n$$x_i^{\\text{ablated}} = m_i \\cdot \\mu_i + (1 - m_i) \\cdot x_i$$\n\nwhere:\n- $m_i = 1$: node is ablated (replaced with mean)\n- $m_i = 0$: node is preserved (keeps original activation)\n\n### Why Mean Ablation?\n\nMean ablation has several advantages over zero ablation:\n\n1. **Preserves distribution**: The mean is a natural \"neutral\" value that doesn't push the network far off its typical activation manifold\n\n2. **Removes information**: By fixing a node to its mean, we remove all task-specific information it might carry\n\n3. **Validates circuits**: If ablating all nodes *except* a proposed circuit preserves task performance, the circuit is **sufficient**. If ablating *only* the circuit destroys performance, it is **necessary**.\n\n### Application to Sparse Circuits\n\nIn weight-sparse transformer interpretability, mean ablation is used to prune models down to minimal circuits. The process involves learning binary masks that minimize both task loss and circuit size, where masked-out nodes are mean-ablated.\n\nThis technique enables researchers to isolate circuits with as few as 10-20 nodes that fully explain specific model behaviors."
}