{
  "description": "SW1wbGVtZW50IGEgUG9zaXRpb24td2lzZSBGZWVkLUZvcndhcmQgTmV0d29yayAoRkZOKSB3aXRoIHJlc2lkdWFsIGNvbm5lY3Rpb24gYW5kIGRyb3BvdXQsIGFzIHVzZWQgaW4gVHJhbnNmb3JtZXIgYXJjaGl0ZWN0dXJlcy4gVGhlIGJsb2NrIHNob3VsZCB0YWtlIGFuIGlucHV0IHZlY3RvciwgYXBwbHkgdHdvIGxpbmVhciB0cmFuc2Zvcm1hdGlvbnMgd2l0aCBhIFJlTFUgYWN0aXZhdGlvbiBpbiBiZXR3ZWVuLCB0aGVuIGFkZCBhIHJlc2lkdWFsIGNvbm5lY3Rpb24gZnJvbSB0aGUgaW5wdXQgYW5kIGFwcGx5IGRyb3BvdXQuIFJvdW5kIG91dHB1dHMgdG8gNCBkZWNpbWFsIHBsYWNlcyBmb3IgcmVwcm9kdWNpYmlsaXR5Lg==",
  "id": "178",
  "test_cases": [
    {
      "test": "print(ffn([1.0, -1.0], [[1.0,2.0],[3.0,4.0]], [0.5,-0.5], [[2.0,1.0],[0.5,1.0]], [0.0,0.5], dropout_p=0.0, seed=42))",
      "expected_output": "[1.0, -0.5]"
    },
    {
      "test": "print(ffn([0.5, 0.5], [[1.0, -1.0],[2.0, 0.5]], [0.0,0.0], [[1.0,1.0],[0.5,2.0]], [0.5,0.5], dropout_p=0.0, seed=123))",
      "expected_output": "[2.25, 3.5]"
    }
  ],
  "difficulty": "medium",
  "pytorch_difficulty": "easy",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "ffn([1.0, -1.0], W1=[[1.0,2.0],[3.0,4.0]], b1=[0.5, -0.5], W2=[[2.0,1.0],[0.5,1.0]], b2=[0.0, 0.5], dropout_p=0.0, seed=42)",
    "output": "[1.0, -0.5]",
    "reasoning": "First compute hidden = ReLU(W1*x + b1) = ReLU([1*1 + -1*2 + 0.5, 1*3 + -1*4 - 0.5]) = ReLU([-0.5, -1.5]) = [0,0]. Then output = W2*hidden + b2 = [0, 0.5]. Residual adds input [1,-1] => [1, -0.5]. Since dropout_p=0, nothing is dropped. Final output = [1.0, -0.5]."
  },
  "category": "Deep Learning",
  "pytorch_starter_code": "aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgppbXBvcnQgdG9yY2gubm4uZnVuY3Rpb25hbCBhcyBGCgpjbGFzcyBGRk5CbG9jayhubi5Nb2R1bGUpOgogICAgZGVmIF9faW5pdF9fKHNlbGYsIGRfbW9kZWwsIGRfaGlkZGVuLCBkcm9wb3V0X3A9MC4xKToKICAgICAgICAjIFlvdXIgY29kZSBoZXJlCiAgICBkZWYgZm9yd2FyZChzZWxmLCB4KToKICAgICAgICAjIFlvdXIgY29kZSBoZXJlCiAgICAgICAgcGFzcw==",
  "title": "Implement Position-wise Feed-Forward Block with Residual and Dropout",
  "createdAt": "September 1, 2025 at 12:17:18â€¯PM UTUTC-4",
  "contributor": [
    {
      "profile_link": "https://github.com/moe18",
      "name": "moe"
    }
  ],
  "pytorch_test_cases": [
    {
      "test": "import torch\nblock = FFNBlock(2,4,dropout_p=0.0)\nwith torch.no_grad():\n    block.linear1.weight.copy_(torch.tensor([[1.0,2.0],[3.0,4.0],[0.0,0.0],[0.0,0.0]]))\n    block.linear1.bias.copy_(torch.tensor([0.5,-0.5,0.0,0.0]))\n    block.linear2.weight.copy_(torch.tensor([[2.0,1.0,0.0,0.0],[0.5,1.0,0.0,0.0]]))\n    block.linear2.bias.copy_(torch.tensor([0.0,0.5]))\n    out = block(torch.tensor([1.0,-1.0]))\nprint(out.tolist())",
      "expected_output": "[1.0, -0.5]"
    },
    {
      "test": "import torch\nblock = FFNBlock(2,3,dropout_p=0.5)\ntorch.manual_seed(1)\nwith torch.no_grad():\n    block.linear1.weight.fill_(1.0)\n    block.linear1.bias.fill_(0.0)\n    block.linear2.weight.fill_(0.5)\n    block.linear2.bias.fill_(0.0)\n    out = block(torch.tensor([1.0,2.0]))\nprint(out.tolist())",
      "expected_output": "[10.0, 11.0]"
    }
  ],
  "learn_section": "IyMgUG9zaXRpb24td2lzZSBGZWVkLUZvcndhcmQgQmxvY2sgaW4gVHJhbnNmb3JtZXJzCgpJbiB0aGUgVHJhbnNmb3JtZXIgYXJjaGl0ZWN0dXJlLCBlYWNoIGVuY29kZXIgYW5kIGRlY29kZXIgbGF5ZXIgY29udGFpbnMgYSAqKnBvc2l0aW9uLXdpc2UgZmVlZC1mb3J3YXJkIG5ldHdvcmsgKEZGTikqKi4gSXQgb3BlcmF0ZXMgaW5kZXBlbmRlbnRseSBvbiBlYWNoIHBvc2l0aW9uIGluIHRoZSBzZXF1ZW5jZS4KClRoZSBGRk4gaXMgZGVmaW5lZCBhczoKCiQkRkZOKHgpID0gXHRleHR7RHJvcG91dH0oV18yKFx0ZXh0e1JlTFV9KFdfMXggKyBiXzEpKSArIGJfMikgKyB4JCQKCndoZXJlOgotICR4JDogSW5wdXQgdmVjdG9yCi0gJFdfMSwgYl8xJDogRmlyc3QgbGluZWFyIHRyYW5zZm9ybWF0aW9uIChleHBhbnNpb24pCi0gJFdfMiwgYl8yJDogU2Vjb25kIGxpbmVhciB0cmFuc2Zvcm1hdGlvbiAocHJvamVjdGlvbiBiYWNrIHRvIGlucHV0IGRpbWVuc2lvbikKLSBSZXNpZHVhbCBjb25uZWN0aW9uOiBBZGRzIHRoZSBpbnB1dCAkeCQgdG8gdGhlIHRyYW5zZm9ybWVkIG91dHB1dAotIERyb3BvdXQ6IFJhbmRvbWx5IHplcm9zIHNvbWUgZWxlbWVudHMgZHVyaW5nIHRyYWluaW5nIHRvIHByZXZlbnQgb3ZlcmZpdHRpbmcKCiMjIyBLZXkgQ29uY2VwdHMKMS4gKipSZXNpZHVhbCBDb25uZWN0aW9uOioqIEhlbHBzIHByZXZlbnQgdmFuaXNoaW5nIGdyYWRpZW50cyBieSBhbGxvd2luZyB0aGUgaW5wdXQgdG8gYnlwYXNzIHRyYW5zZm9ybWF0aW9ucy4KMi4gKipEcm9wb3V0OioqIEltcHJvdmVzIGdlbmVyYWxpemF0aW9uIGJ5IHByZXZlbnRpbmcgY28tYWRhcHRhdGlvbiBvZiBuZXVyb25zLgozLiAqKlBvc2l0aW9uLXdpc2U6KiogVGhlIHNhbWUgRkZOIGlzIGFwcGxpZWQgaW5kZXBlbmRlbnRseSB0byBlYWNoIHBvc2l0aW9uLgoKVGhpcyBtYWtlcyBGRk5zIGNydWNpYWwgZm9yIGNhcHR1cmluZyBub24tbGluZWFyIHJlcHJlc2VudGF0aW9ucyB3aXRoaW4gVHJhbnNmb3JtZXIgYmxvY2tzLg==",
  "starter_code": "import numpy as np\n\ndef ffn(x: list[float], W1: list[list[float]], b1: list[float], W2: list[list[float]], b2: list[float], dropout_p: float=0.1, seed: int=42) -> list[float]:\n\t\"\"\"\n\tImplement a position-wise feed-forward block with residual and dropout.\n\n\tArgs:\n\t\tx: input vector\n\t\tW1, b1: first linear layer parameters\n\t\tW2, b2: second linear layer parameters\n\t\tdropout_p: dropout probability\n\t\tseed: random seed for reproducibility\n\n\tReturns:\n\t\tOutput vector after FFN block (rounded to 4 decimals)\n\t\"\"\"\n\t# Your code here\n\tpass",
  "description_decoded": "Implement a Position-wise Feed-Forward Network (FFN) with residual connection and dropout, as used in Transformer architectures. The block should take an input vector, apply two linear transformations with a ReLU activation in between, then add a residual connection from the input and apply dropout. Round outputs to 4 decimal places for reproducibility.",
  "learn_section_decoded": "## Position-wise Feed-Forward Block in Transformers\n\nIn the Transformer architecture, each encoder and decoder layer contains a **position-wise feed-forward network (FFN)**. It operates independently on each position in the sequence.\n\nThe FFN is defined as:\n\n$$FFN(x) = \\text{Dropout}(W_2(\\text{ReLU}(W_1x + b_1)) + b_2) + x$$\n\nwhere:\n- $x$: Input vector\n- $W_1, b_1$: First linear transformation (expansion)\n- $W_2, b_2$: Second linear transformation (projection back to input dimension)\n- Residual connection: Adds the input $x$ to the transformed output\n- Dropout: Randomly zeros some elements during training to prevent overfitting\n\n### Key Concepts\n1. **Residual Connection:** Helps prevent vanishing gradients by allowing the input to bypass transformations.\n2. **Dropout:** Improves generalization by preventing co-adaptation of neurons.\n3. **Position-wise:** The same FFN is applied independently to each position.\n\nThis makes FFNs crucial for capturing non-linear representations within Transformer blocks."
}