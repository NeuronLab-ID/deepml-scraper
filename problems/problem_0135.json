{
  "description": "Q3JlYXRlIGEgZnVuY3Rpb24gdG8gZGVjaWRlIHdoZW4gdG8gc3RvcCB0cmFpbmluZyBhIG1vZGVsIGVhcmx5IGJhc2VkIG9uIGEgbGlzdCBvZiB2YWxpZGF0aW9uIGxvc3Nlcy4gVGhlIGVhcmx5IHN0b3BwaW5nIGNyaXRlcmlvbiBzaG91bGQgc3RvcCB0cmFpbmluZyBpZiB0aGUgdmFsaWRhdGlvbiBsb3NzIGhhc24ndCBpbXByb3ZlZCBmb3IgYSBzcGVjaWZpZWQgbnVtYmVyIG9mIGVwb2NocyAocGF0aWVuY2UpLCBhbmQgb25seSBjb3VudCBhcyBpbXByb3ZlbWVudCBpZiB0aGUgbG9zcyBkZWNyZWFzZXMgYnkgbW9yZSB0aGFuIGEgY2VydGFpbiB0aHJlc2hvbGQgKG1pbl9kZWx0YSkuIFlvdXIgZnVuY3Rpb24gc2hvdWxkIHJldHVybiB0aGUgZXBvY2ggdG8gc3RvcCBhdCBhbmQgdGhlIGJlc3QgZXBvY2ggdGhhdCBhY2hpZXZlZCB0aGUgbG93ZXN0IHZhbGlkYXRpb24gbG9zcy4=",
  "id": "135",
  "test_cases": [
    {
      "test": "print(early_stopping([0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78], 2, 0.01))",
      "expected_output": "(4, 2)"
    },
    {
      "test": "print(early_stopping([0.9, 0.8, 0.7, 0.6, 0.5], 2, 0.01))",
      "expected_output": "(4, 4)"
    }
  ],
  "difficulty": "easy",
  "video": "",
  "likes": "0",
  "dislikes": "0",
  "example": {
    "input": "[0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78], patience=2, min_delta=0.01",
    "output": "(4, 2)",
    "reasoning": "The best validation loss is 0.75 at epoch 2. There is no improvement greater than 0.01 for the next 2 epochs. Therefore, training should stop at epoch 4."
  },
  "category": "Machine Learning",
  "starter_code": "from typing import Tuple\n\ndef early_stopping(val_losses: list[float], patience: int, min_delta: float) -> Tuple[int, int]:\n    # Your code here\n    pass",
  "title": "Implement Early Stopping Based on Validation Loss",
  "learn_section": "IyMgSW1wbGVtZW50aW5nIEVhcmx5IFN0b3BwaW5nIENyaXRlcmlvbgoKRWFybHkgc3RvcHBpbmcgaXMgYSByZWd1bGFyaXphdGlvbiB0ZWNobmlxdWUgdGhhdCBoZWxwcyBwcmV2ZW50IG92ZXJmaXR0aW5nIGluIG1hY2hpbmUgbGVhcm5pbmcgbW9kZWxzLiBZb3VyIHRhc2sgaXMgdG8gaW1wbGVtZW50IHRoZSBlYXJseSBzdG9wcGluZyBkZWNpc2lvbiBsb2dpYyBiYXNlZCBvbiB0aGUgdmFsaWRhdGlvbiBsb3NzIGhpc3RvcnkuCgojIyMgUHJvYmxlbSBEZXNjcmlwdGlvbgoKR2l2ZW4gYSBzZXF1ZW5jZSBvZiB2YWxpZGF0aW9uIGxvc3NlcyBmcm9tIG1vZGVsIHRyYWluaW5nLCBkZXRlcm1pbmUgaWYgdHJhaW5pbmcgc2hvdWxkIGJlIHN0b3BwZWQgYmFzZWQgb24gdGhlIGZvbGxvd2luZyBjcml0ZXJpYToKCi0gVHJhaW5pbmcgc2hvdWxkIHN0b3AgaWYgdGhlIHZhbGlkYXRpb24gbG9zcyBoYXNuJ3QgaW1wcm92ZWQgKGRlY3JlYXNlZCkgZm9yIGEgc3BlY2lmaWVkIG51bWJlciBvZiBlcG9jaHMgKHBhdGllbmNlKQotIEFuIGltcHJvdmVtZW50IGlzIG9ubHkgY291bnRlZCBpZiB0aGUgbG9zcyBkZWNyZWFzZXMgYnkgbW9yZSB0aGFuIGEgbWluaW11bSB0aHJlc2hvbGQgKG1pbl9kZWx0YSkKLSBUaGUgYmVzdCBtb2RlbCBpcyB0aGUgb25lIHdpdGggdGhlIGxvd2VzdCB2YWxpZGF0aW9uIGxvc3MKCiMjIyBFeGFtcGxlCgpDb25zaWRlciB0aGUgZm9sbG93aW5nIHZhbGlkYXRpb24gbG9zc2VzOiBbMC45LCAwLjgsIDAuNzUsIDAuNzcsIDAuNzYsIDAuNzcsIDAuNzhdCgotIFdpdGggcGF0aWVuY2U9MiBhbmQgbWluX2RlbHRhPTAuMDE6CiAgLSBCZXN0IGxvc3MgaXMgMC43NSBhdCBlcG9jaCAyCiAgLSBObyBpbXByb3ZlbWVudCA+IDAuMDEgZm9yIG5leHQgMiBlcG9jaHMKICAtIFNob3VsZCBzdG9wIGF0IGVwb2NoIDQKCiMjIyBGdW5jdGlvbiBSZXF1aXJlbWVudHMKCi0gUmV0dXJuIGJvdGggdGhlIGVwb2NoIHRvIHN0b3AgYXQgYW5kIHRoZSBiZXN0IGVwb2NoCi0gSWYgbm8gc3RvcHBpbmcgaXMgbmVlZGVkLCByZXR1cm4gdGhlIGxhc3QgZXBvY2gKLSBFcG9jaHMgYXJlIDAtaW5kZXhlZA==",
  "contributor": [
    {
      "profile_link": "https://github.com/emharsha1812",
      "name": "Harshwardhan Fartale"
    }
  ],
  "description_decoded": "Create a function to decide when to stop training a model early based on a list of validation losses. The early stopping criterion should stop training if the validation loss hasn't improved for a specified number of epochs (patience), and only count as improvement if the loss decreases by more than a certain threshold (min_delta). Your function should return the epoch to stop at and the best epoch that achieved the lowest validation loss.",
  "learn_section_decoded": "## Implementing Early Stopping Criterion\n\nEarly stopping is a regularization technique that helps prevent overfitting in machine learning models. Your task is to implement the early stopping decision logic based on the validation loss history.\n\n### Problem Description\n\nGiven a sequence of validation losses from model training, determine if training should be stopped based on the following criteria:\n\n- Training should stop if the validation loss hasn't improved (decreased) for a specified number of epochs (patience)\n- An improvement is only counted if the loss decreases by more than a minimum threshold (min_delta)\n- The best model is the one with the lowest validation loss\n\n### Example\n\nConsider the following validation losses: [0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78]\n\n- With patience=2 and min_delta=0.01:\n  - Best loss is 0.75 at epoch 2\n  - No improvement > 0.01 for next 2 epochs\n  - Should stop at epoch 4\n\n### Function Requirements\n\n- Return both the epoch to stop at and the best epoch\n- If no stopping is needed, return the last epoch\n- Epochs are 0-indexed"
}