{
  "problem_id": 181,
  "title": "Central Limit Theorem Simulation",
  "category": "Probability",
  "difficulty": "medium",
  "description": "Write a Python function that simulates the Central Limit Theorem (CLT). The function should take as input the number of samples, the sample size, and the distribution type ('uniform' or 'exponential'). It should return the mean of the sample means.",
  "example": {
    "input": "simulate_clt(num_samples=1000, sample_size=30, distribution='uniform')",
    "output": "0.4996",
    "reasoning": "We draw 1000 samples of size 30 each from a uniform(0,1) distribution. The mean of sample means is close to 0.5 due to the Central Limit Theorem."
  },
  "starter_code": "import numpy as np\n\ndef simulate_clt(num_samples: int, sample_size: int, distribution: str = 'uniform') -> float:\n\t\"\"\"\n\tSimulate the Central Limit Theorem (CLT).\n\n\tArgs:\n\t\tnum_samples: number of repeated samples to draw\n\t\tsample_size: size of each sample\n\t\tdistribution: 'uniform' or 'exponential'\n\n\tReturns:\n\t\tMean of the sample means (float)\n\t\"\"\"\n\t# Your code here\n\tpass",
  "sub_quests": [
    {
      "step": 1,
      "title": "Random Sampling from Probability Distributions",
      "relation_to_problem": "The CLT simulation requires drawing random samples from specified distributions (uniform and exponential). Understanding how to generate random samples programmatically is the foundation for all subsequent steps.",
      "prerequisites": [
        "Basic Python programming",
        "NumPy library basics",
        "Concept of probability distributions"
      ],
      "learning_objectives": [
        "Understand the mathematical properties of uniform and exponential distributions",
        "Generate random samples from different distributions using NumPy",
        "Verify that generated samples match theoretical distribution properties"
      ],
      "math_content": {
        "definition": "A **probability distribution** is a mathematical function that describes the likelihood of different outcomes in a random experiment. For continuous distributions, the probability density function (PDF) $f(x)$ satisfies: (1) $f(x) \\geq 0$ for all $x$, and (2) $\\int_{-\\infty}^{\\infty} f(x)dx = 1$.",
        "notation": "$X$ = random variable, $f_X(x)$ = probability density function, $F_X(x)$ = cumulative distribution function, $E[X]$ = expected value (mean), $\\text{Var}(X)$ = variance",
        "theorem": "**Uniform Distribution**: A continuous uniform distribution $U(a,b)$ has PDF $f(x) = \\frac{1}{b-a}$ for $x \\in [a,b]$ and $f(x)=0$ otherwise. Its mean is $\\mu = \\frac{a+b}{2}$ and variance is $\\sigma^2 = \\frac{(b-a)^2}{12}$. **Exponential Distribution**: An exponential distribution with rate parameter $\\lambda$ has PDF $f(x) = \\lambda e^{-\\lambda x}$ for $x \\geq 0$. Its mean is $\\mu = \\frac{1}{\\lambda}$ and variance is $\\sigma^2 = \\frac{1}{\\lambda^2}$.",
        "proof_sketch": "For $U(0,1)$: $E[X] = \\int_0^1 x \\cdot 1 dx = [\\frac{x^2}{2}]_0^1 = 0.5$. For exponential with $\\lambda=1$: $E[X] = \\int_0^{\\infty} x \\lambda e^{-\\lambda x} dx = \\frac{1}{\\lambda}$ (using integration by parts).",
        "examples": [
          "For $U(0,1)$: Drawing 1000 samples should give mean $\\approx 0.5$ and variance $\\approx 0.083$",
          "For exponential with $\\lambda=1$: Drawing 1000 samples should give mean $\\approx 1.0$ and variance $\\approx 1.0$"
        ]
      },
      "key_formulas": [
        {
          "name": "Uniform(0,1) Mean",
          "latex": "$\\mu = \\frac{0+1}{2} = 0.5$",
          "description": "Expected value of standard uniform distribution"
        },
        {
          "name": "Uniform(0,1) Variance",
          "latex": "$\\sigma^2 = \\frac{(1-0)^2}{12} = \\frac{1}{12} \\approx 0.083$",
          "description": "Variance of standard uniform distribution"
        },
        {
          "name": "Exponential(λ=1) Mean",
          "latex": "$\\mu = \\frac{1}{\\lambda} = 1$",
          "description": "Expected value of standard exponential distribution"
        },
        {
          "name": "Exponential(λ=1) Variance",
          "latex": "$\\sigma^2 = \\frac{1}{\\lambda^2} = 1$",
          "description": "Variance of standard exponential distribution"
        }
      ],
      "exercise": {
        "description": "Write a function that generates random samples from either a uniform(0,1) or exponential(λ=1) distribution and returns the samples as a NumPy array. This function will be the building block for creating individual samples in the CLT simulation.",
        "function_signature": "def generate_sample(size: int, distribution: str = 'uniform') -> np.ndarray:",
        "starter_code": "import numpy as np\n\ndef generate_sample(size: int, distribution: str = 'uniform') -> np.ndarray:\n    \"\"\"\n    Generate a random sample from specified distribution.\n    \n    Args:\n        size: number of random values to generate\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        NumPy array of random values\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "generate_sample(1000, 'uniform')",
            "expected": "Array with mean ≈ 0.5, all values in [0,1]",
            "explanation": "Uniform(0,1) should produce values between 0 and 1 with mean close to 0.5"
          },
          {
            "input": "generate_sample(1000, 'exponential')",
            "expected": "Array with mean ≈ 1.0, all values ≥ 0",
            "explanation": "Exponential(λ=1) should produce non-negative values with mean close to 1.0"
          },
          {
            "input": "len(generate_sample(50, 'uniform'))",
            "expected": "50",
            "explanation": "Function should return exactly the requested number of samples"
          }
        ]
      },
      "common_mistakes": [
        "Using random.random() instead of np.random functions (incompatible with NumPy operations)",
        "Forgetting that exponential distribution in NumPy uses scale parameter (1/λ) not rate parameter λ",
        "Not setting random seed for reproducibility during testing",
        "Assuming uniform distribution defaults to (0,1) range without verification"
      ],
      "hint": "NumPy provides np.random.uniform() and np.random.exponential() functions. For exponential distribution, np.random.exponential(scale=1.0) generates samples with mean=1.",
      "references": [
        "NumPy random sampling documentation",
        "Probability distributions in statistics",
        "Properties of exponential and uniform distributions"
      ]
    },
    {
      "step": 2,
      "title": "Computing Sample Statistics: The Sample Mean",
      "relation_to_problem": "The CLT concerns the distribution of sample means. We must understand what a sample mean is mathematically and how to compute it from a sample. This is the fundamental statistic we'll track across multiple samples.",
      "prerequisites": [
        "Random sampling from distributions",
        "Basic statistics",
        "Array operations in NumPy"
      ],
      "learning_objectives": [
        "Understand the formal definition of sample mean as an estimator",
        "Compute sample means efficiently using NumPy",
        "Recognize that sample mean is itself a random variable",
        "Understand the relationship between sample mean and population mean"
      ],
      "math_content": {
        "definition": "The **sample mean** $\\bar{X}_n$ is a statistic computed from a random sample $X_1, X_2, \\ldots, X_n$ drawn from a population: $$\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$$ The sample mean is an **unbiased estimator** of the population mean $\\mu$, meaning $E[\\bar{X}_n] = \\mu$.",
        "notation": "$\\bar{X}_n$ or $\\bar{X}$ = sample mean, $n$ = sample size, $X_i$ = individual observations, $\\mu$ = population mean, $E[\\cdot]$ = expectation operator",
        "theorem": "**Properties of Sample Mean**: Let $X_1, \\ldots, X_n$ be i.i.d. random variables with mean $\\mu$ and variance $\\sigma^2$. Then: (1) $E[\\bar{X}_n] = \\mu$ (unbiasedness), (2) $\\text{Var}(\\bar{X}_n) = \\frac{\\sigma^2}{n}$ (variance decreases with sample size), (3) $\\text{SE}(\\bar{X}_n) = \\frac{\\sigma}{\\sqrt{n}}$ (standard error of the mean).",
        "proof_sketch": "Unbiasedness: $E[\\bar{X}_n] = E[\\frac{1}{n}\\sum_{i=1}^n X_i] = \\frac{1}{n}\\sum_{i=1}^n E[X_i] = \\frac{1}{n} \\cdot n\\mu = \\mu$. Variance: $\\text{Var}(\\bar{X}_n) = \\text{Var}(\\frac{1}{n}\\sum_{i=1}^n X_i) = \\frac{1}{n^2}\\sum_{i=1}^n \\text{Var}(X_i) = \\frac{1}{n^2} \\cdot n\\sigma^2 = \\frac{\\sigma^2}{n}$ (using independence).",
        "examples": [
          "For uniform(0,1): If we draw samples of size n=30, each sample mean should be close to 0.5, with most values within $0.5 \\pm \\frac{0.289}{\\sqrt{30}} \\approx 0.5 \\pm 0.053$",
          "For exponential(λ=1): If we draw samples of size n=30, each sample mean should be close to 1.0, with standard error $\\frac{1}{\\sqrt{30}} \\approx 0.183$"
        ]
      },
      "key_formulas": [
        {
          "name": "Sample Mean",
          "latex": "$\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$",
          "description": "Average of n observations from a sample"
        },
        {
          "name": "Expected Value of Sample Mean",
          "latex": "$E[\\bar{X}_n] = \\mu$",
          "description": "Sample mean is an unbiased estimator of population mean"
        },
        {
          "name": "Variance of Sample Mean",
          "latex": "$\\text{Var}(\\bar{X}_n) = \\frac{\\sigma^2}{n}$",
          "description": "Variance decreases proportionally to sample size"
        },
        {
          "name": "Standard Error",
          "latex": "$\\text{SE}(\\bar{X}_n) = \\frac{\\sigma}{\\sqrt{n}}$",
          "description": "Standard deviation of the sampling distribution of the mean"
        }
      ],
      "exercise": {
        "description": "Write a function that takes a sample (as a NumPy array) and computes its mean. Additionally, write a function that generates multiple samples of a given size from a specified distribution and returns an array containing the mean of each sample. This builds toward collecting multiple sample means for CLT analysis.",
        "function_signature": "def compute_sample_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> np.ndarray:",
        "starter_code": "import numpy as np\n\ndef compute_sample_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> np.ndarray:\n    \"\"\"\n    Generate multiple samples and compute the mean of each sample.\n    \n    Args:\n        num_samples: number of samples to generate\n        sample_size: size of each individual sample\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        NumPy array containing the mean of each sample\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "compute_sample_means(1000, 30, 'uniform')",
            "expected": "Array of length 1000 with overall mean ≈ 0.5",
            "explanation": "1000 sample means from uniform(0,1) should average to the population mean of 0.5"
          },
          {
            "input": "compute_sample_means(500, 50, 'exponential')",
            "expected": "Array of length 500 with overall mean ≈ 1.0",
            "explanation": "500 sample means from exponential(λ=1) should average to the population mean of 1.0"
          },
          {
            "input": "np.std(compute_sample_means(10000, 100, 'uniform'))",
            "expected": "Value ≈ 0.029 (theoretical SE = 0.289/√100 = 0.0289)",
            "explanation": "Standard deviation of sample means should match theoretical standard error"
          }
        ]
      },
      "common_mistakes": [
        "Computing the mean of all values across all samples instead of mean of each sample separately",
        "Not storing each sample mean individually (need array of means, not single value)",
        "Confusion between sample standard deviation and standard error of the mean",
        "Using np.mean() incorrectly with multidimensional arrays (forgetting axis parameter)"
      ],
      "hint": "Use a loop to generate each sample, compute its mean with np.mean(), and store results in a list or array. Alternatively, generate all samples at once as a 2D array and use np.mean(axis=1) to compute row-wise means.",
      "references": [
        "Law of Large Numbers",
        "Sampling distributions",
        "Unbiased estimators",
        "Standard error vs standard deviation"
      ]
    },
    {
      "step": 3,
      "title": "Understanding the Central Limit Theorem Mathematically",
      "relation_to_problem": "The CLT is the theoretical foundation of our simulation. Understanding its formal statement, conditions, and implications is essential to interpret what our simulation demonstrates and why it works.",
      "prerequisites": [
        "Sample mean computation",
        "Normal distribution",
        "Convergence in distribution",
        "Basic probability theory"
      ],
      "learning_objectives": [
        "State the Central Limit Theorem formally with proper mathematical notation",
        "Understand the conditions required for CLT to hold",
        "Interpret the standardization formula and its role in CLT",
        "Recognize how sample size affects the approximation to normality"
      ],
      "math_content": {
        "definition": "The **Central Limit Theorem (CLT)** states that for a sequence of independent and identically distributed (i.i.d.) random variables $X_1, X_2, \\ldots, X_n$ with finite mean $\\mu$ and finite variance $\\sigma^2 > 0$, the standardized sample mean converges in distribution to a standard normal distribution as $n \\to \\infty$: $$Z_n = \\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} = \\frac{\\sqrt{n}(\\bar{X}_n - \\mu)}{\\sigma} \\xrightarrow{d} N(0,1)$$ Equivalently, $\\bar{X}_n \\xrightarrow{d} N(\\mu, \\sigma^2/n)$ as $n \\to \\infty$.",
        "notation": "$\\bar{X}_n$ = sample mean, $\\mu$ = population mean, $\\sigma$ = population standard deviation, $n$ = sample size, $Z_n$ = standardized sample mean, $N(0,1)$ = standard normal distribution, $\\xrightarrow{d}$ = convergence in distribution",
        "theorem": "**Central Limit Theorem (Formal Statement)**: Let $X_1, X_2, \\ldots$ be i.i.d. random variables with $E[X_i] = \\mu$ and $\\text{Var}(X_i) = \\sigma^2 < \\infty$. Define $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$. Then for any $z \\in \\mathbb{R}$: $$\\lim_{n \\to \\infty} P\\left(\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\leq z\\right) = \\Phi(z)$$ where $\\Phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^z e^{-t^2/2}dt$ is the CDF of $N(0,1)$.",
        "proof_sketch": "The proof uses characteristic functions (Fourier transforms of distributions). Key steps: (1) Standardize $X_i$ to have mean 0 and variance 1. (2) Show that the characteristic function of $Z_n$ converges to $e^{-t^2/2}$, which is the characteristic function of $N(0,1)$. (3) Apply Lévy's continuity theorem to conclude convergence in distribution. The finite variance assumption ensures that the Taylor expansion of the characteristic function is well-defined.",
        "examples": [
          "**Uniform(0,1)**: Population mean $\\mu=0.5$, variance $\\sigma^2=1/12$. For $n=30$, $\\bar{X}_{30} \\approx N(0.5, 1/(12 \\cdot 30)) = N(0.5, 0.00278)$, so $\\text{SE}=0.0527$.",
          "**Exponential(λ=1)**: Population mean $\\mu=1$, variance $\\sigma^2=1$. For $n=30$, $\\bar{X}_{30} \\approx N(1, 1/30) = N(1, 0.0333)$, so $\\text{SE}=0.1826$. Despite the strong skewness of exponential distribution, the sample mean distribution becomes approximately normal."
        ]
      },
      "key_formulas": [
        {
          "name": "CLT Standardization",
          "latex": "$Z_n = \\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}}$",
          "description": "Standardized sample mean converges to N(0,1)"
        },
        {
          "name": "CLT Distribution Form",
          "latex": "$\\bar{X}_n \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$",
          "description": "Approximate distribution of sample mean for large n"
        },
        {
          "name": "Z-score Formula",
          "latex": "$Z = \\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}}$",
          "description": "Used to standardize sample means for comparison"
        },
        {
          "name": "Standard Normal PDF",
          "latex": "$\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2}$",
          "description": "Probability density function of N(0,1)"
        }
      ],
      "exercise": {
        "description": "Write a function that generates a specified number of sample means from a distribution, then computes the standardized Z-scores using the theoretical population parameters. Return both the array of sample means and their corresponding Z-scores. This demonstrates the standardization step of CLT.",
        "function_signature": "def compute_standardized_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> tuple:",
        "starter_code": "import numpy as np\n\ndef compute_standardized_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> tuple:\n    \"\"\"\n    Generate sample means and compute their standardized Z-scores.\n    \n    Args:\n        num_samples: number of samples to generate\n        sample_size: size of each sample\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        Tuple of (sample_means, z_scores) where both are NumPy arrays\n    \"\"\"\n    # Population parameters\n    if distribution == 'uniform':\n        mu = 0.5\n        sigma = np.sqrt(1/12)\n    else:  # exponential\n        mu = 1.0\n        sigma = 1.0\n    \n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "means, zscores = compute_standardized_means(1000, 30, 'uniform'); np.mean(zscores)",
            "expected": "Value ≈ 0 (mean of Z-scores should be close to 0)",
            "explanation": "Standardized values should have mean approximately 0 according to CLT"
          },
          {
            "input": "means, zscores = compute_standardized_means(1000, 30, 'uniform'); np.std(zscores)",
            "expected": "Value ≈ 1 (standard deviation of Z-scores should be close to 1)",
            "explanation": "Standardized values should have standard deviation approximately 1 according to CLT"
          },
          {
            "input": "means, zscores = compute_standardized_means(500, 50, 'exponential'); len(means) == len(zscores)",
            "expected": "True",
            "explanation": "Should return equal-length arrays of means and z-scores"
          }
        ]
      },
      "common_mistakes": [
        "Using sample standard deviation instead of population standard deviation for standardization",
        "Forgetting to divide by √n in the denominator of Z-score formula",
        "Confusing population parameters (μ, σ) with sample statistics ($\\bar{x}$, s)",
        "Not recognizing that Z-scores themselves should form approximately N(0,1) distribution",
        "Assuming CLT works well for very small sample sizes (n < 30 is often insufficient)"
      ],
      "hint": "For each sample mean $\\bar{x}$, compute $z = \\frac{\\bar{x} - \\mu}{\\sigma/\\sqrt{n}}$ using the known population parameters. For uniform(0,1): μ=0.5, σ²=1/12. For exponential(λ=1): μ=1, σ²=1.",
      "references": [
        "Convergence in distribution",
        "Characteristic functions",
        "Normal approximation",
        "Berry-Esseen theorem (rate of convergence)"
      ]
    },
    {
      "step": 4,
      "title": "The Mean of Sample Means: Law of Large Numbers Connection",
      "relation_to_problem": "Our CLT simulation returns the mean of sample means. Understanding why this value converges to the population mean requires knowledge of the Law of Large Numbers and how it relates to CLT.",
      "prerequisites": [
        "Sample mean computation",
        "CLT understanding",
        "Expected value properties"
      ],
      "learning_objectives": [
        "Understand the Law of Large Numbers and its relationship to CLT",
        "Recognize that the mean of sample means estimates the population mean",
        "Compute and interpret the grand mean (mean of means)",
        "Distinguish between LLN (convergence of means) and CLT (distribution of means)"
      ],
      "math_content": {
        "definition": "The **Law of Large Numbers (LLN)** states that as the number of samples increases, the sample mean converges to the population mean. **Strong LLN**: $\\bar{X}_n \\xrightarrow{a.s.} \\mu$ (almost sure convergence). **Weak LLN**: For any $\\epsilon > 0$, $P(|\\bar{X}_n - \\mu| > \\epsilon) \\to 0$ as $n \\to \\infty$ (convergence in probability). When we compute the **mean of sample means** from $M$ samples, each of size $n$: $$\\bar{\\bar{X}} = \\frac{1}{M}\\sum_{j=1}^M \\bar{X}_{n,j}$$ By LLN, as $M \\to \\infty$, $\\bar{\\bar{X}} \\to E[\\bar{X}_n] = \\mu$.",
        "notation": "$\\bar{X}_n$ = sample mean from one sample, $\\bar{\\bar{X}}$ = mean of sample means (grand mean), $M$ = number of samples, $\\mu$ = population mean, $\\xrightarrow{a.s.}$ = almost sure convergence, $\\xrightarrow{p}$ = convergence in probability",
        "theorem": "**Relationship between LLN and CLT**: LLN tells us WHERE the sample mean converges (to $\\mu$), while CLT tells us HOW it converges (the distribution around $\\mu$). Formally: LLN states $\\bar{X}_n \\xrightarrow{p} \\mu$, while CLT states $\\sqrt{n}(\\bar{X}_n - \\mu) \\xrightarrow{d} N(0, \\sigma^2)$. These are complementary results: LLN describes convergence of the center, CLT describes convergence of the (rescaled) fluctuations around the center.",
        "proof_sketch": "For the mean of sample means: $E[\\bar{\\bar{X}}] = E[\\frac{1}{M}\\sum_{j=1}^M \\bar{X}_{n,j}] = \\frac{1}{M}\\sum_{j=1}^M E[\\bar{X}_{n,j}] = \\frac{1}{M} \\cdot M \\cdot \\mu = \\mu$. The variance is $\\text{Var}(\\bar{\\bar{X}}) = \\frac{1}{M^2}\\sum_{j=1}^M \\text{Var}(\\bar{X}_{n,j}) = \\frac{1}{M^2} \\cdot M \\cdot \\frac{\\sigma^2}{n} = \\frac{\\sigma^2}{Mn}$, which goes to 0 as $M \\to \\infty$ (for fixed $n$), confirming convergence to $\\mu$.",
        "examples": [
          "**Uniform(0,1) with n=30, M=1000**: Each $\\bar{X}_{30}$ has mean 0.5. The grand mean $\\bar{\\bar{X}}$ from 1000 such sample means should be very close to 0.5, typically within ±0.005.",
          "**Exponential(λ=1) with n=30, M=1000**: Each $\\bar{X}_{30}$ has mean 1.0. The grand mean $\\bar{\\bar{X}}$ from 1000 such sample means should be very close to 1.0, typically within ±0.01."
        ]
      },
      "key_formulas": [
        {
          "name": "Mean of Sample Means",
          "latex": "$\\bar{\\bar{X}} = \\frac{1}{M}\\sum_{j=1}^M \\bar{X}_{n,j}$",
          "description": "Grand mean computed from M sample means"
        },
        {
          "name": "Expected Value of Grand Mean",
          "latex": "$E[\\bar{\\bar{X}}] = \\mu$",
          "description": "Grand mean is an unbiased estimator of population mean"
        },
        {
          "name": "Variance of Grand Mean",
          "latex": "$\\text{Var}(\\bar{\\bar{X}}) = \\frac{\\sigma^2}{Mn}$",
          "description": "Variance decreases with both M and n"
        },
        {
          "name": "Standard Error of Grand Mean",
          "latex": "$\\text{SE}(\\bar{\\bar{X}}) = \\frac{\\sigma}{\\sqrt{Mn}}$",
          "description": "Standard deviation of the grand mean"
        }
      ],
      "exercise": {
        "description": "Write a function that generates multiple samples from a distribution, computes the mean of each sample, and then returns the mean of those sample means (the grand mean). Compare this to the theoretical population mean to verify the Law of Large Numbers in action.",
        "function_signature": "def mean_of_sample_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> float:",
        "starter_code": "import numpy as np\n\ndef mean_of_sample_means(num_samples: int, sample_size: int, distribution: str = 'uniform') -> float:\n    \"\"\"\n    Compute the mean of sample means (grand mean).\n    \n    Args:\n        num_samples: number of samples to generate (M)\n        sample_size: size of each sample (n)\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        The mean of all sample means (float)\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "mean_of_sample_means(1000, 30, 'uniform')",
            "expected": "Value ≈ 0.5 (within ±0.01)",
            "explanation": "Grand mean should converge to population mean of uniform(0,1) which is 0.5"
          },
          {
            "input": "mean_of_sample_means(1000, 30, 'exponential')",
            "expected": "Value ≈ 1.0 (within ±0.02)",
            "explanation": "Grand mean should converge to population mean of exponential(λ=1) which is 1.0"
          },
          {
            "input": "abs(mean_of_sample_means(10000, 50, 'uniform') - 0.5) < 0.01",
            "expected": "True (with high probability)",
            "explanation": "With more samples, the grand mean should be even closer to the true mean"
          }
        ]
      },
      "common_mistakes": [
        "Confusing the mean of sample means with the mean of all individual observations",
        "Thinking that increasing M improves the CLT approximation (it's n that matters for CLT, M only improves estimation of μ)",
        "Not recognizing that the grand mean is itself a random variable with its own distribution",
        "Confusing LLN (which guarantees convergence to a value) with CLT (which describes the distribution around that value)"
      ],
      "hint": "Generate M samples, compute the mean of each, store these M means in an array, then compute the mean of that array. This two-level averaging is the essence of the CLT simulation structure.",
      "references": [
        "Law of Large Numbers",
        "Weak vs. strong convergence",
        "Monte Carlo estimation",
        "Relationship between LLN and CLT"
      ]
    },
    {
      "step": 5,
      "title": "Implementing Distribution-Specific Random Sampling",
      "relation_to_problem": "The final simulation must handle different distribution types specified by string input. We need to implement conditional logic that selects the appropriate random number generator and uses the correct population parameters.",
      "prerequisites": [
        "Random sampling from distributions",
        "Conditional logic",
        "NumPy random module",
        "Dictionary data structures"
      ],
      "learning_objectives": [
        "Implement conditional logic to select distribution functions dynamically",
        "Store and retrieve population parameters for different distributions",
        "Handle string-based distribution specification with error checking",
        "Write modular code that can be easily extended to new distributions"
      ],
      "math_content": {
        "definition": "**Parametric distribution families** are sets of probability distributions characterized by a finite number of parameters. For our simulation, we consider: (1) **Uniform family**: $U(a,b)$ with parameters $a$ (lower bound) and $b$ (upper bound). Standard form: $U(0,1)$ with $\\mu=0.5$, $\\sigma^2=1/12$. (2) **Exponential family**: $\\text{Exp}(\\lambda)$ with rate parameter $\\lambda > 0$. Standard form: $\\text{Exp}(1)$ with $\\mu=1$, $\\sigma^2=1$. Each distribution has specific population parameters needed for CLT calculations.",
        "notation": "$U(a,b)$ = uniform distribution, $\\text{Exp}(\\lambda)$ = exponential distribution, $\\lambda$ = rate parameter, $\\beta = 1/\\lambda$ = scale parameter, $\\mu$ = population mean, $\\sigma$ = population standard deviation",
        "theorem": "**Distribution Parameter Relationships**: For $U(a,b)$: $\\mu = \\frac{a+b}{2}$, $\\sigma = \\frac{b-a}{\\sqrt{12}}$. For $\\text{Exp}(\\lambda)$: $\\mu = \\frac{1}{\\lambda}$, $\\sigma = \\frac{1}{\\lambda}$. **Note on NumPy**: np.random.exponential uses scale parameter $\\beta = 1/\\lambda$, not rate parameter. So np.random.exponential(scale=1.0) generates $\\text{Exp}(\\lambda=1)$.",
        "proof_sketch": "Population parameters are derived from the PDF. For $U(0,1)$: $\\mu = \\int_0^1 x \\cdot 1 dx = 0.5$. $E[X^2] = \\int_0^1 x^2 \\cdot 1 dx = 1/3$. $\\sigma^2 = E[X^2] - (E[X])^2 = 1/3 - 1/4 = 1/12$. For $\\text{Exp}(\\lambda=1)$: $\\mu = \\int_0^{\\infty} x e^{-x} dx = 1$ (by integration by parts). $E[X^2] = 2$, so $\\sigma^2 = 2 - 1 = 1$.",
        "examples": [
          "For 'uniform': Use np.random.uniform(0, 1, size) to generate samples, with population parameters μ=0.5, σ²=1/12",
          "For 'exponential': Use np.random.exponential(scale=1.0, size) to generate samples, with population parameters μ=1.0, σ²=1.0"
        ]
      },
      "key_formulas": [
        {
          "name": "Uniform(0,1) Parameters",
          "latex": "$\\mu = 0.5, \\quad \\sigma^2 = \\frac{1}{12}, \\quad \\sigma = \\frac{1}{2\\sqrt{3}} \\approx 0.289$",
          "description": "Population parameters for standard uniform distribution"
        },
        {
          "name": "Exponential(λ=1) Parameters",
          "latex": "$\\mu = 1, \\quad \\sigma^2 = 1, \\quad \\sigma = 1$",
          "description": "Population parameters for standard exponential distribution"
        },
        {
          "name": "NumPy Exponential Scale",
          "latex": "$\\text{scale} = \\beta = \\frac{1}{\\lambda}$",
          "description": "NumPy uses scale parameter, not rate parameter"
        }
      ],
      "exercise": {
        "description": "Write a function that takes a distribution type string and sample size, then returns a random sample from that distribution along with a dictionary containing the population parameters (mean and standard deviation). This creates a reusable component for generating samples with their metadata.",
        "function_signature": "def sample_with_parameters(size: int, distribution: str = 'uniform') -> tuple:",
        "starter_code": "import numpy as np\n\ndef sample_with_parameters(size: int, distribution: str = 'uniform') -> tuple:\n    \"\"\"\n    Generate a sample and return it with population parameters.\n    \n    Args:\n        size: number of random values to generate\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        Tuple of (sample_array, parameters_dict) where parameters_dict\n        contains 'mean' and 'std' keys with population parameter values\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "sample, params = sample_with_parameters(100, 'uniform'); params['mean']",
            "expected": "0.5",
            "explanation": "Should return correct population mean for uniform(0,1)"
          },
          {
            "input": "sample, params = sample_with_parameters(100, 'exponential'); params['std']",
            "expected": "1.0",
            "explanation": "Should return correct population standard deviation for exponential(λ=1)"
          },
          {
            "input": "sample, params = sample_with_parameters(50, 'uniform'); len(sample)",
            "expected": "50",
            "explanation": "Should return sample of correct size"
          },
          {
            "input": "sample, params = sample_with_parameters(100, 'uniform'); all(0 <= x <= 1 for x in sample)",
            "expected": "True",
            "explanation": "Uniform(0,1) samples should all be in [0,1] range"
          }
        ]
      },
      "common_mistakes": [
        "Using rate parameter λ with np.random.exponential (it requires scale parameter 1/λ)",
        "Hardcoding distribution parameters instead of storing them in a data structure",
        "Not validating the distribution string input (should handle invalid values)",
        "Computing sample statistics instead of returning known population parameters",
        "Rounding population parameters unnecessarily (use exact values like 1/12 or np.sqrt(1/12))"
      ],
      "hint": "Create a dictionary mapping distribution names to tuples of (generator_function, mean, std). Use conditional logic or dictionary lookup to select the appropriate distribution. Return both the generated sample and the parameter dictionary.",
      "references": [
        "NumPy random module documentation",
        "Standard form distributions",
        "Parameter estimation vs. known parameters"
      ]
    },
    {
      "step": 6,
      "title": "Complete CLT Simulation: Integrating All Components",
      "relation_to_problem": "This final sub-quest synthesizes all previous concepts to build the complete CLT simulation. You will generate multiple samples, compute their means, and return the mean of sample means—demonstrating both CLT (distribution of means approaches normal) and LLN (mean of means approaches population mean).",
      "prerequisites": [
        "All previous sub-quests",
        "NumPy array operations",
        "Function composition",
        "Statistical interpretation"
      ],
      "learning_objectives": [
        "Integrate random sampling, mean computation, and distribution selection into a complete simulation",
        "Generate and process large numbers of samples efficiently",
        "Interpret the output as demonstrating both CLT and LLN",
        "Understand the dual role of sample size (n) and number of samples (M) in the simulation"
      ],
      "math_content": {
        "definition": "A **Central Limit Theorem simulation** is a computational procedure that empirically demonstrates the CLT by: (1) Drawing $M$ independent random samples, each of size $n$, from a population with mean $\\mu$ and variance $\\sigma^2$. (2) Computing the sample mean $\\bar{X}_{n,j}$ for each sample $j=1,\\ldots,M$. (3) Analyzing the distribution of the $M$ sample means, which should approximate $N(\\mu, \\sigma^2/n)$ for large $n$. (4) Computing the grand mean $\\bar{\\bar{X}} = \\frac{1}{M}\\sum_{j=1}^M \\bar{X}_{n,j}$, which should approximate $\\mu$ for large $M$.",
        "notation": "$M$ = number of samples (repetitions), $n$ = sample size, $\\bar{X}_{n,j}$ = mean of sample $j$, $\\bar{\\bar{X}}$ = mean of sample means (grand mean), $\\mu$ = population mean, $\\sigma^2$ = population variance",
        "theorem": "**Dual Application of Limit Theorems**: The CLT simulation demonstrates two related but distinct phenomena: (1) **CLT**: For fixed $M$ and increasing $n$, the distribution of the $M$ sample means becomes increasingly normal: $\\bar{X}_{n,j} \\xrightarrow{d} N(\\mu, \\sigma^2/n)$ as $n \\to \\infty$. (2) **LLN**: For fixed $n$ and increasing $M$, the grand mean converges to the population mean: $\\bar{\\bar{X}} \\xrightarrow{p} \\mu$ as $M \\to \\infty$. The simulation output (grand mean) primarily demonstrates LLN, while examining the distribution of sample means demonstrates CLT.",
        "proof_sketch": "The theoretical justification combines both theorems: By LLN applied to the sample means (which are i.i.d. with mean $\\mu$), we have $\\bar{\\bar{X}} \\to \\mu$ as $M \\to \\infty$. The accuracy of this approximation is $O(1/\\sqrt{M})$. Simultaneously, each individual $\\bar{X}_{n,j}$ has distribution approximately $N(\\mu, \\sigma^2/n)$ when $n$ is large (by CLT). The simulation generates empirical evidence for both results.",
        "examples": [
          "**Uniform(0,1), n=30, M=1000**: Generate 1000 samples of size 30. Each sample mean is approximately $N(0.5, 0.00278)$. The grand mean of 1000 sample means should be approximately $0.5 \\pm \\frac{0.289}{\\sqrt{1000 \\cdot 30}} \\approx 0.5 \\pm 0.0017$.",
          "**Exponential(λ=1), n=50, M=500**: Generate 500 samples of size 50. Each sample mean is approximately $N(1, 0.02)$. The grand mean should be approximately $1.0 \\pm \\frac{1}{\\sqrt{500 \\cdot 50}} \\approx 1.0 \\pm 0.006$. Despite the strong positive skew of exponential distribution, the sample means are approximately normal."
        ]
      },
      "key_formulas": [
        {
          "name": "CLT Simulation Grand Mean",
          "latex": "$\\bar{\\bar{X}} = \\frac{1}{M}\\sum_{j=1}^M \\bar{X}_{n,j} = \\frac{1}{M}\\sum_{j=1}^M \\left(\\frac{1}{n}\\sum_{i=1}^n X_{ij}\\right)$",
          "description": "Two-level averaging: first within samples, then across samples"
        },
        {
          "name": "Theoretical Standard Error of Grand Mean",
          "latex": "$\\text{SE}(\\bar{\\bar{X}}) = \\frac{\\sigma}{\\sqrt{Mn}}$",
          "description": "Precision improves with both M and n"
        },
        {
          "name": "Sample Mean Distribution (by CLT)",
          "latex": "$\\bar{X}_{n,j} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$ for large $n$",
          "description": "Individual sample means are approximately normal"
        },
        {
          "name": "Grand Mean Convergence (by LLN)",
          "latex": "$\\bar{\\bar{X}} \\xrightarrow{p} \\mu$ as $M \\to \\infty$",
          "description": "Grand mean converges to population mean"
        }
      ],
      "exercise": {
        "description": "Write the complete CLT simulation function that takes the number of samples (M), sample size (n), and distribution type, then returns the mean of sample means. This is the final solution that integrates all concepts from previous sub-quests. DO NOT copy the solution directly—build it using the components you've learned.",
        "function_signature": "def simulate_clt(num_samples: int, sample_size: int, distribution: str = 'uniform') -> float:",
        "starter_code": "import numpy as np\n\ndef simulate_clt(num_samples: int, sample_size: int, distribution: str = 'uniform') -> float:\n    \"\"\"\n    Simulate the Central Limit Theorem (CLT).\n    \n    Args:\n        num_samples: number of repeated samples to draw (M)\n        sample_size: size of each sample (n)\n        distribution: 'uniform' or 'exponential'\n    \n    Returns:\n        Mean of the sample means (float)\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "simulate_clt(1000, 30, 'uniform')",
            "expected": "Value approximately 0.5 (within ±0.02)",
            "explanation": "For uniform(0,1), the grand mean should converge to population mean μ=0.5"
          },
          {
            "input": "simulate_clt(1000, 30, 'exponential')",
            "expected": "Value approximately 1.0 (within ±0.03)",
            "explanation": "For exponential(λ=1), the grand mean should converge to population mean μ=1.0"
          },
          {
            "input": "0.45 <= simulate_clt(5000, 50, 'uniform') <= 0.55",
            "expected": "True (with very high probability)",
            "explanation": "With large M and n, the grand mean should be very close to 0.5"
          },
          {
            "input": "0.95 <= simulate_clt(2000, 100, 'exponential') <= 1.05",
            "expected": "True (with very high probability)",
            "explanation": "With large M and n, the grand mean should be very close to 1.0"
          }
        ]
      },
      "common_mistakes": [
        "Computing the mean of all Mn individual values instead of the mean of M sample means",
        "Not using the correct NumPy functions for each distribution type",
        "Generating all samples in a single call without computing individual sample means",
        "Confusing which parameter (M or n) affects CLT approximation vs. LLN convergence",
        "Returning an array of sample means instead of a single grand mean value",
        "Not handling the distribution parameter correctly (especially exponential scale vs. rate)"
      ],
      "hint": "Structure your solution in clear steps: (1) Initialize an empty list or array to store sample means. (2) Loop M times to generate samples. (3) In each iteration, generate one sample of size n from the specified distribution. (4) Compute and store the mean of that sample. (5) After the loop, compute and return the mean of all stored sample means. Use conditional logic to select the correct NumPy random function based on distribution type.",
      "references": [
        "Monte Carlo methods",
        "Statistical simulation",
        "Empirical verification of theoretical results",
        "Law of Large Numbers vs. Central Limit Theorem",
        "CLT applications in hypothesis testing and confidence intervals"
      ]
    }
  ]
}