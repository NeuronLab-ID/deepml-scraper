{
  "problem_id": 93,
  "title": "Calculate Mean Absolute Error (MAE)",
  "category": "Machine Learning",
  "difficulty": "easy",
  "description": "Implement a function to calculate the Mean Absolute Error (MAE) between two arrays of actual and predicted values. The MAE is a metric used to measure the average magnitude of errors in a set of predictions without considering their direction.",
  "example": {
    "input": "y_true = np.array([3, -0.5, 2, 7]), y_pred = np.array([2.5, 0.0, 2, 8])",
    "output": "0.500",
    "reasoning": "The MAE is calculated by taking the mean of the absolute differences between the predicted and true values. Using the formula, the result is 0.500."
  },
  "starter_code": "import numpy as np\n\ndef mae(y_true, y_pred):\n\t\"\"\"\n\tCalculate Mean Absolute Error between two arrays.\n\n\tParameters:\n\ty_true (numpy.ndarray): Array of true values\n    y_pred (numpy.ndarray): Array of predicted values\n\n\tReturns:\n\tfloat: Mean Absolute Error rounded to 3 decimal places\n\t\"\"\"\n\t# Your code here\n\tpass\n\treturn round(val,3)",
  "sub_quests": [
    {
      "step": 1,
      "title": "Understanding Absolute Value and Distance Metrics",
      "relation_to_problem": "The absolute value function |x| is the core operation in MAE, transforming signed errors into magnitudes that measure prediction distance without directional bias.",
      "prerequisites": [
        "Basic arithmetic",
        "Number line concept",
        "Signed numbers"
      ],
      "learning_objectives": [
        "Define the absolute value function formally using piecewise notation",
        "Compute absolute differences between pairs of numbers",
        "Understand the geometric interpretation of absolute value as distance"
      ],
      "math_content": {
        "definition": "The **absolute value** of a real number $x$, denoted $|x|$, is defined as the distance from $x$ to zero on the real number line. Formally, it is a piecewise function:\n\n$$|x| = \\begin{cases} x & \\text{if } x \\geq 0 \\\\ -x & \\text{if } x < 0 \\end{cases}$$\n\nThe **absolute difference** between two real numbers $a$ and $b$ is defined as $|a - b|$, which measures the distance between them regardless of order: $|a - b| = |b - a|$.",
        "notation": "$|x|$ = absolute value of $x$\n$a, b \\in \\mathbb{R}$ = real numbers\n$|a - b|$ = distance between $a$ and $b$",
        "theorem": "**Triangle Inequality:** For all real numbers $x$ and $y$, $|x + y| \\leq |x| + |y|$. This fundamental property ensures that absolute value respects the metric axioms.",
        "proof_sketch": "The absolute value function satisfies three key properties:\n1. **Non-negativity:** $|x| \\geq 0$ for all $x$, with $|x| = 0$ if and only if $x = 0$\n2. **Symmetry:** $|-x| = |x|$ for all $x$\n3. **Triangle inequality:** $|x + y| \\leq |x| + |y|$\n\nThese properties make absolute value an L₁ norm in one dimension.",
        "examples": [
          "Example 1: $|5| = 5$ (positive number unchanged)",
          "Example 2: $|-3| = 3$ (negative number becomes positive)",
          "Example 3: $|7 - 9| = |-2| = 2$ (distance between 7 and 9)",
          "Example 4: For predicted value $\\hat{y} = 2.5$ and actual value $y = 3$, the absolute error is $|3 - 2.5| = 0.5$"
        ]
      },
      "key_formulas": [
        {
          "name": "Absolute Value Definition",
          "latex": "$|x| = \\begin{cases} x & \\text{if } x \\geq 0 \\\\ -x & \\text{if } x < 0 \\end{cases}$",
          "description": "Use this to compute the magnitude of any signed number"
        },
        {
          "name": "Absolute Difference",
          "latex": "$|a - b|$",
          "description": "Computes distance between two numbers; order doesn't matter"
        }
      ],
      "exercise": {
        "description": "Implement a function that computes the absolute difference between two numbers. This is the fundamental operation for each individual error term in MAE calculation.",
        "function_signature": "def absolute_difference(a: float, b: float) -> float:",
        "starter_code": "def absolute_difference(a: float, b: float) -> float:\n    \"\"\"\n    Calculate the absolute difference between two numbers.\n    \n    Parameters:\n    a (float): First number\n    b (float): Second number\n    \n    Returns:\n    float: The absolute difference |a - b|\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "absolute_difference(3, 2.5)",
            "expected": "0.5",
            "explanation": "The difference 3 - 2.5 = 0.5 is already positive, so |0.5| = 0.5"
          },
          {
            "input": "absolute_difference(-0.5, 0.0)",
            "expected": "0.5",
            "explanation": "The difference -0.5 - 0.0 = -0.5, so |-0.5| = 0.5"
          },
          {
            "input": "absolute_difference(7, 8)",
            "expected": "1.0",
            "explanation": "The difference 7 - 8 = -1, so |-1| = 1"
          },
          {
            "input": "absolute_difference(2, 2)",
            "expected": "0.0",
            "explanation": "When numbers are equal, the absolute difference is zero"
          }
        ]
      },
      "common_mistakes": [
        "Forgetting to handle negative differences (e.g., returning -1 instead of 1)",
        "Computing |a| - |b| instead of |a - b| (these are not equivalent)",
        "Thinking absolute value changes the order of operations in complex expressions"
      ],
      "hint": "The built-in abs() function in Python implements the absolute value operation, or you can use conditional logic based on the sign.",
      "references": [
        "L₁ norm and Manhattan distance",
        "Metric spaces and distance functions",
        "Error magnitude in regression"
      ]
    },
    {
      "step": 2,
      "title": "Array Operations and Element-wise Computation",
      "relation_to_problem": "MAE requires computing absolute differences element-by-element between two arrays of predictions and actual values, which demands understanding vectorized operations.",
      "prerequisites": [
        "Absolute value function",
        "Basic array/list manipulation",
        "Iteration concepts"
      ],
      "learning_objectives": [
        "Understand element-wise operations between arrays of equal length",
        "Apply a function to corresponding pairs of elements from two arrays",
        "Generate a new array containing computed results"
      ],
      "math_content": {
        "definition": "Let $\\mathbf{a} = (a_1, a_2, \\ldots, a_n)$ and $\\mathbf{b} = (b_1, b_2, \\ldots, b_n)$ be two vectors (arrays) in $\\mathbb{R}^n$. An **element-wise operation** $f$ produces a new vector $\\mathbf{c} = (c_1, c_2, \\ldots, c_n)$ where $c_i = f(a_i, b_i)$ for each $i \\in \\{1, 2, \\ldots, n\\}$.\n\nFor the specific case of absolute differences:\n$$\\mathbf{c}_i = |a_i - b_i| \\quad \\text{for } i = 1, 2, \\ldots, n$$",
        "notation": "$\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n$ = vectors in n-dimensional real space\n$a_i$ = the $i$-th component of vector $\\mathbf{a}$\n$n$ = dimension/length of vectors\n$f: \\mathbb{R} \\times \\mathbb{R} \\rightarrow \\mathbb{R}$ = binary operation applied element-wise",
        "theorem": "**Dimension Preservation:** If vectors $\\mathbf{a}$ and $\\mathbf{b}$ both have dimension $n$, then any element-wise operation produces a result vector of dimension $n$. This requires that $\\text{dim}(\\mathbf{a}) = \\text{dim}(\\mathbf{b})$ for the operation to be well-defined.",
        "proof_sketch": "Element-wise operations are well-defined only when vectors have equal dimensions. Given $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^n$:\n1. Each pair $(a_i, b_i)$ exists for $i = 1, \\ldots, n$\n2. Applying $f$ to each pair produces exactly $n$ results\n3. The resulting vector $\\mathbf{c} = (f(a_1, b_1), \\ldots, f(a_n, b_n))$ has dimension $n$\n\nThis forms the basis for vectorized computation in numerical libraries.",
        "examples": [
          "Example 1: $\\mathbf{y} = [3, -0.5, 2, 7]$, $\\hat{\\mathbf{y}} = [2.5, 0.0, 2, 8]$",
          "Element-wise absolute differences: $|3-2.5|=0.5$, $|-0.5-0.0|=0.5$, $|2-2|=0$, $|7-8|=1$",
          "Result vector: $[0.5, 0.5, 0, 1]$",
          "Example 2: For $\\mathbf{a} = [1, 2, 3]$ and $\\mathbf{b} = [4, 1, 5]$: absolute differences give $[3, 1, 2]$"
        ]
      },
      "key_formulas": [
        {
          "name": "Element-wise Absolute Difference",
          "latex": "$\\mathbf{e} = (|a_1 - b_1|, |a_2 - b_2|, \\ldots, |a_n - b_n|)$",
          "description": "Creates an error vector where each component is the absolute difference of corresponding elements"
        },
        {
          "name": "Index Notation",
          "latex": "$e_i = |a_i - b_i|$ for $i = 1, \\ldots, n$",
          "description": "Compact notation for the $i$-th element of the error vector"
        }
      ],
      "exercise": {
        "description": "Implement a function that takes two arrays of equal length and returns a new array containing the absolute difference for each corresponding pair of elements. This produces the error vector needed for MAE.",
        "function_signature": "def compute_absolute_errors(y_true: list, y_pred: list) -> list:",
        "starter_code": "def compute_absolute_errors(y_true: list, y_pred: list) -> list:\n    \"\"\"\n    Compute element-wise absolute differences between two arrays.\n    \n    Parameters:\n    y_true (list): Array of actual values\n    y_pred (list): Array of predicted values\n    \n    Returns:\n    list: Array of absolute errors |y_true[i] - y_pred[i]|\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "compute_absolute_errors([3, -0.5, 2, 7], [2.5, 0.0, 2, 8])",
            "expected": "[0.5, 0.5, 0, 1]",
            "explanation": "Element-wise: |3-2.5|=0.5, |-0.5-0|=0.5, |2-2|=0, |7-8|=1"
          },
          {
            "input": "compute_absolute_errors([1, 2, 3], [1, 2, 3])",
            "expected": "[0, 0, 0]",
            "explanation": "Perfect predictions result in all zero errors"
          },
          {
            "input": "compute_absolute_errors([5], [3])",
            "expected": "[2]",
            "explanation": "Works for single-element arrays: |5-3|=2"
          },
          {
            "input": "compute_absolute_errors([10, -5, 0], [8, -3, 1])",
            "expected": "[2, 2, 1]",
            "explanation": "Handles positive, negative, and zero values correctly"
          }
        ]
      },
      "common_mistakes": [
        "Attempting to operate on arrays of different lengths without validation",
        "Using array subtraction without element-wise absolute value",
        "Modifying input arrays instead of creating a new result array",
        "Incorrect indexing in loops (off-by-one errors)"
      ],
      "hint": "Use a loop to iterate through indices, or leverage list comprehension for concise element-wise operations. Ensure both arrays have the same length.",
      "references": [
        "NumPy vectorized operations",
        "Broadcasting in array libraries",
        "Element-wise vs. matrix multiplication"
      ]
    },
    {
      "step": 3,
      "title": "Summation Notation and Aggregate Operations",
      "relation_to_problem": "After computing individual errors, MAE requires summing all absolute errors - understanding summation notation and aggregate operations is essential for the next step of averaging.",
      "prerequisites": [
        "Sequences and arrays",
        "Basic arithmetic",
        "Iteration"
      ],
      "learning_objectives": [
        "Understand sigma notation for expressing sums mathematically",
        "Compute the sum of all elements in an array",
        "Relate summation to the accumulation of multiple error terms"
      ],
      "math_content": {
        "definition": "**Summation** is an operation that adds a sequence of numbers. The summation of a sequence $(x_1, x_2, \\ldots, x_n)$ is denoted using sigma notation:\n\n$$\\sum_{i=1}^{n} x_i = x_1 + x_2 + x_3 + \\cdots + x_n$$\n\nwhere:\n- $\\sum$ (capital Greek sigma) denotes summation\n- $i$ is the **index of summation** (dummy variable)\n- $i=1$ is the **lower bound** (starting index)\n- $n$ is the **upper bound** (ending index)\n- $x_i$ is the **summand** (general term being summed)",
        "notation": "$\\sum_{i=1}^{n} x_i$ = sum of $x_i$ from $i=1$ to $i=n$\n$n$ = number of terms in the sum\n$x_i$ = the $i$-th term in the sequence",
        "theorem": "**Linearity of Summation:** For sequences $(x_i)$ and $(y_i)$ and constants $a, b \\in \\mathbb{R}$:\n\n$$\\sum_{i=1}^{n} (a \\cdot x_i + b \\cdot y_i) = a \\sum_{i=1}^{n} x_i + b \\sum_{i=1}^{n} y_i$$\n\nThis property allows us to factor out constants and split sums.",
        "proof_sketch": "The summation operator distributes over addition:\n$$\\sum_{i=1}^{n} (x_i + y_i) = (x_1 + y_1) + (x_2 + y_2) + \\cdots + (x_n + y_n)$$\n\nRearranging using commutativity and associativity of addition:\n$$= (x_1 + x_2 + \\cdots + x_n) + (y_1 + y_2 + \\cdots + y_n) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i$$\n\nConstants factor out since $a \\cdot x_1 + a \\cdot x_2 + \\cdots + a \\cdot x_n = a(x_1 + x_2 + \\cdots + x_n)$.",
        "examples": [
          "Example 1: $\\sum_{i=1}^{4} i = 1 + 2 + 3 + 4 = 10$",
          "Example 2: For error vector $[0.5, 0.5, 0, 1]$: $\\sum_{i=1}^{4} e_i = 0.5 + 0.5 + 0 + 1 = 2.0$",
          "Example 3: Empty sum (n=0): $\\sum_{i=1}^{0} x_i = 0$ by convention",
          "Example 4: For MAE calculation, we sum absolute errors: $\\sum_{i=1}^{n} |y_i - \\hat{y}_i|$"
        ]
      },
      "key_formulas": [
        {
          "name": "General Summation",
          "latex": "$\\sum_{i=1}^{n} x_i = x_1 + x_2 + \\cdots + x_n$",
          "description": "Adds all elements from index 1 to n"
        },
        {
          "name": "Sum of Absolute Errors",
          "latex": "$\\sum_{i=1}^{n} |y_i - \\hat{y}_i|$",
          "description": "Total absolute error across all predictions - the numerator in MAE formula"
        },
        {
          "name": "Constant Factor Property",
          "latex": "$\\sum_{i=1}^{n} c \\cdot x_i = c \\cdot \\sum_{i=1}^{n} x_i$",
          "description": "Constants can be moved outside the summation"
        }
      ],
      "exercise": {
        "description": "Implement a function that computes the sum of all elements in an array. This operation aggregates individual errors into a total error, which is then averaged to obtain MAE.",
        "function_signature": "def sum_array(arr: list) -> float:",
        "starter_code": "def sum_array(arr: list) -> float:\n    \"\"\"\n    Calculate the sum of all elements in an array.\n    \n    Parameters:\n    arr (list): Array of numerical values\n    \n    Returns:\n    float: The sum of all elements\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "sum_array([0.5, 0.5, 0, 1])",
            "expected": "2.0",
            "explanation": "0.5 + 0.5 + 0 + 1 = 2.0 (sum of absolute errors from previous example)"
          },
          {
            "input": "sum_array([1, 2, 3, 4, 5])",
            "expected": "15",
            "explanation": "1 + 2 + 3 + 4 + 5 = 15"
          },
          {
            "input": "sum_array([10])",
            "expected": "10",
            "explanation": "Sum of single element is the element itself"
          },
          {
            "input": "sum_array([-1, 1, -2, 2])",
            "expected": "0",
            "explanation": "Positive and negative values can cancel: -1 + 1 + (-2) + 2 = 0"
          },
          {
            "input": "sum_array([])",
            "expected": "0",
            "explanation": "Empty sum equals zero by convention"
          }
        ]
      },
      "common_mistakes": [
        "Not initializing accumulator to zero before summing",
        "Forgetting to handle empty arrays (should return 0)",
        "Using wrong data types that cause integer division issues",
        "Confusing sum with other aggregate operations like product"
      ],
      "hint": "Initialize a variable to store the running total, iterate through the array, and add each element to the total. Python's built-in sum() function also implements this.",
      "references": [
        "Aggregate functions in data analysis",
        "Reduction operations",
        "Accumulator pattern in programming"
      ]
    },
    {
      "step": 4,
      "title": "Arithmetic Mean and Averaging Operations",
      "relation_to_problem": "MAE divides the sum of absolute errors by the number of observations to obtain the mean (average) error, making the metric independent of dataset size.",
      "prerequisites": [
        "Summation",
        "Division",
        "Understanding of central tendency"
      ],
      "learning_objectives": [
        "Define the arithmetic mean formally",
        "Compute the mean of an array of values",
        "Understand why dividing by n normalizes the error metric"
      ],
      "math_content": {
        "definition": "The **arithmetic mean** (or average) of a sequence of $n$ real numbers $(x_1, x_2, \\ldots, x_n)$ is defined as:\n\n$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{x_1 + x_2 + \\cdots + x_n}{n}$$\n\nThe mean represents the central value of a dataset and minimizes the sum of squared deviations. For MAE, we compute the mean of absolute errors:\n\n$$\\text{Mean of absolute errors} = \\frac{1}{n} \\sum_{i=1}^{n} |e_i|$$\n\nwhere $e_i = y_i - \\hat{y}_i$ is the prediction error for the $i$-th observation.",
        "notation": "$\\bar{x}$ = sample mean (x-bar)\n$n$ = number of observations (sample size)\n$\\sum_{i=1}^{n} x_i$ = sum of all observations\n$\\frac{1}{n}$ = normalization factor",
        "theorem": "**Normalization Property:** The mean scales linearly with the sum but is independent of sample size when comparing datasets. Specifically:\n1. If all values are multiplied by constant $c$: $\\overline{cx} = c\\bar{x}$\n2. If constant $c$ is added to all values: $\\overline{x+c} = \\bar{x} + c$\n3. The mean of a uniform sample equals the common value\n\n**Division by n:** This normalization ensures that MAE represents a per-observation average error rather than total error, enabling fair comparisons across datasets of different sizes.",
        "proof_sketch": "The mean satisfies key properties:\n\n**Linearity:** Using summation properties,\n$$\\overline{cx} = \\frac{1}{n}\\sum_{i=1}^{n} cx_i = \\frac{c}{n}\\sum_{i=1}^{n} x_i = c\\bar{x}$$\n\n**Translation Invariance of Deviation:** The mean minimizes $\\sum_{i=1}^{n}(x_i - a)^2$ over all $a \\in \\mathbb{R}$, with the minimum occurring at $a = \\bar{x}$.\n\n**Why divide by n?** Without normalization, the sum of errors would grow with dataset size. A dataset with 1000 observations would have ~10x larger total error than one with 100 observations, even with identical per-observation accuracy. Division by $n$ makes the metric size-invariant.",
        "examples": [
          "Example 1: For $[0.5, 0.5, 0, 1]$ with $n=4$: mean $= \\frac{0.5+0.5+0+1}{4} = \\frac{2.0}{4} = 0.5$",
          "Example 2: Dataset with 4 errors summing to 2.0 has MAE = 0.5; dataset with 8 errors summing to 4.0 also has MAE = 0.5",
          "Example 3: Perfect predictions give errors $[0, 0, 0, 0]$, so mean = $\\frac{0}{4} = 0$",
          "Example 4: For $[2, 4, 6, 8]$: mean $= \\frac{20}{4} = 5$ (the central value)"
        ]
      },
      "key_formulas": [
        {
          "name": "Arithmetic Mean",
          "latex": "$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$",
          "description": "Divides the sum by the count to get average"
        },
        {
          "name": "Mean Absolute Error Formula (Complete)",
          "latex": "$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$",
          "description": "Average of absolute differences - this is the final MAE formula"
        },
        {
          "name": "Sample Size",
          "latex": "$n = |\\{x_1, x_2, \\ldots, x_n\\}|$",
          "description": "Count of observations; denominator in mean calculation"
        }
      ],
      "exercise": {
        "description": "Implement a function that calculates the arithmetic mean of an array. This operation converts the sum of absolute errors into the final MAE by dividing by the number of observations.",
        "function_signature": "def calculate_mean(arr: list) -> float:",
        "starter_code": "def calculate_mean(arr: list) -> float:\n    \"\"\"\n    Calculate the arithmetic mean (average) of an array.\n    \n    Parameters:\n    arr (list): Array of numerical values\n    \n    Returns:\n    float: The arithmetic mean of the array\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "calculate_mean([0.5, 0.5, 0, 1])",
            "expected": "0.5",
            "explanation": "Sum is 2.0, count is 4, so mean = 2.0/4 = 0.5 (this is the MAE)"
          },
          {
            "input": "calculate_mean([1, 2, 3, 4, 5])",
            "expected": "3.0",
            "explanation": "Sum is 15, count is 5, so mean = 15/5 = 3.0"
          },
          {
            "input": "calculate_mean([10, 10, 10])",
            "expected": "10.0",
            "explanation": "All values equal means the mean equals that value"
          },
          {
            "input": "calculate_mean([2.5])",
            "expected": "2.5",
            "explanation": "Mean of single element is the element itself"
          },
          {
            "input": "calculate_mean([0, 0, 0, 0])",
            "expected": "0.0",
            "explanation": "Mean of all zeros is zero (perfect predictions case)"
          }
        ]
      },
      "common_mistakes": [
        "Not handling the empty array case (division by zero)",
        "Using integer division instead of float division (Python 2 vs 3)",
        "Forgetting that mean requires both sum AND count",
        "Computing median or mode instead of mean"
      ],
      "hint": "Divide the sum of all elements by the number of elements. Watch out for empty arrays where division by zero would occur.",
      "references": [
        "Measures of central tendency",
        "Sample mean vs population mean",
        "Arithmetic vs geometric vs harmonic means"
      ]
    },
    {
      "step": 5,
      "title": "Composing Functions: Building the Complete MAE Pipeline",
      "relation_to_problem": "MAE computation requires chaining multiple operations: element-wise absolute differences, summation, and averaging. Understanding function composition creates the complete solution.",
      "prerequisites": [
        "Absolute difference",
        "Element-wise operations",
        "Summation",
        "Mean calculation"
      ],
      "learning_objectives": [
        "Combine multiple mathematical operations into a pipeline",
        "Understand the order of operations in MAE calculation",
        "Implement intermediate steps that build toward the final metric"
      ],
      "math_content": {
        "definition": "**Function composition** applies multiple functions in sequence, where the output of one function becomes the input to the next. For MAE, we compose three operations:\n\n1. **Element-wise absolute difference** (vectorization): $f: \\mathbb{R}^n \\times \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$\n   $$\\mathbf{e} = f(\\mathbf{y}, \\hat{\\mathbf{y}}) = (|y_1 - \\hat{y}_1|, \\ldots, |y_n - \\hat{y}_n|)$$\n\n2. **Summation** (reduction): $g: \\mathbb{R}^n \\rightarrow \\mathbb{R}$\n   $$S = g(\\mathbf{e}) = \\sum_{i=1}^{n} e_i$$\n\n3. **Averaging** (normalization): $h: \\mathbb{R} \\rightarrow \\mathbb{R}$\n   $$\\text{MAE} = h(S) = \\frac{S}{n}$$\n\nThe complete MAE is the composition: $\\text{MAE} = h \\circ g \\circ f$",
        "notation": "$f \\circ g$ = function composition (read \"f after g\")\n$(f \\circ g)(x) = f(g(x))$ = apply $g$ first, then $f$\n$\\mathbb{R}^n \\rightarrow \\mathbb{R}$ = function mapping n-dimensional vector to scalar",
        "theorem": "**MAE as Composed Metric:** The Mean Absolute Error can be expressed as a composition of three functions:\n\n$$\\text{MAE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n\nThis formulation makes MAE:\n1. **Scale-independent**: Comparing errors of different magnitudes fairly\n2. **Outlier-robust**: Using L₁ norm rather than L₂ (squared) norm\n3. **Interpretable**: Result is in same units as original data\n4. **Size-invariant**: Division by $n$ normalizes across dataset sizes",
        "proof_sketch": "**Composition correctness:** Let's verify the pipeline produces MAE:\n\nStarting with $\\mathbf{y} \\in \\mathbb{R}^n$ and $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$:\n\n**Step 1:** Apply element-wise absolute difference\n$$\\mathbf{e} = (|y_1 - \\hat{y}_1|, |y_2 - \\hat{y}_2|, \\ldots, |y_n - \\hat{y}_n|)$$\nResult: error vector $\\mathbf{e} \\in \\mathbb{R}^n$\n\n**Step 2:** Apply summation\n$$S = e_1 + e_2 + \\cdots + e_n = \\sum_{i=1}^{n} e_i = \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\nResult: total absolute error $S \\in \\mathbb{R}$\n\n**Step 3:** Apply normalization\n$$\\text{MAE} = \\frac{S}{n} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\nResult: mean absolute error (scalar)\n\nThis matches the formal definition of MAE, confirming the composition is correct.",
        "examples": [
          "Example: Complete MAE calculation for $\\mathbf{y} = [3, -0.5, 2, 7]$, $\\hat{\\mathbf{y}} = [2.5, 0.0, 2, 8]$",
          "Step 1 (differences): $\\mathbf{e} = [0.5, 0.5, 0, 1]$",
          "Step 2 (sum): $S = 0.5 + 0.5 + 0 + 1 = 2.0$",
          "Step 3 (mean): $\\text{MAE} = 2.0 / 4 = 0.5$",
          "Alternative formulation: $\\text{MAE} = \\frac{1}{4}(|3-2.5| + |-0.5-0| + |2-2| + |7-8|) = \\frac{1}{4}(0.5+0.5+0+1) = 0.5$"
        ]
      },
      "key_formulas": [
        {
          "name": "MAE Pipeline (Step-by-Step)",
          "latex": "$\\mathbf{e} \\xrightarrow{\\text{errors}} S \\xrightarrow{\\text{sum}} \\text{MAE} \\xrightarrow{\\text{mean}}$",
          "description": "Three-stage pipeline: compute errors, sum them, then average"
        },
        {
          "name": "Complete MAE Formula",
          "latex": "$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$",
          "description": "The final metric combining all operations"
        },
        {
          "name": "MAE Properties",
          "latex": "$\\text{MAE} \\geq 0$ and $\\text{MAE} = 0 \\iff \\mathbf{y} = \\hat{\\mathbf{y}}$",
          "description": "Non-negative; zero if and only if predictions are perfect"
        }
      ],
      "exercise": {
        "description": "Implement a function that computes MAE by composing the three operations: (1) compute element-wise absolute errors, (2) sum the errors, (3) divide by count. Do NOT use the final MAE solution directly; instead, explicitly call helper functions or implement each step.",
        "function_signature": "def mean_absolute_error_pipeline(y_true: list, y_pred: list) -> float:",
        "starter_code": "def mean_absolute_error_pipeline(y_true: list, y_pred: list) -> float:\n    \"\"\"\n    Calculate MAE by composing three operations:\n    1. Compute absolute differences element-wise\n    2. Sum all absolute differences\n    3. Divide by the number of observations\n    \n    Parameters:\n    y_true (list): Array of actual values\n    y_pred (list): Array of predicted values\n    \n    Returns:\n    float: Mean Absolute Error\n    \"\"\"\n    # Step 1: Compute absolute errors for each element\n    # (your code here)\n    \n    # Step 2: Sum all the errors\n    # (your code here)\n    \n    # Step 3: Divide by count to get mean\n    # (your code here)\n    \n    pass",
        "test_cases": [
          {
            "input": "mean_absolute_error_pipeline([3, -0.5, 2, 7], [2.5, 0.0, 2, 8])",
            "expected": "0.5",
            "explanation": "Errors: [0.5, 0.5, 0, 1], Sum: 2.0, Count: 4, MAE: 2.0/4 = 0.5"
          },
          {
            "input": "mean_absolute_error_pipeline([1, 2, 3], [1, 2, 3])",
            "expected": "0.0",
            "explanation": "Perfect predictions: all errors are 0, MAE = 0"
          },
          {
            "input": "mean_absolute_error_pipeline([10], [15])",
            "expected": "5.0",
            "explanation": "Single observation: |10-15| = 5, MAE = 5/1 = 5.0"
          },
          {
            "input": "mean_absolute_error_pipeline([1, 2, 3, 4], [2, 3, 4, 5])",
            "expected": "1.0",
            "explanation": "All predictions off by 1: errors [1,1,1,1], MAE = 4/4 = 1.0"
          },
          {
            "input": "mean_absolute_error_pipeline([100, 200], [110, 180])",
            "expected": "15.0",
            "explanation": "Errors: [10, 20], Sum: 30, Count: 2, MAE: 30/2 = 15.0"
          }
        ]
      },
      "common_mistakes": [
        "Computing the sum correctly but forgetting to divide by n",
        "Dividing by the wrong count (e.g., sum of values instead of length)",
        "Not handling arrays of length 1 correctly",
        "Computing squared errors (MSE) instead of absolute errors (MAE)",
        "Forgetting to take absolute value of differences"
      ],
      "hint": "Break the problem into three distinct steps and store intermediate results. You can reuse functions from previous sub-quests or implement each step inline.",
      "references": [
        "Pipeline design patterns",
        "L₁ loss functions in machine learning",
        "Regression evaluation metrics"
      ]
    },
    {
      "step": 6,
      "title": "Numerical Precision and Rounding in Error Metrics",
      "relation_to_problem": "The final MAE implementation requires rounding to 3 decimal places for consistent reporting. Understanding floating-point precision and rounding ensures reliable numeric output.",
      "prerequisites": [
        "MAE calculation",
        "Floating-point arithmetic",
        "Rounding concepts"
      ],
      "learning_objectives": [
        "Understand floating-point representation limitations",
        "Apply proper rounding to a specified number of decimal places",
        "Handle edge cases in numerical computation"
      ],
      "math_content": {
        "definition": "**Rounding** is the process of reducing the number of significant digits in a number while preserving its approximate value. For rounding to $d$ decimal places, we use:\n\n$$\\text{round}(x, d) = \\frac{\\lfloor x \\cdot 10^d + 0.5 \\rfloor}{10^d}$$\n\nThis is **round-half-up** (or round-half-away-from-zero for negative numbers). Python's `round()` function uses **round-half-to-even** (banker's rounding) to avoid systematic bias.\n\n**Floating-point precision:** Computers represent real numbers with finite precision (typically 53 bits for mantissa in double precision). This causes small rounding errors:\n$$0.1 + 0.2 \\neq 0.3 \\text{ (in floating-point arithmetic)}$$\n\nFor MAE reporting, we round to 3 decimal places: $\\text{MAE}_{\\text{rounded}} = \\text{round}(\\text{MAE}, 3)$",
        "notation": "$\\lfloor x \\rfloor$ = floor function (largest integer ≤ x)\n$\\lceil x \\rceil$ = ceiling function (smallest integer ≥ x)\n$\\text{round}(x, d)$ = round x to d decimal places\nIEEE 754 = standard for floating-point arithmetic",
        "theorem": "**Rounding Error Bound:** When rounding a number to $d$ decimal places, the absolute error is bounded:\n\n$$|x - \\text{round}(x, d)| \\leq \\frac{1}{2} \\cdot 10^{-d}$$\n\nFor $d=3$: $|x - \\text{round}(x, 3)| \\leq 0.0005$\n\n**Stability:** For well-conditioned problems, rounding the final result (rather than intermediate values) minimizes accumulated error.",
        "proof_sketch": "**Rounding error bound proof:**\n\nWhen rounding to $d$ decimal places, we're mapping $x$ to the nearest multiple of $10^{-d}$. The maximum distance from $x$ to the nearest such multiple is half the gap between consecutive multiples:\n\n$$\\max |x - \\text{round}(x, d)| = \\frac{10^{-d}}{2}$$\n\nFor $d=3$: multiples are at $0.001$ intervals, so maximum error is $0.001/2 = 0.0005$.\n\n**Why round at the end?** Each arithmetic operation introduces small floating-point errors (machine epsilon $\\epsilon \\approx 2.22 \\times 10^{-16}$ for double precision). Rounding intermediate results can amplify these errors through subsequent operations. Rounding only the final result minimizes total error accumulation.",
        "examples": [
          "Example 1: $\\text{round}(0.5, 3) = 0.500$ (already at 3 decimals)",
          "Example 2: $\\text{round}(0.12345, 3) = 0.123$ (truncates extra digits)",
          "Example 3: $\\text{round}(0.12349, 3) = 0.123$ (rounds down)",
          "Example 4: $\\text{round}(0.12351, 3) = 0.124$ (rounds up)",
          "Example 5: $\\text{round}(1.9999, 3) = 2.000$ (can change integer part)",
          "Example 6: For MAE = 0.499999 due to floating-point errors, $\\text{round}(0.499999, 3) = 0.500$"
        ]
      },
      "key_formulas": [
        {
          "name": "Rounding to d Decimals",
          "latex": "$\\text{round}(x, d) = \\frac{\\lfloor x \\cdot 10^d + 0.5 \\rfloor}{10^d}$",
          "description": "Mathematical definition of rounding (round-half-up)"
        },
        {
          "name": "MAE with Rounding",
          "latex": "$\\text{MAE}_{\\text{final}} = \\text{round}\\left(\\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|, 3\\right)$",
          "description": "Complete MAE formula with 3-decimal rounding for reporting"
        },
        {
          "name": "Machine Epsilon",
          "latex": "$\\epsilon_{\\text{machine}} \\approx 2.22 \\times 10^{-16}$",
          "description": "Smallest number such that 1.0 + ε ≠ 1.0 in floating-point"
        }
      ],
      "exercise": {
        "description": "Implement a function that takes a computed MAE value (or any float) and rounds it to exactly 3 decimal places. This is the final formatting step needed for the complete MAE implementation.",
        "function_signature": "def round_to_decimals(value: float, decimals: int = 3) -> float:",
        "starter_code": "def round_to_decimals(value: float, decimals: int = 3) -> float:\n    \"\"\"\n    Round a floating-point number to a specified number of decimal places.\n    \n    Parameters:\n    value (float): The number to round\n    decimals (int): Number of decimal places (default 3)\n    \n    Returns:\n    float: The rounded value\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "round_to_decimals(0.5, 3)",
            "expected": "0.5",
            "explanation": "0.5 rounded to 3 decimals is 0.500 (displayed as 0.5)"
          },
          {
            "input": "round_to_decimals(0.12345, 3)",
            "expected": "0.123",
            "explanation": "Truncates the 4th and 5th decimal places"
          },
          {
            "input": "round_to_decimals(0.12349, 3)",
            "expected": "0.123",
            "explanation": "Fourth digit is 4, so rounds down"
          },
          {
            "input": "round_to_decimals(0.12351, 3)",
            "expected": "0.124",
            "explanation": "Fourth digit is 5, so rounds up"
          },
          {
            "input": "round_to_decimals(1.9999, 3)",
            "expected": "2.0",
            "explanation": "Rounding can change the integer part"
          },
          {
            "input": "round_to_decimals(2.0005, 3)",
            "expected": "2.001",
            "explanation": "Fourth digit is 5, rounds up from 0.000 to 0.001"
          }
        ]
      },
      "common_mistakes": [
        "Using string formatting instead of numeric rounding (affects subsequent calculations)",
        "Confusing truncation with rounding (truncation always rounds toward zero)",
        "Not understanding banker's rounding (Python's round() uses round-half-to-even)",
        "Rounding intermediate values instead of only the final result",
        "Assuming exact decimal representation (0.1 cannot be represented exactly in binary)"
      ],
      "hint": "Python's built-in round(value, decimals) function handles this correctly. Understanding its behavior is important for numeric computing.",
      "references": [
        "IEEE 754 floating-point standard",
        "Numerical stability in scientific computing",
        "Significant figures in error reporting"
      ]
    }
  ]
}