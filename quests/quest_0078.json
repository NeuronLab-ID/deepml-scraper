{
  "problem_id": 78,
  "title": "Descriptive Statistics Calculator",
  "category": "Statistics",
  "difficulty": "easy",
  "description": "Write a Python function to calculate various descriptive statistics metrics for a given dataset. The function should take a list or NumPy array of numerical values and return a dictionary containing:\n\n- **mean**: Average of all values\n- **median**: Middle value when sorted\n- **mode**: Most frequently occurring value\n- **variance**: Population variance (divide by N)\n- **standard_deviation**: Square root of variance\n- **25th_percentile**, **50th_percentile**, **75th_percentile**: Quartile values\n- **interquartile_range**: Difference between 75th and 25th percentiles (IQR)",
  "example": {
    "input": "[1, 2, 2, 3, 4, 4, 4, 5]",
    "output": "{'mean': 3.125, 'median': 3.5, 'mode': 4, 'variance': 1.6094, 'standard_deviation': 1.2686, ...}",
    "reasoning": "Mean = (1+2+2+3+4+4+4+5)/8 = 3.125. Median = average of 4th and 5th values = (3+4)/2 = 3.5. Mode = 4 (appears 3 times, most frequent). Variance and standard deviation measure spread around the mean. Percentiles divide the sorted data into quarters."
  },
  "starter_code": "import numpy as np\n\ndef descriptive_statistics(data: list | np.ndarray) -> dict:\n    \"\"\"\n    Calculate various descriptive statistics metrics for a given dataset.\n    \n    Args:\n        data: List or numpy array of numerical values\n    \n    Returns:\n        Dictionary containing mean, median, mode, variance, standard deviation,\n        percentiles (25th, 50th, 75th), and interquartile range (IQR)\n    \"\"\"\n    # Your code here\n    pass",
  "sub_quests": [
    {
      "step": 1,
      "title": "Measures of Central Tendency: Mean, Median, and Mode",
      "relation_to_problem": "These three fundamental measures form the core of descriptive statistics and are the first metrics required in the calculator. Understanding central tendency is essential before exploring variability measures.",
      "prerequisites": [
        "Basic arithmetic operations",
        "List/array manipulation in Python",
        "Summation notation"
      ],
      "learning_objectives": [
        "Define and compute the arithmetic mean using summation notation",
        "Calculate the median for both odd and even-length datasets",
        "Identify the mode by finding the most frequent value",
        "Understand when each measure is most appropriate"
      ],
      "math_content": {
        "definition": "**Measures of Central Tendency** quantify the center or typical value of a dataset. For a dataset $X = \\{x_1, x_2, \\ldots, x_n\\}$ of $n$ observations:\n\n**Mean (Arithmetic Average)**: The sum of all values divided by the count:\n$$\\bar{x} = \\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i = \\frac{x_1 + x_2 + \\cdots + x_n}{n}$$\n\n**Median**: The middle value of the ordered dataset $X_{(1)} \\leq X_{(2)} \\leq \\cdots \\leq X_{(n)}$:\n$$\\text{median}(X) = \\begin{cases} X_{(\\frac{n+1}{2})} & \\text{if } n \\text{ is odd} \\\\ \\frac{X_{(\\frac{n}{2})} + X_{(\\frac{n}{2}+1)}}{2} & \\text{if } n \\text{ is even} \\end{cases}$$\n\n**Mode**: The value that appears most frequently:\n$$\\text{mode}(X) = \\underset{x \\in X}{\\arg\\max} \\left|\\{i : x_i = x\\}\\right|$$\nIf multiple values share the maximum frequency, return the smallest.",
        "notation": "$n$ = sample size (number of observations)\n$x_i$ = the $i$-th observation\n$\\bar{x}$ or $\\mu$ = population mean\n$X_{(i)}$ = the $i$-th order statistic (sorted values)\n$\\sum_{i=1}^{n}$ = sum from $i=1$ to $i=n$",
        "theorem": "**Properties of the Mean**:\n1. Linearity: $\\bar{ax + b} = a\\bar{x} + b$ for constants $a, b$\n2. Sum of deviations: $\\sum_{i=1}^{n}(x_i - \\bar{x}) = 0$\n3. The mean minimizes the sum of squared deviations: $\\bar{x} = \\underset{c}{\\arg\\min} \\sum_{i=1}^{n}(x_i - c)^2$",
        "proof_sketch": "**Proof that sum of deviations equals zero**:\n$$\\sum_{i=1}^{n}(x_i - \\bar{x}) = \\sum_{i=1}^{n}x_i - \\sum_{i=1}^{n}\\bar{x} = \\sum_{i=1}^{n}x_i - n\\bar{x} = \\sum_{i=1}^{n}x_i - n\\cdot\\frac{\\sum_{i=1}^{n}x_i}{n} = \\sum_{i=1}^{n}x_i - \\sum_{i=1}^{n}x_i = 0$$",
        "examples": [
          "**Example 1 (Odd length)**: $X = \\{1, 3, 5, 7, 9\\}$. Mean: $\\bar{x} = \\frac{1+3+5+7+9}{5} = \\frac{25}{5} = 5$. Median: Middle value (3rd position) = 5. Mode: No value repeats, so no mode or all values are modes.",
          "**Example 2 (Even length)**: $X = \\{2, 2, 4, 6, 8, 10\\}$. Mean: $\\bar{x} = \\frac{2+2+4+6+8+10}{6} = \\frac{32}{6} \\approx 5.333$. Median: $\\frac{4+6}{2} = 5$. Mode: 2 (appears twice).",
          "**Example 3 (From problem)**: $X = \\{1, 2, 2, 3, 4, 4, 4, 5\\}$. Mean: $\\bar{x} = \\frac{25}{8} = 3.125$. Median: $\\frac{3+4}{2} = 3.5$. Mode: 4 (appears 3 times)."
        ]
      },
      "key_formulas": [
        {
          "name": "Arithmetic Mean",
          "latex": "$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$",
          "description": "Use for the average value; sensitive to outliers"
        },
        {
          "name": "Median (Odd n)",
          "latex": "$\\text{median} = X_{(\\frac{n+1}{2})}$",
          "description": "Use when n is odd; the single middle value in sorted data"
        },
        {
          "name": "Median (Even n)",
          "latex": "$\\text{median} = \\frac{X_{(\\frac{n}{2})} + X_{(\\frac{n}{2}+1)}}{2}$",
          "description": "Use when n is even; average of two middle values"
        }
      ],
      "exercise": {
        "description": "Implement a function that calculates the mean, median, and mode of a dataset. This is the foundation for all descriptive statistics. Handle edge cases like empty datasets and ties in mode frequency.",
        "function_signature": "def calculate_central_tendency(data: list) -> dict:",
        "starter_code": "def calculate_central_tendency(data: list) -> dict:\n    \"\"\"\n    Calculate mean, median, and mode of a dataset.\n    \n    Args:\n        data: List of numerical values\n    \n    Returns:\n        Dictionary with keys 'mean', 'median', 'mode'\n        If multiple modes exist, return the smallest\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "calculate_central_tendency([1, 2, 3, 4, 5])",
            "expected": "{'mean': 3.0, 'median': 3, 'mode': 1}",
            "explanation": "Odd-length dataset: mean = 15/5 = 3, median is middle value (3rd element), no repeating values so mode is smallest (1)"
          },
          {
            "input": "calculate_central_tendency([1, 2, 2, 3, 4, 4, 4, 5])",
            "expected": "{'mean': 3.125, 'median': 3.5, 'mode': 4}",
            "explanation": "Even-length dataset: mean = 25/8, median = (3+4)/2 = 3.5, mode = 4 (appears 3 times)"
          },
          {
            "input": "calculate_central_tendency([10, 10, 20, 20])",
            "expected": "{'mean': 15.0, 'median': 15.0, 'mode': 10}",
            "explanation": "Tie in mode frequency (both appear twice), return smallest: 10"
          }
        ]
      },
      "common_mistakes": [
        "Forgetting to sort the data before finding the median",
        "Using integer division instead of float division for the mean",
        "Not handling the even-length case for median correctly (must average two middle values)",
        "Returning all tied modes instead of the smallest when multiple values have max frequency",
        "Not converting input to a list if it's a NumPy array before processing"
      ],
      "hint": "Use sorted() for median calculation, and collections.Counter or a frequency dictionary for mode. Remember to handle both odd and even dataset lengths for median.",
      "references": [
        "Order statistics and their properties",
        "Robustness of median vs mean to outliers",
        "Multimodal distributions"
      ]
    },
    {
      "step": 2,
      "title": "Population Variance and Standard Deviation",
      "relation_to_problem": "After understanding central tendency, we need measures of spread (dispersion). Variance and standard deviation quantify how data points deviate from the mean, which is essential for the descriptive statistics calculator.",
      "prerequisites": [
        "Understanding of arithmetic mean",
        "Algebraic manipulation of summations",
        "Square root operations"
      ],
      "learning_objectives": [
        "Define and calculate population variance using the deviation formula",
        "Derive and apply the computational formula for variance",
        "Compute standard deviation as the square root of variance",
        "Understand the difference between population (÷n) and sample (÷(n-1)) variance"
      ],
      "math_content": {
        "definition": "**Population Variance** ($\\sigma^2$) measures the average squared deviation from the mean:\n$$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\mu)^2$$\n\nThis is the **definitional formula**. The **computational formula** (algebraically equivalent but more numerically stable):\n$$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}x_i^2 - \\bar{x}^2 = \\frac{\\sum_{i=1}^{n}x_i^2}{n} - \\left(\\frac{\\sum_{i=1}^{n}x_i}{n}\\right)^2$$\n\n**Standard Deviation** ($\\sigma$) is the square root of variance, in the same units as the original data:\n$$\\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$\n\n**Note**: Population variance divides by $n$. Sample variance uses $n-1$ (Bessel's correction) for unbiased estimation, but this problem requires population variance.",
        "notation": "$\\sigma^2$ = population variance\n$\\sigma$ = population standard deviation\n$s^2$ = sample variance (uses $n-1$)\n$\\bar{x}$ or $\\mu$ = mean\n$(x_i - \\bar{x})$ = deviation from mean",
        "theorem": "**Computational Formula Derivation**:\nStarting from the definitional formula:\n$$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$$\n\n**Variance Properties**:\n1. $\\text{Var}(X) \\geq 0$ (non-negative)\n2. $\\text{Var}(aX + b) = a^2\\text{Var}(X)$ (constant shifts don't affect variance)\n3. $\\text{Var}(X) = E[X^2] - (E[X])^2$ (expected value notation)",
        "proof_sketch": "**Proof of computational formula**:\n$$\\begin{align*}\n\\sigma^2 &= \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^{n}(x_i^2 - 2x_i\\bar{x} + \\bar{x}^2) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^{n}x_i^2 - \\frac{2\\bar{x}}{n}\\sum_{i=1}^{n}x_i + \\frac{1}{n}\\sum_{i=1}^{n}\\bar{x}^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^{n}x_i^2 - 2\\bar{x}\\cdot\\bar{x} + \\bar{x}^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^{n}x_i^2 - \\bar{x}^2\n\\end{align*}$$\n\nThis formula is more efficient computationally but can suffer from numerical precision issues when $\\bar{x}$ is large.",
        "examples": [
          "**Example 1**: $X = \\{2, 4, 6, 8, 10\\}$. Mean: $\\bar{x} = 6$. Variance: $\\sigma^2 = \\frac{(2-6)^2 + (4-6)^2 + (6-6)^2 + (8-6)^2 + (10-6)^2}{5} = \\frac{16+4+0+4+16}{5} = \\frac{40}{5} = 8$. Standard deviation: $\\sigma = \\sqrt{8} \\approx 2.828$.",
          "**Example 2 (Computational formula)**: Same data. $\\sum x_i^2 = 4+16+36+64+100 = 220$. $\\bar{x}^2 = 36$. $\\sigma^2 = \\frac{220}{5} - 36 = 44 - 36 = 8$. Same result!",
          "**Example 3 (From problem)**: $X = \\{1, 2, 2, 3, 4, 4, 4, 5\\}$, $\\bar{x} = 3.125$. Deviations: $\\{-2.125, -1.125, -1.125, -0.125, 0.875, 0.875, 0.875, 1.875\\}$. Squared: $\\{4.516, 1.266, 1.266, 0.016, 0.766, 0.766, 0.766, 3.516\\}$. Sum = 12.875. $\\sigma^2 = 12.875/8 = 1.6094$. $\\sigma = \\sqrt{1.6094} \\approx 1.2686$."
        ]
      },
      "key_formulas": [
        {
          "name": "Population Variance (Definitional)",
          "latex": "$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^2$",
          "description": "Direct calculation using deviations from mean; conceptually clear"
        },
        {
          "name": "Population Variance (Computational)",
          "latex": "$\\sigma^2 = \\frac{\\sum_{i=1}^{n}x_i^2}{n} - \\bar{x}^2$",
          "description": "One-pass calculation; faster but less numerically stable"
        },
        {
          "name": "Standard Deviation",
          "latex": "$\\sigma = \\sqrt{\\sigma^2}$",
          "description": "Square root of variance; same units as original data"
        }
      ],
      "exercise": {
        "description": "Implement a function to calculate population variance and standard deviation. Use the definitional formula (sum of squared deviations) for numerical stability. This builds directly toward the final calculator.",
        "function_signature": "def calculate_variance_std(data: list) -> dict:",
        "starter_code": "def calculate_variance_std(data: list) -> dict:\n    \"\"\"\n    Calculate population variance and standard deviation.\n    \n    Args:\n        data: List of numerical values\n    \n    Returns:\n        Dictionary with keys 'variance' and 'standard_deviation'\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "calculate_variance_std([2, 4, 6, 8, 10])",
            "expected": "{'variance': 8.0, 'standard_deviation': 2.828}",
            "explanation": "Mean = 6, squared deviations sum to 40, variance = 40/5 = 8, std = sqrt(8) ≈ 2.828"
          },
          {
            "input": "calculate_variance_std([1, 2, 2, 3, 4, 4, 4, 5])",
            "expected": "{'variance': 1.6094, 'standard_deviation': 1.2686}",
            "explanation": "Mean = 3.125, variance = 1.6094 (rounded to 4 decimals), std ≈ 1.2686"
          },
          {
            "input": "calculate_variance_std([5, 5, 5, 5])",
            "expected": "{'variance': 0.0, 'standard_deviation': 0.0}",
            "explanation": "All values equal mean, so all deviations are 0, variance = 0"
          }
        ]
      },
      "common_mistakes": [
        "Using n-1 instead of n (that's sample variance, not population variance)",
        "Forgetting to square the deviations before summing",
        "Not importing math.sqrt or using x**0.5 for square root",
        "Using the computational formula which can have floating-point precision issues",
        "Returning variance when asked for standard deviation (or vice versa)"
      ],
      "hint": "First calculate the mean, then compute each squared deviation, sum them, and divide by n. Standard deviation is just the square root of variance.",
      "references": [
        "Bessel's correction and unbiased estimators",
        "Numerical stability in variance computation",
        "Mean squared error and its relation to variance"
      ]
    },
    {
      "step": 3,
      "title": "Percentiles and Quantiles: Order Statistics",
      "relation_to_problem": "Percentiles (25th, 50th, 75th) are critical for understanding data distribution and are required outputs. The 50th percentile equals the median, and percentiles form the basis for the interquartile range calculation.",
      "prerequisites": [
        "Understanding of ordered data and sorting",
        "Median calculation",
        "Linear interpolation"
      ],
      "learning_objectives": [
        "Define percentiles and quantiles formally",
        "Calculate percentiles using linear interpolation between ranks",
        "Understand different percentile calculation methods",
        "Identify quartiles as special cases (Q1=25th, Q2=50th, Q3=75th percentile)"
      ],
      "math_content": {
        "definition": "The **$p$-th percentile** (where $0 \\leq p \\leq 100$) is a value $x_p$ such that approximately $p\\%$ of the data falls at or below $x_p$.\n\nFor a sorted dataset $X_{(1)} \\leq X_{(2)} \\leq \\cdots \\leq X_{(n)}$:\n\n**Linear Interpolation Method** (NumPy's default):\n1. Calculate the rank: $r = \\frac{p}{100} \\cdot (n - 1) + 1$\n2. Let $k = \\lfloor r \\rfloor$ (integer part) and $f = r - k$ (fractional part)\n3. Percentile: $x_p = X_{(k)} + f \\cdot (X_{(k+1)} - X_{(k)})$\n\nIf $r$ is an integer, $x_p = X_{(r)}$. Otherwise, interpolate linearly between $X_{(k)}$ and $X_{(k+1)}$.\n\n**Quartiles** are special percentiles:\n- **First Quartile** (Q1): 25th percentile\n- **Second Quartile** (Q2): 50th percentile (median)\n- **Third Quartile** (Q3): 75th percentile",
        "notation": "$p$ = percentile value (0 to 100)\n$x_p$ or $Q_p$ = the p-th percentile\n$X_{(k)}$ = k-th order statistic (k-th smallest value)\n$Q_1, Q_2, Q_3$ = first, second, third quartiles\n$r$ = rank position\n$\\lfloor r \\rfloor$ = floor function (round down)",
        "theorem": "**Properties of Percentiles**:\n1. Monotonicity: If $p_1 < p_2$, then $x_{p_1} \\leq x_{p_2}$\n2. The 50th percentile equals the median\n3. The 0th percentile is $\\min(X)$ and 100th percentile is $\\max(X)$\n4. Percentiles are equivariant under linear transformations: percentile$(aX + b) = a \\cdot$ percentile$(X) + b$\n\n**Note**: Multiple percentile calculation methods exist (R has 9 types). NumPy uses linear interpolation by default.",
        "proof_sketch": "**Why use $(n-1)$ in rank formula**: Consider a dataset of size $n$. The indices range from 1 to $n$ (or 0 to $n-1$ in zero-indexing). For the 0th percentile, we want the minimum: $r = 0 \\cdot (n-1) + 1 = 1 \\rightarrow X_{(1)}$. For the 100th percentile, we want the maximum: $r = 1 \\cdot (n-1) + 1 = n \\rightarrow X_{(n)}$. The formula $r = p/100 \\cdot (n-1) + 1$ ensures correct boundary behavior.",
        "examples": [
          "**Example 1**: $X = \\{1, 2, 3, 4, 5\\}$, find 25th percentile. $r = 0.25 \\cdot (5-1) + 1 = 0.25 \\cdot 4 + 1 = 2$. Since $r=2$ is an integer, $Q_1 = X_{(2)} = 2$.",
          "**Example 2**: $X = \\{1, 2, 3, 4, 5\\}$, find 75th percentile. $r = 0.75 \\cdot 4 + 1 = 4$. $Q_3 = X_{(4)} = 4$.",
          "**Example 3**: $X = \\{10, 20, 30, 40\\}$, find 25th percentile. $r = 0.25 \\cdot 3 + 1 = 1.75$. $k = 1, f = 0.75$. $Q_1 = X_{(1)} + 0.75(X_{(2)} - X_{(1)}) = 10 + 0.75(20-10) = 10 + 7.5 = 17.5$.",
          "**Example 4 (From problem)**: $X = \\{1, 2, 2, 3, 4, 4, 4, 5\\}$. For 25th: $r = 0.25 \\cdot 7 + 1 = 2.75$, interpolate between $X_{(2)}=2$ and $X_{(3)}=2$: $Q_1 = 2 + 0.75(2-2) = 2.0$. For 75th: $r = 0.75 \\cdot 7 + 1 = 6.25$, interpolate between $X_{(6)}=4$ and $X_{(7)}=4$: $Q_3 = 4.0$."
        ]
      },
      "key_formulas": [
        {
          "name": "Percentile Rank",
          "latex": "$r = \\frac{p}{100} \\cdot (n-1) + 1$",
          "description": "Calculate position in sorted data for p-th percentile"
        },
        {
          "name": "Linear Interpolation",
          "latex": "$x_p = X_{(k)} + f \\cdot (X_{(k+1)} - X_{(k)})$",
          "description": "Interpolate between adjacent order statistics where k=⌊r⌋, f=r-k"
        },
        {
          "name": "Quartiles",
          "latex": "$Q_1 = P_{25}, \\quad Q_2 = P_{50}, \\quad Q_3 = P_{75}$",
          "description": "First, second (median), and third quartiles"
        }
      ],
      "exercise": {
        "description": "Implement a function to calculate any percentile using linear interpolation. Then use it to find the 25th, 50th, and 75th percentiles (quartiles). This is essential for the final statistics calculator.",
        "function_signature": "def calculate_percentile(data: list, p: float) -> float:",
        "starter_code": "def calculate_percentile(data: list, p: float) -> float:\n    \"\"\"\n    Calculate the p-th percentile using linear interpolation.\n    \n    Args:\n        data: List of numerical values\n        p: Percentile value (0 to 100)\n    \n    Returns:\n        The p-th percentile value\n    \"\"\"\n    # Your code here\n    pass\n\ndef calculate_quartiles(data: list) -> dict:\n    \"\"\"\n    Calculate the three quartiles (25th, 50th, 75th percentiles).\n    \n    Returns:\n        Dictionary with keys '25th_percentile', '50th_percentile', '75th_percentile'\n    \"\"\"\n    # Your code here using calculate_percentile\n    pass",
        "test_cases": [
          {
            "input": "calculate_percentile([1, 2, 3, 4, 5], 50)",
            "expected": "3.0",
            "explanation": "50th percentile (median) of odd-length sorted data is middle value"
          },
          {
            "input": "calculate_percentile([10, 20, 30, 40], 25)",
            "expected": "17.5",
            "explanation": "r = 0.25*3+1 = 1.75, interpolate: 10 + 0.75*(20-10) = 17.5"
          },
          {
            "input": "calculate_quartiles([1, 2, 2, 3, 4, 4, 4, 5])",
            "expected": "{'25th_percentile': 2.0, '50th_percentile': 3.5, '75th_percentile': 4.0}",
            "explanation": "Q1=2.0, Q2 (median) = 3.5, Q3=4.0 using linear interpolation"
          }
        ]
      },
      "common_mistakes": [
        "Using 1-indexed array access when rank formula assumes 1-indexing (adjust for 0-indexed Python lists)",
        "Forgetting to sort the data before calculating percentiles",
        "Using (n+1) instead of (n-1) in rank formula (different percentile methods exist)",
        "Not handling interpolation correctly when rank is non-integer",
        "Confusing percentile (0-100) with quantile (0-1) notation"
      ],
      "hint": "Sort the data first. Calculate rank using the formula, then check if it's an integer. If so, return that indexed value (adjust for 0-indexing). If not, linearly interpolate between floor(rank) and ceil(rank) positions.",
      "references": [
        "Different percentile estimation methods (Hyndman-Fan taxonomy)",
        "NumPy's percentile and quantile functions",
        "Box plots and five-number summary"
      ]
    },
    {
      "step": 4,
      "title": "Interquartile Range and Spread Measurement",
      "relation_to_problem": "The IQR is the final required metric, measuring the spread of the middle 50% of data. It's robust to outliers and complements the standard deviation as a dispersion measure.",
      "prerequisites": [
        "Understanding of quartiles and percentiles",
        "Calculation of Q1 and Q3",
        "Concept of data spread/dispersion"
      ],
      "learning_objectives": [
        "Define the interquartile range formally",
        "Calculate IQR from quartiles",
        "Understand IQR's role in outlier detection",
        "Compare IQR with other spread measures (range, variance, standard deviation)"
      ],
      "math_content": {
        "definition": "The **Interquartile Range (IQR)** measures the spread of the middle 50% of the data:\n$$\\text{IQR} = Q_3 - Q_1 = P_{75} - P_{25}$$\n\nwhere $Q_1$ is the first quartile (25th percentile) and $Q_3$ is the third quartile (75th percentile).\n\nThe IQR represents the range containing the central half of the data and is **robust** to outliers (unlike range or standard deviation).\n\n**Related Concepts**:\n- **Range**: $\\max(X) - \\min(X)$ (entire spread, sensitive to outliers)\n- **IQR**: $Q_3 - Q_1$ (middle 50% spread, robust)\n- **Standard Deviation**: $\\sigma$ (average deviation from mean, affected by outliers)\n\n**Outlier Detection Rule** (Tukey's fences):\n- Lower fence: $Q_1 - 1.5 \\times \\text{IQR}$\n- Upper fence: $Q_3 + 1.5 \\times \\text{IQR}$\n- Values outside these fences are potential outliers",
        "notation": "$\\text{IQR}$ = interquartile range\n$Q_1$ = first quartile (25th percentile)\n$Q_3$ = third quartile (75th percentile)\n$P_k$ = k-th percentile\n$[Q_1, Q_3]$ = interquartile interval",
        "theorem": "**Properties of IQR**:\n1. Scale equivariance: $\\text{IQR}(aX + b) = |a| \\cdot \\text{IQR}(X)$ (translation doesn't change IQR)\n2. Non-negativity: $\\text{IQR} \\geq 0$\n3. For normal distribution: $\\text{IQR} \\approx 1.35\\sigma$ (approximate relationship)\n4. Breakdown point: 25% (up to 25% of data can be arbitrarily large without making IQR infinite)\n\n**IQR vs Standard Deviation**:\n- IQR: Robust, less sensitive to outliers\n- SD: More efficient for normal data but sensitive to extreme values",
        "proof_sketch": "**Proof of translation invariance**: Let $Y = X + b$ for constant $b$. Then all order statistics shift by $b$: $Y_{(i)} = X_{(i)} + b$. Thus $Q_1(Y) = Q_1(X) + b$ and $Q_3(Y) = Q_3(X) + b$. Therefore:\n$$\\text{IQR}(Y) = Q_3(Y) - Q_1(Y) = [Q_3(X) + b] - [Q_1(X) + b] = Q_3(X) - Q_1(X) = \\text{IQR}(X)$$\n\nFor scaling by $a$: $Q_3(aX) = aQ_3(X)$ and $Q_1(aX) = aQ_1(X)$, so $\\text{IQR}(aX) = aQ_3(X) - aQ_1(X) = a \\cdot \\text{IQR}(X)$.",
        "examples": [
          "**Example 1**: $X = \\{1, 2, 3, 4, 5, 6, 7, 8, 9\\}$. $Q_1 = 2.5$ (interpolated), $Q_3 = 7.5$. $\\text{IQR} = 7.5 - 2.5 = 5.0$.",
          "**Example 2 (From problem)**: $X = \\{1, 2, 2, 3, 4, 4, 4, 5\\}$. $Q_1 = 2.0$, $Q_3 = 4.0$. $\\text{IQR} = 4.0 - 2.0 = 2.0$.",
          "**Example 3 (With outliers)**: $X = \\{1, 2, 3, 4, 5, 100\\}$. $Q_1 \\approx 1.75$, $Q_3 \\approx 5.25$. $\\text{IQR} \\approx 3.5$. Note: The outlier (100) doesn't dramatically affect IQR, but would greatly increase standard deviation. Lower fence: $1.75 - 1.5(3.5) = -3.5$. Upper fence: $5.25 + 1.5(3.5) = 10.5$. Value 100 is an outlier.",
          "**Example 4 (Uniform data)**: $X = \\{5, 5, 5, 5\\}$. $Q_1 = Q_3 = 5$. $\\text{IQR} = 0$ (no spread)."
        ]
      },
      "key_formulas": [
        {
          "name": "Interquartile Range",
          "latex": "$\\text{IQR} = Q_3 - Q_1$",
          "description": "Difference between third and first quartiles; measures middle 50% spread"
        },
        {
          "name": "Tukey's Lower Fence",
          "latex": "$L = Q_1 - 1.5 \\times \\text{IQR}$",
          "description": "Values below this are potential outliers"
        },
        {
          "name": "Tukey's Upper Fence",
          "latex": "$U = Q_3 + 1.5 \\times \\text{IQR}$",
          "description": "Values above this are potential outliers"
        }
      ],
      "exercise": {
        "description": "Implement a function to calculate the interquartile range. Also implement a bonus function to detect outliers using Tukey's fences (1.5×IQR rule). This combines your quartile calculation skills.",
        "function_signature": "def calculate_iqr(data: list) -> float:",
        "starter_code": "def calculate_iqr(data: list) -> float:\n    \"\"\"\n    Calculate the interquartile range (IQR).\n    \n    Args:\n        data: List of numerical values\n    \n    Returns:\n        The IQR (Q3 - Q1)\n    \"\"\"\n    # Your code here\n    pass\n\ndef detect_outliers(data: list) -> dict:\n    \"\"\"\n    Detect outliers using Tukey's fences (bonus exercise).\n    \n    Returns:\n        Dictionary with 'lower_fence', 'upper_fence', 'outliers' (list of outlier values)\n    \"\"\"\n    # Your code here\n    pass",
        "test_cases": [
          {
            "input": "calculate_iqr([1, 2, 3, 4, 5, 6, 7, 8, 9])",
            "expected": "5.0",
            "explanation": "Q1 ≈ 2.5, Q3 ≈ 7.5, IQR = 7.5 - 2.5 = 5.0"
          },
          {
            "input": "calculate_iqr([1, 2, 2, 3, 4, 4, 4, 5])",
            "expected": "2.0",
            "explanation": "Q1 = 2.0, Q3 = 4.0, IQR = 4.0 - 2.0 = 2.0"
          },
          {
            "input": "detect_outliers([1, 2, 3, 4, 5, 100])",
            "expected": "{'lower_fence': -3.5, 'upper_fence': 10.5, 'outliers': [100]}",
            "explanation": "IQR ≈ 3.5, fences at Q1-1.5*IQR and Q3+1.5*IQR, value 100 exceeds upper fence"
          }
        ]
      },
      "common_mistakes": [
        "Calculating Q3 - Q1 before ensuring data is sorted",
        "Using the wrong quartile calculation method (inconsistent with percentile implementation)",
        "Confusing IQR with range (max - min)",
        "Forgetting that IQR is always non-negative",
        "In outlier detection, using wrong multiplier (1.5 is standard, but 3.0 is used for 'far outliers')"
      ],
      "hint": "Reuse your percentile/quartile calculation function from the previous sub-quest. Calculate Q1 (25th percentile) and Q3 (75th percentile), then subtract Q1 from Q3.",
      "references": [
        "Box plots and five-number summary (min, Q1, median, Q3, max)",
        "Robust statistics and resistance to outliers",
        "Alternative outlier detection methods (z-score, modified z-score)"
      ]
    },
    {
      "step": 5,
      "title": "Comprehensive Descriptive Statistics Integration",
      "relation_to_problem": "This final sub-quest integrates all previous concepts into a complete descriptive statistics calculator. You'll combine central tendency, dispersion, and distribution measures to create the full solution.",
      "prerequisites": [
        "Mean, median, mode calculation",
        "Variance and standard deviation computation",
        "Percentile and quartile determination",
        "Interquartile range calculation"
      ],
      "learning_objectives": [
        "Integrate multiple statistical measures into a single function",
        "Handle data validation and edge cases (empty data, single value, etc.)",
        "Return results in a structured dictionary format",
        "Apply proper rounding and numerical precision for output",
        "Understand the complete picture of data distribution through all metrics together"
      ],
      "math_content": {
        "definition": "A **Descriptive Statistics Summary** is a comprehensive characterization of a dataset using multiple complementary measures:\n\n**Central Tendency** (location):\n- Mean ($\\bar{x}$): sensitive to all values\n- Median ($Q_2$): resistant to outliers\n- Mode: most typical value\n\n**Dispersion** (spread):\n- Variance ($\\sigma^2$): average squared deviation\n- Standard Deviation ($\\sigma$): typical deviation in original units\n- IQR: spread of middle 50%\n\n**Distribution** (shape and position):\n- Percentiles ($Q_1, Q_2, Q_3$): divide data into quarters\n- Min/Max: data range boundaries\n\nTogether, these metrics form the **five-number summary** plus additional measures: $(\\min, Q_1, Q_2, Q_3, \\max, \\bar{x}, \\sigma, \\text{mode})$.",
        "notation": "$\\{x_1, x_2, \\ldots, x_n\\}$ = dataset\n$n$ = sample size\n$\\bar{x}$ = mean\n$\\sigma^2, \\sigma$ = variance, standard deviation\n$Q_1, Q_2, Q_3$ = quartiles\n$\\text{IQR}$ = interquartile range",
        "theorem": "**Relationship Between Metrics**:\n1. For symmetric distributions: mean ≈ median\n2. For right-skewed: mean > median\n3. For left-skewed: mean < median\n4. Empirical Rule (normal distribution): approximately 68% of data within $\\bar{x} \\pm \\sigma$, 95% within $\\bar{x} \\pm 2\\sigma$, 99.7% within $\\bar{x} \\pm 3\\sigma$\n5. Chebyshev's Inequality: For any distribution, at least $1 - \\frac{1}{k^2}$ of data lies within $k$ standard deviations of the mean (e.g., at least 75% within $2\\sigma$)\n\n**Coefficient of Variation**: $CV = \\frac{\\sigma}{\\bar{x}}$ (relative variability, useful for comparing datasets with different units or scales)",
        "proof_sketch": "**Chebyshev's Inequality Proof Sketch**: For any $k > 0$, the probability that a random variable $X$ deviates from its mean by at least $k$ standard deviations is:\n$$P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2}$$\n\nEquivalently, $P(|X - \\mu| < k\\sigma) \\geq 1 - \\frac{1}{k^2}$.\n\nProof uses Markov's inequality applied to $(X - \\mu)^2$. This bound holds for ANY distribution (not just normal), making it a powerful general result, though conservative for specific distributions.",
        "examples": [
          "**Example 1 (Complete analysis)**: $X = \\{1, 2, 2, 3, 4, 4, 4, 5\\}$. Mean: 3.125, Median: 3.5, Mode: 4. Variance: 1.6094, SD: 1.2686. Q1: 2.0, Q2: 3.5, Q3: 4.0, IQR: 2.0. Interpretation: Right-skewed (mean < median), mode at upper end. Moderate spread (SD ≈ 1.27, IQR = 2).",
          "**Example 2 (Symmetric)**: $X = \\{1, 2, 3, 4, 5\\}$. Mean: 3.0, Median: 3.0, Mode: 1 (all equal frequency). Variance: 2.0, SD: 1.414. Q1: 1.5, Q2: 3.0, Q3: 4.5, IQR: 3.0. Interpretation: Symmetric distribution (mean = median), uniform frequency.",
          "**Example 3 (No variation)**: $X = \\{5, 5, 5\\}$. Mean: 5.0, Median: 5.0, Mode: 5. Variance: 0.0, SD: 0.0. Q1: 5.0, Q2: 5.0, Q3: 5.0, IQR: 0.0. Interpretation: No variability, all measures converge to single value."
        ]
      },
      "key_formulas": [
        {
          "name": "Complete Statistics Dictionary",
          "latex": "$\\text{stats} = \\{\\bar{x}, \\tilde{x}, \\text{mode}, \\sigma^2, \\sigma, Q_1, Q_2, Q_3, \\text{IQR}\\}$",
          "description": "Comprehensive summary combining all measures"
        },
        {
          "name": "Coefficient of Variation",
          "latex": "$CV = \\frac{\\sigma}{|\\bar{x}|} \\times 100\\%$",
          "description": "Relative variability (optional but useful for comparison)"
        }
      ],
      "exercise": {
        "description": "Create a comprehensive descriptive statistics calculator that integrates all previous sub-quests. The function should accept a list or NumPy array and return a dictionary with all required metrics: mean, median, mode, variance, standard_deviation, 25th/50th/75th percentiles, and IQR. Include data validation for edge cases.",
        "function_signature": "def descriptive_statistics(data: list | np.ndarray) -> dict:",
        "starter_code": "import numpy as np\n\ndef descriptive_statistics(data):\n    \"\"\"\n    Calculate comprehensive descriptive statistics for a dataset.\n    \n    Args:\n        data: List or numpy array of numerical values\n    \n    Returns:\n        Dictionary containing:\n        - mean: arithmetic average\n        - median: middle value\n        - mode: most frequent value (smallest if tie)\n        - variance: population variance\n        - standard_deviation: square root of variance\n        - 25th_percentile: first quartile\n        - 50th_percentile: second quartile (median)\n        - 75th_percentile: third quartile\n        - interquartile_range: Q3 - Q1\n    \"\"\"\n    # Convert to list if numpy array\n    if isinstance(data, np.ndarray):\n        data = data.tolist()\n    \n    # Your code here - combine all previous concepts\n    # Hint: Reuse or adapt functions from previous sub-quests\n    pass",
        "test_cases": [
          {
            "input": "descriptive_statistics([1, 2, 2, 3, 4, 4, 4, 5])",
            "expected": "{'mean': 3.125, 'median': 3.5, 'mode': 4, 'variance': 1.6094, 'standard_deviation': 1.2686, '25th_percentile': 2.0, '50th_percentile': 3.5, '75th_percentile': 4.0, 'interquartile_range': 2.0}",
            "explanation": "Complete statistics for the example dataset. All metrics calculated using formulas from previous sub-quests."
          },
          {
            "input": "descriptive_statistics([10, 20, 30, 40, 50])",
            "expected": "{'mean': 30.0, 'median': 30, 'mode': 10, 'variance': 200.0, 'standard_deviation': 14.142, '25th_percentile': 15.0, '50th_percentile': 30.0, '75th_percentile': 45.0, 'interquartile_range': 30.0}",
            "explanation": "Symmetric distribution with equal spacing. Mean equals median, large IQR relative to range."
          },
          {
            "input": "descriptive_statistics(np.array([5, 5, 5]))",
            "expected": "{'mean': 5.0, 'median': 5, 'mode': 5, 'variance': 0.0, 'standard_deviation': 0.0, '25th_percentile': 5.0, '50th_percentile': 5.0, '75th_percentile': 5.0, 'interquartile_range': 0.0}",
            "explanation": "No variation case - all values identical. Tests NumPy array input handling."
          }
        ]
      },
      "common_mistakes": [
        "Not converting NumPy arrays to lists (can cause indexing issues)",
        "Forgetting to round output to reasonable precision (4 decimal places is standard)",
        "Calculating metrics in wrong order (need mean before variance, need quartiles before IQR)",
        "Not handling edge cases (empty list, single value, all identical values)",
        "Using sample variance (n-1) instead of population variance (n) as specified",
        "Dictionary keys not matching exact specification ('std' vs 'standard_deviation')"
      ],
      "hint": "Build incrementally: start with simple metrics (mean), then use those in complex ones (variance needs mean). Sort data once at the beginning for efficiency. Store intermediate results (like quartiles) to avoid recalculation. Test each component separately before integration.",
      "references": [
        "Exploratory Data Analysis (EDA) best practices",
        "Pandas describe() method implementation",
        "NumPy statistical functions documentation",
        "Tukey's five-number summary and box plots"
      ]
    }
  ]
}